{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1187d7fc",
   "metadata": {},
   "source": [
    "# Filtering the Noise: ML for Trustworthy Location Reviews\n",
    "\n",
    "**Team:** OIIA OIIA \n",
    "**Date:** August 31, 2025  \n",
    "**Challenge:** Design and implement an ML-based system to evaluate the quality and relevancy of Google location reviews\n",
    "\n",
    "### Problem Statement\n",
    "- **Gauge review quality**: Detect spam, advertisements*, irrelevant content*, and rants*\n",
    "- **Assess relevancy**: Determine if review content is genuinely related to the location\n",
    "- **Enforce policies**: Automatically flag reviews violating predefined policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b4810",
   "metadata": {},
   "source": [
    "## üî® Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3fd6026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (4.56.0)\n",
      "Requirement already satisfied: torch in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (2.8.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (4.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (3.10.6)\n",
      "Requirement already satisfied: seaborn in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (0.13.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (6.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2025.8.29)\n",
      "Requirement already satisfied: requests in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from plotly) (2.2.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from fsspec->torch) (3.12.15)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.20.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (0.34.4)\n",
      "Requirement already satisfied: accelerate in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (1.10.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (4.15.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (2.3.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (3.9.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (3.8.7)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (1.9.4)\n",
      "Requirement already satisfied: click in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (2025.8.29)\n",
      "Requirement already satisfied: tqdm in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from wordcloud) (11.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from wordcloud) (3.10.6)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: wrapt in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kaggle in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (2025.8.3)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (3.4.3)\n",
      "Requirement already satisfied: idna in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (6.32.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\program files\\python311\\lib\\site-packages (from kaggle) (65.5.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textstat in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (0.7.8)\n",
      "Requirement already satisfied: pyphen in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: cmudict in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from textstat) (1.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from textstat) (65.5.0)\n",
      "Requirement already satisfied: importlib-metadata>=5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from cmudict->textstat) (8.7.0)\n",
      "Requirement already satisfied: importlib-resources>=5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from cmudict->textstat) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from importlib-metadata>=5->cmudict->textstat) (3.23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "All packages installed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ‚ö†Ô∏è Run this cell only if fresh runtime or first time setup\n",
    "\n",
    "# Install required packages\n",
    "%pip install transformers torch datasets pandas numpy scikit-learn matplotlib seaborn plotly\n",
    "%pip install huggingface-hub accelerate\n",
    "%pip install nltk spacy wordcloud\n",
    "%pip install kaggle\n",
    "%pip install textstat\n",
    "print(\"All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b987589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanh\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\seanh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\seanh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\seanh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ‚ö†Ô∏è Run this cell only if fresh runtime or first time setup\n",
    "\n",
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# NLP and ML libraries\n",
    "import nltk\n",
    "import spacy\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Data processing\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Terminal commands\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bfc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è Run this cell only if fresh runtime or first time setup\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Kaggle API Setup & Downloading of Dataset to ./kaggle_data directory\n",
    "def config_kaggle_api_token():\n",
    "    # kaggle_dir = Path.home() / '.config' / 'kaggle'\n",
    "    kaggle_dir = Path.home() / '.kaggle'\n",
    "    kaggle_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    shutil.copy('./kaggle.json', kaggle_dir / 'kaggle.json')\n",
    "    os.chmod(kaggle_dir / 'kaggle.json', 0o600)\n",
    "\n",
    "def download_kaggle_dataset(path='./kaggle_data', dataset_name=\"denizbilginn/google-maps-restaurant-reviews\"):\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    dataset_name=\"denizbilginn/google-maps-restaurant-reviews\"\n",
    "    api.dataset_download_files(dataset_name,\n",
    "                            path=path,\n",
    "                            unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b39ba",
   "metadata": {},
   "source": [
    "## üìä Data Collection & Loading\n",
    "\n",
    "We'll use the provided Google Local Reviews dataset. You can also supplement with additional data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c52343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/denizbilginn/google-maps-restaurant-reviews\n"
     ]
    }
   ],
   "source": [
    "# ‚ö†Ô∏è Run this cell only if fresh runtime or first time setup\n",
    "\n",
    "# Download Kaggle Dataset\n",
    "config_kaggle_api_token()\n",
    "download_kaggle_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Functions\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    \"\"\"Load dataset from local CSV file\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"‚úÖ Loaded {len(df)} rows from {file_path}\")\n",
    "            # df = standardize_columns(df)\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"‚ùå File not found: {file_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading local file: {e}\")\n",
    "        return None\n",
    "\n",
    "def standardize_columns(df):\n",
    "    \"\"\"Standardize column names to match our expected format\"\"\"\n",
    "    # Common column mappings\n",
    "    column_mappings = {\n",
    "        'text': 'review_text',\n",
    "        'review': 'review_text',\n",
    "        'comment': 'review_text',\n",
    "        'content': 'review_text',\n",
    "        'review_text': 'review_text',\n",
    "\n",
    "        'rating': 'rating',\n",
    "        'stars': 'rating',\n",
    "        'score': 'rating',\n",
    "        'star_rating': 'rating',\n",
    "\n",
    "        'business': 'business_name',\n",
    "        'restaurant': 'business_name',\n",
    "        'place_name': 'business_name',\n",
    "        'name': 'business_name',\n",
    "\n",
    "        'user': 'user_id',\n",
    "        'user_name': 'user_id',\n",
    "        'reviewer': 'user_id',\n",
    "\n",
    "        'date': 'timestamp',\n",
    "        'time': 'timestamp',\n",
    "        'created_at': 'timestamp',\n",
    "        'review_date': 'timestamp'\n",
    "    }\n",
    "\n",
    "    # Convert column names to lowercase for matching\n",
    "    df_columns_lower = [col.lower() for col in df.columns]\n",
    "\n",
    "    # Apply mappings\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        if col_lower in column_mappings:\n",
    "            new_columns.append(column_mappings[col_lower])\n",
    "        else:\n",
    "            new_columns.append(col)\n",
    "\n",
    "    df.columns = new_columns\n",
    "\n",
    "    # Ensure we have required columns\n",
    "    required_columns = ['review_text', 'rating']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            if col == 'review_text':\n",
    "                # Try to find any text column\n",
    "                text_cols = [c for c in df.columns if 'text' in c.lower() or 'review' in c.lower() or 'comment' in c.lower()]\n",
    "                if text_cols:\n",
    "                    df['review_text'] = df[text_cols[0]]\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Could not find text column, creating placeholder\")\n",
    "                    df['review_text'] = \"Sample review text\"\n",
    "            elif col == 'rating':\n",
    "                # Try to find any rating column\n",
    "                rating_cols = [c for c in df.columns if 'rating' in c.lower() or 'star' in c.lower() or 'score' in c.lower()]\n",
    "                if rating_cols:\n",
    "                    df['rating'] = df[rating_cols[0]]\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Could not find rating column, creating placeholder\")\n",
    "                    df['rating'] = 3  # Default neutral rating\n",
    "\n",
    "    # Add missing optional columns\n",
    "    if 'business_name' not in df.columns:\n",
    "        df['business_name'] = 'Unknown Business'\n",
    "    if 'user_id' not in df.columns:\n",
    "        df['user_id'] = [f'user_{i}' for i in range(len(df))]\n",
    "    if 'timestamp' not in df.columns:\n",
    "        df['timestamp'] = pd.date_range('2024-01-01', periods=len(df), freq='D')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd1608a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 1100 rows from ./kaggle_data/reviews.csv\n",
      "üîß Introduced a missing value in row 5 (text column)\n",
      "\n",
      "üßπ Cleaned dataset: 1100 ‚Üí 1100 rows (removed 0)\n",
      "\n",
      "üìã Cleaned Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100 entries, 0 to 1099\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   business_name    1100 non-null   object\n",
      " 1   author_name      1100 non-null   object\n",
      " 2   text             1100 non-null   object\n",
      " 3   rating           1100 non-null   int64 \n",
      " 4   photo            1100 non-null   object\n",
      " 5   rating_category  1100 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 51.7+ KB\n",
      "None\n",
      "\n",
      "üìä Dataset shape: (1100, 6)\n",
      "\n",
      "üîç First 5 reviews:\n",
      "                     business_name    author_name  \\\n",
      "0  Haci'nin Yeri - Yigit Lokantasi    Gulsum Akar   \n",
      "1  Haci'nin Yeri - Yigit Lokantasi  Oguzhan Cetin   \n",
      "2  Haci'nin Yeri - Yigit Lokantasi     Yasin Kuyu   \n",
      "3  Haci'nin Yeri - Yigit Lokantasi     Orhan Kapu   \n",
      "4  Haci'nin Yeri - Yigit Lokantasi     Ozgur Sati   \n",
      "\n",
      "                                                text  rating  \\\n",
      "0  We went to Marmaris with my wife for a holiday...       5   \n",
      "1  During my holiday in Marmaris we ate here to f...       4   \n",
      "2  Prices are very affordable. The menu in the ph...       3   \n",
      "3  Turkey's cheapest artisan restaurant and its f...       5   \n",
      "4  I don't know what you will look for in terms o...       3   \n",
      "\n",
      "                                               photo     rating_category  \n",
      "0         dataset/taste/hacinin_yeri_gulsum_akar.png               taste  \n",
      "1        dataset/menu/hacinin_yeri_oguzhan_cetin.png                menu  \n",
      "2  dataset/outdoor_atmosphere/hacinin_yeri_yasin_...  outdoor_atmosphere  \n",
      "3  dataset/indoor_atmosphere/hacinin_yeri_orhan_k...   indoor_atmosphere  \n",
      "4           dataset/menu/hacinin_yeri_ozgur_sati.png                menu  \n",
      "\n",
      "‚úÖ Data Quality Check:\n",
      "- Total reviews: 1100\n",
      "- Unique businesses: 100\n",
      "- Rating distribution: {1: np.int64(80), 2: np.int64(72), 3: np.int64(172), 4: np.int64(316), 5: np.int64(460)}\n",
      "- Missing values: 0\n",
      "- Average review length: 110.8 characters\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = load_dataset('./kaggle_data/reviews.csv')\n",
    "\n",
    "# üëá Simulate a bad row (make the 5th row's text missing)\n",
    "df.loc[4, \"review_text\"] = \"\"   # or \"\" to test empty-string removal\n",
    "print(\"üîß Introduced a missing value in row 5 (text column)\\n\")\n",
    "\n",
    "df = clean_reviews_dataset(df)\n",
    "\n",
    "print(\"\\nüìã Cleaned Dataset Info:\")\n",
    "print(df.info())\n",
    "print(f\"\\nüìä Dataset shape: {df.shape}\")\n",
    "print(\"\\nüîç First 5 reviews:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display data quality info\n",
    "print(f\"\\n‚úÖ Data Quality Check:\")\n",
    "print(f\"- Total reviews: {len(df)}\")\n",
    "print(f\"- Unique businesses: {df['business_name'].nunique()}\")\n",
    "print(f\"- Rating distribution: {dict(df['rating'].value_counts().sort_index())}\")\n",
    "print(f\"- Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"- Average review length: {df['text'].str.len().mean():.1f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fd5f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleanup\n",
    "\n",
    "def _find_col(df, aliases, required=True):\n",
    "    \"\"\"Return the first matching column from aliases; None if not found and required=False.\"\"\"\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    for a in aliases:\n",
    "        if a.lower() in cols_lower:\n",
    "            return cols_lower[a.lower()]\n",
    "    if required:\n",
    "        raise KeyError(f\"None of the aliases {aliases} found in columns: {list(df.columns)}\")\n",
    "    return None\n",
    "\n",
    "def clean_reviews_dataset(df):\n",
    "    \"\"\"\n",
    "    Keep rows that have ALL of the following (non-empty, non-NaN):\n",
    "      - business_name\n",
    "      - author_name\n",
    "      - text\n",
    "      - rating\n",
    "    Allow missing: photo, rating_category\n",
    "    Preserve output columns in original schema.\n",
    "    \"\"\"\n",
    "\n",
    "    # Resolve columns even if earlier steps renamed them\n",
    "    col_business = _find_col(df, [\"business_name\", \"restaurant\", \"place_name\", \"name\"])\n",
    "    col_author   = _find_col(df, [\"author_name\", \"user\", \"user_name\", \"reviewer\"])\n",
    "    col_text     = _find_col(df, [\"text\", \"review_text\", \"comment\", \"content\"])\n",
    "    col_rating   = _find_col(df, [\"rating\", \"stars\", \"score\", \"star_rating\"])\n",
    "\n",
    "    # Optional columns may or may not exist\n",
    "    col_photo          = _find_col(df, [\"photo\"], required=False)\n",
    "    col_rating_category= _find_col(df, [\"rating_category\"], required=False)\n",
    "\n",
    "    # Work on a copy\n",
    "    d = df.copy()\n",
    "\n",
    "    # Normalize whitespace for string fields (only if they exist)\n",
    "    for c in [col_business, col_author, col_text]:\n",
    "        d[c] = d[c].astype(str).str.strip()\n",
    "\n",
    "    # Coerce rating to numeric\n",
    "    d[col_rating] = pd.to_numeric(d[col_rating], errors=\"coerce\")\n",
    "\n",
    "    # Drop rows with missing/empty required fields\n",
    "    before = len(d)\n",
    "    d = d.dropna(subset=[col_business, col_author, col_text, col_rating])\n",
    "    # Remove empty-string rows in required text columns\n",
    "    for c in [col_business, col_author, col_text]:\n",
    "        d = d[d[c] != \"\"]\n",
    "    # Optionally enforce valid rating range (comment out if you want raw)\n",
    "    d = d[(d[col_rating] >= 1) & (d[col_rating] <= 5)]\n",
    "\n",
    "    removed = before - len(d)\n",
    "    print(f\"üßπ Cleaned dataset: {before} ‚Üí {len(d)} rows (removed {removed})\")\n",
    "\n",
    "    # Rebuild output with your target column names in the same format\n",
    "    out = pd.DataFrame({\n",
    "        \"business_name\":    d[col_business],\n",
    "        \"author_name\":      d[col_author],\n",
    "        \"text\":             d[col_text],\n",
    "        \"rating\":           d[col_rating],\n",
    "    })\n",
    "\n",
    "    # Attach optional columns if present; else create with NaN\n",
    "    out[\"photo\"] = d[col_photo] if col_photo in d.columns else pd.Series([pd.NA]*len(d))\n",
    "    out[\"rating_category\"] = d[col_rating_category] if col_rating_category in d.columns else pd.Series([pd.NA]*len(d))\n",
    "\n",
    "    # Keep any extra columns? If you want to strictly keep only the six, return `out` as is.\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9692e1",
   "metadata": {},
   "source": [
    "## üîß Feature Engineering\n",
    "\n",
    "Extract comprehensive textual and non-textual features from review data for ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faad4094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ textstat module loaded successfully\n",
      "üîß Extracting features...\n",
      "üìã Available columns: ['business_name', 'author_name', 'text', 'rating', 'photo', 'rating_category']\n",
      "‚úÖ Using 'text' as the text column\n",
      "   Processing row 0/1100\n",
      "   Processing row 1000/1100\n",
      "‚úÖ Feature extraction complete! Extracted 44 features\n",
      "\n",
      "üìä Dataset with features shape: (1100, 50)\n",
      "\n",
      "üîç Feature columns extracted:\n",
      "    1. text_length\n",
      "    2. word_count\n",
      "    3. sentence_count\n",
      "    4. avg_word_length\n",
      "    5. uppercase_count\n",
      "    6. punctuation_count\n",
      "    7. digit_count\n",
      "    8. exclamation_count\n",
      "    9. question_count\n",
      "   10. uppercase_ratio\n",
      "   11. punctuation_ratio\n",
      "   12. digit_ratio\n",
      "   13. sentiment_pos\n",
      "   14. sentiment_neu\n",
      "   15. sentiment_neg\n",
      "   16. sentiment_compound\n",
      "   17. has_url\n",
      "   18. has_email\n",
      "   19. has_phone\n",
      "   20. first_person_count\n",
      "   21. second_person_count\n",
      "   22. third_person_count\n",
      "   23. first_person_ratio\n",
      "   24. second_person_ratio\n",
      "   25. third_person_ratio\n",
      "   26. spam_keyword_count\n",
      "   27. spam_keyword_ratio\n",
      "   28. restaurant_keyword_count\n",
      "   29. restaurant_keyword_ratio\n",
      "   30. flesch_reading_ease\n",
      "   31. flesch_kincaid_grade\n",
      "   32. all_caps_word_count\n",
      "   33. all_caps_ratio\n",
      "   34. unique_word_ratio\n",
      "   35. rating\n",
      "   36. is_extreme_rating\n",
      "   37. is_low_rating\n",
      "   38. is_high_rating\n",
      "   39. is_neutral_rating\n",
      "   40. author_name_length\n",
      "   41. author_has_numbers\n",
      "   42. author_all_caps\n",
      "   43. business_name_length\n",
      "   44. has_photo\n",
      "\n",
      "üìà Feature Statistics Summary:\n",
      "       text_length  word_count  sentence_count  avg_word_length  \\\n",
      "count     1100.000    1100.000        1100.000         1100.000   \n",
      "mean       110.834      20.052           2.145            4.807   \n",
      "std         69.154      12.978           1.233            0.947   \n",
      "min          5.000       1.000           1.000            3.269   \n",
      "25%         62.000      11.000           1.000            4.248   \n",
      "50%        104.000      19.000           2.000            4.615   \n",
      "75%        147.000      27.000           3.000            5.056   \n",
      "max        914.000     179.000          17.000           12.000   \n",
      "\n",
      "       uppercase_count  punctuation_count  digit_count  exclamation_count  \\\n",
      "count         1100.000           1100.000     1100.000           1100.000   \n",
      "mean             2.768              3.663        0.313              0.085   \n",
      "std              1.999              2.213        1.090              0.321   \n",
      "min              0.000              0.000        0.000              0.000   \n",
      "25%              1.000              2.000        0.000              0.000   \n",
      "50%              2.000              3.000        0.000              0.000   \n",
      "75%              3.000              5.000        0.000              0.000   \n",
      "max             23.000             22.000        9.000              4.000   \n",
      "\n",
      "       question_count  uppercase_ratio  ...    rating  is_extreme_rating  \\\n",
      "count        1100.000         1100.000  ...  1100.000           1100.000   \n",
      "mean            0.006            0.030  ...     3.913              0.491   \n",
      "std             0.080            0.024  ...     1.218              0.500   \n",
      "min             0.000            0.000  ...     1.000              0.000   \n",
      "25%             0.000            0.018  ...     3.000              0.000   \n",
      "50%             0.000            0.025  ...     4.000              0.000   \n",
      "75%             0.000            0.035  ...     5.000              1.000   \n",
      "max             1.000            0.333  ...     5.000              1.000   \n",
      "\n",
      "       is_low_rating  is_high_rating  is_neutral_rating  author_name_length  \\\n",
      "count       1100.000        1100.000           1100.000            1100.000   \n",
      "mean           0.138           0.705              0.156              12.005   \n",
      "std            0.345           0.456              0.363               2.069   \n",
      "min            0.000           0.000              0.000               6.000   \n",
      "25%            0.000           0.000              0.000              11.000   \n",
      "50%            0.000           1.000              0.000              12.000   \n",
      "75%            0.000           1.000              0.000              13.000   \n",
      "max            1.000           1.000              1.000              20.000   \n",
      "\n",
      "       author_has_numbers  author_all_caps  business_name_length  has_photo  \n",
      "count              1100.0           1100.0              1100.000     1100.0  \n",
      "mean                  0.0              0.0                12.300        1.0  \n",
      "std                   0.0              0.0                 5.085        0.0  \n",
      "min                   0.0              0.0                 3.000        1.0  \n",
      "25%                   0.0              0.0                 8.000        1.0  \n",
      "50%                   0.0              0.0                12.000        1.0  \n",
      "75%                   0.0              0.0                16.000        1.0  \n",
      "max                   0.0              0.0                31.000        1.0  \n",
      "\n",
      "[8 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from datetime import datetime\n",
    "\n",
    "# Try to import textstat, use fallback if not available\n",
    "try:\n",
    "    from textstat import flesch_reading_ease, flesch_kincaid_grade\n",
    "    TEXTSTAT_AVAILABLE = True\n",
    "    print(\"‚úÖ textstat module loaded successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è textstat module not found. Readability metrics will be set to default values.\")\n",
    "    print(\"üí° To install: pip install textstat\")\n",
    "    TEXTSTAT_AVAILABLE = False\n",
    "    \n",
    "    # Fallback functions\n",
    "    def flesch_reading_ease(text):\n",
    "        return 50.0  # Default neutral readability score\n",
    "    \n",
    "    def flesch_kincaid_grade(text):\n",
    "        return 8.0   # Default grade level\n",
    "\n",
    "class AdvancedFeatureExtractor:\n",
    "    \"\"\"Extract comprehensive textual and non-textual features from review data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sia = SentimentIntensityAnalyzer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # Common spam/promotional keywords\n",
    "        self.spam_keywords = [\n",
    "            'discount', 'promo', 'deal', 'offer', 'sale', 'buy', 'purchase', \n",
    "            'visit', 'click', 'link', 'website', 'free', 'win', 'prize'\n",
    "        ]\n",
    "        \n",
    "        # Restaurant-related keywords for relevancy\n",
    "        self.restaurant_keywords = [\n",
    "            'food', 'meal', 'eat', 'taste', 'flavor', 'delicious', 'menu',\n",
    "            'service', 'waiter', 'waitress', 'staff', 'cook', 'chef',\n",
    "            'restaurant', 'cafe', 'dine', 'dining', 'lunch', 'dinner',\n",
    "            'breakfast', 'appetizer', 'entree', 'dessert', 'drink'\n",
    "        ]\n",
    "        \n",
    "    def extract_textual_features(self, text):\n",
    "        \"\"\"Extract comprehensive textual features\"\"\"\n",
    "        features = {}\n",
    "        text_lower = text.lower()\n",
    "        words = text.split()\n",
    "        \n",
    "        # Basic text statistics\n",
    "        features['text_length'] = len(text)\n",
    "        features['word_count'] = len(words)\n",
    "        features['sentence_count'] = len([s for s in text.split('.') if s.strip()])\n",
    "        features['avg_word_length'] = np.mean([len(word) for word in words]) if words else 0\n",
    "        \n",
    "        # Character-level features\n",
    "        features['uppercase_count'] = sum(1 for c in text if c.isupper())\n",
    "        features['punctuation_count'] = sum(1 for c in text if c in string.punctuation)\n",
    "        features['digit_count'] = sum(1 for c in text if c.isdigit())\n",
    "        features['exclamation_count'] = text.count('!')\n",
    "        features['question_count'] = text.count('?')\n",
    "        \n",
    "        # Ratios\n",
    "        total_chars = len(text) if len(text) > 0 else 1\n",
    "        features['uppercase_ratio'] = features['uppercase_count'] / total_chars\n",
    "        features['punctuation_ratio'] = features['punctuation_count'] / total_chars\n",
    "        features['digit_ratio'] = features['digit_count'] / total_chars\n",
    "        \n",
    "        # Sentiment analysis\n",
    "        sentiment_scores = self.sia.polarity_scores(text)\n",
    "        features.update({\n",
    "            'sentiment_pos': sentiment_scores['pos'],\n",
    "            'sentiment_neu': sentiment_scores['neu'],\n",
    "            'sentiment_neg': sentiment_scores['neg'],\n",
    "            'sentiment_compound': sentiment_scores['compound']\n",
    "        })\n",
    "        \n",
    "        # URL and contact detection\n",
    "        features['has_url'] = bool(re.search(r'http[s]?://\\S+|www\\.\\w+\\.\\w+', text_lower))\n",
    "        features['has_email'] = bool(re.search(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text))\n",
    "        features['has_phone'] = bool(re.search(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', text))\n",
    "        \n",
    "        # Personal pronouns and perspective\n",
    "        first_person_words = ['i', 'me', 'my', 'myself', 'we', 'us', 'our']\n",
    "        second_person_words = ['you', 'your', 'yours']\n",
    "        third_person_words = ['he', 'she', 'it', 'they', 'them', 'their']\n",
    "        \n",
    "        words_lower = [w.lower().strip(string.punctuation) for w in words]\n",
    "        features['first_person_count'] = sum(1 for word in words_lower if word in first_person_words)\n",
    "        features['second_person_count'] = sum(1 for word in words_lower if word in second_person_words)\n",
    "        features['third_person_count'] = sum(1 for word in words_lower if word in third_person_words)\n",
    "        \n",
    "        total_words = len(words) if len(words) > 0 else 1\n",
    "        features['first_person_ratio'] = features['first_person_count'] / total_words\n",
    "        features['second_person_ratio'] = features['second_person_count'] / total_words\n",
    "        features['third_person_ratio'] = features['third_person_count'] / total_words\n",
    "        \n",
    "        # Spam/promotional indicators\n",
    "        features['spam_keyword_count'] = sum(1 for keyword in self.spam_keywords if keyword in text_lower)\n",
    "        features['spam_keyword_ratio'] = features['spam_keyword_count'] / total_words\n",
    "        \n",
    "        # Restaurant relevancy indicators\n",
    "        features['restaurant_keyword_count'] = sum(1 for keyword in self.restaurant_keywords if keyword in text_lower)\n",
    "        features['restaurant_keyword_ratio'] = features['restaurant_keyword_count'] / total_words\n",
    "        \n",
    "        # Readability metrics with fallback\n",
    "        try:\n",
    "            if TEXTSTAT_AVAILABLE:\n",
    "                features['flesch_reading_ease'] = flesch_reading_ease(text)\n",
    "                features['flesch_kincaid_grade'] = flesch_kincaid_grade(text)\n",
    "            else:\n",
    "                # Use simple fallback calculations\n",
    "                avg_sentence_length = features['word_count'] / max(features['sentence_count'], 1)\n",
    "                features['flesch_reading_ease'] = max(0, min(100, 206.835 - (1.015 * avg_sentence_length) - (84.6 * features['avg_word_length'])))\n",
    "                features['flesch_kincaid_grade'] = max(0, (0.39 * avg_sentence_length) + (11.8 * features['avg_word_length']) - 15.59)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Readability calculation failed: {e}\")\n",
    "            features['flesch_reading_ease'] = 50.0  # Default neutral score\n",
    "            features['flesch_kincaid_grade'] = 8.0   # Default grade level\n",
    "        \n",
    "        # All caps words (often indicates spam/shouting)\n",
    "        all_caps_words = [w for w in words if w.isupper() and len(w) > 1]\n",
    "        features['all_caps_word_count'] = len(all_caps_words)\n",
    "        features['all_caps_ratio'] = len(all_caps_words) / total_words\n",
    "        \n",
    "        # Repetitive patterns\n",
    "        unique_words = set(words_lower)\n",
    "        features['unique_word_ratio'] = len(unique_words) / total_words\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def extract_non_textual_features(self, row):\n",
    "        \"\"\"Extract non-textual features from metadata\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Rating-based features\n",
    "        features['rating'] = row['rating']\n",
    "        features['is_extreme_rating'] = 1 if row['rating'] in [1, 5] else 0\n",
    "        features['is_low_rating'] = 1 if row['rating'] <= 2 else 0\n",
    "        features['is_high_rating'] = 1 if row['rating'] >= 4 else 0\n",
    "        features['is_neutral_rating'] = 1 if row['rating'] == 3 else 0\n",
    "        \n",
    "        # Author-based features\n",
    "        if 'author_name' in row:\n",
    "            author_name = str(row['author_name'])\n",
    "            features['author_name_length'] = len(author_name)\n",
    "            features['author_has_numbers'] = 1 if any(c.isdigit() for c in author_name) else 0\n",
    "            features['author_all_caps'] = 1 if author_name.isupper() else 0\n",
    "        else:\n",
    "            features['author_name_length'] = 0\n",
    "            features['author_has_numbers'] = 0\n",
    "            features['author_all_caps'] = 0\n",
    "        \n",
    "        # Business-based features\n",
    "        if 'business_name' in row:\n",
    "            business_name = str(row['business_name'])\n",
    "            features['business_name_length'] = len(business_name)\n",
    "        else:\n",
    "            features['business_name_length'] = 0\n",
    "        \n",
    "        # Photo presence\n",
    "        if 'photo' in row and pd.notna(row['photo']):\n",
    "            features['has_photo'] = 1\n",
    "        else:\n",
    "            features['has_photo'] = 0\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def extract_all_features(self, df):\n",
    "        \"\"\"Extract all features for the entire dataset\"\"\"\n",
    "        print(\"üîß Extracting features...\")\n",
    "        if not TEXTSTAT_AVAILABLE:\n",
    "            print(\"‚ö†Ô∏è Using fallback readability calculations (textstat not available)\")\n",
    "        \n",
    "        # üîç COLUMN NAME DETECTION AND VALIDATION\n",
    "        print(f\"üìã Available columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Find the text column dynamically\n",
    "        text_column = None\n",
    "        possible_text_columns = ['text', 'review_text', 'review', 'content', 'comment']\n",
    "        \n",
    "        for col in possible_text_columns:\n",
    "            if col in df.columns:\n",
    "                text_column = col\n",
    "                break\n",
    "        \n",
    "        if text_column is None:\n",
    "            raise ValueError(f\"‚ùå No text column found! Available columns: {list(df.columns)}\")\n",
    "        \n",
    "        print(f\"‚úÖ Using '{text_column}' as the text column\")\n",
    "        \n",
    "        all_features = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if idx % 1000 == 0:\n",
    "                print(f\"   Processing row {idx}/{len(df)}\")\n",
    "            \n",
    "            # Use the detected text column instead of hardcoded 'review_text'\n",
    "            text_features = self.extract_textual_features(row[text_column])\n",
    "            non_text_features = self.extract_non_textual_features(row)\n",
    "            \n",
    "            # Combine all features\n",
    "            combined_features = {**text_features, **non_text_features}\n",
    "            all_features.append(combined_features)\n",
    "        \n",
    "        features_df = pd.DataFrame(all_features)\n",
    "        print(f\"‚úÖ Feature extraction complete! Extracted {len(features_df.columns)} features\")\n",
    "        return features_df\n",
    "\n",
    "# Initialize feature extractor\n",
    "feature_extractor = AdvancedFeatureExtractor()\n",
    "\n",
    "# Extract features from the dataset\n",
    "features_df = feature_extractor.extract_all_features(df)\n",
    "\n",
    "# Combine with original data\n",
    "df_with_features = pd.concat([df.reset_index(drop=True), features_df], axis=1)\n",
    "\n",
    "print(f\"\\nüìä Dataset with features shape: {df_with_features.shape}\")\n",
    "print(f\"\\nüîç Feature columns extracted:\")\n",
    "for i, col in enumerate(features_df.columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "# Display feature statistics\n",
    "print(\"\\nüìà Feature Statistics Summary:\")\n",
    "print(features_df.describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff5045",
   "metadata": {},
   "source": [
    "## üö´ Policy Detection Module\n",
    "\n",
    "Implement rule-based and ML-based policy violation detectors for the three main categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "195e4d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Policy Violation Detection Results:\n",
      "==================================================\n",
      "\n",
      "üìù Review 1: 'Great food and excellent service! The pasta was am...'\n",
      "üö® Violation: False\n",
      "üí° Details: No violation detected\n",
      "\n",
      "üìù Review 2: 'Call us now for the best deals! Visit our website ...'\n",
      "üö® Violation: True\n",
      "üìã Type: advertisement\n",
      "üéØ Confidence: 0.333\n",
      "üìä All Scores: {'advertisement': 0.3333333333333333, 'irrelevant_content': 0, 'rant_without_visit': 0.0}\n",
      "üí° Details: Primary violation: advertisement\n",
      "\n",
      "üìù Review 3: 'I hate politics and this election is terrible. Not...'\n",
      "üö® Violation: False\n",
      "üí° Details: No violation detected\n",
      "\n",
      "üìù Review 4: 'I heard this place is awful, never been there but ...'\n",
      "üö® Violation: True\n",
      "üìã Type: rant_without_visit\n",
      "üéØ Confidence: 0.357\n",
      "üìä All Scores: {'advertisement': 0.0, 'irrelevant_content': 0, 'rant_without_visit': 0.35714285714285715}\n",
      "üí° Details: Primary violation: rant_without_visit\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import Dict, Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PolicyViolationDetector:\n",
    "    \"\"\"Rule-based policy violation detector for restaurant reviews\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Advertisement detection patterns\n",
    "        self.ad_patterns = [\n",
    "            r'\\b(?:call|text|contact|visit|website|phone|email|dm|message)\\s+(?:us|me|now|today)\\b',\n",
    "            r'\\b(?:best|cheapest|lowest|highest|top)\\s+(?:price|deal|offer|service)\\b',\n",
    "            r'\\b(?:free|discount|sale|promo|special|offer|deal)\\b.*\\b(?:today|now|limited|expires)\\b',\n",
    "            r'\\b(?:check|visit|see|follow)\\s+(?:our|my)\\s+(?:website|page|profile|instagram|facebook)\\b',\n",
    "            r'\\b(?:book|order|reserve)\\s+(?:now|today|online)\\b',\n",
    "            r'(?:www\\.|http|\\.com|\\.org|\\.net)',\n",
    "            r'\\b(?:delivery|takeout|pickup)\\s+(?:available|service)\\b',\n",
    "            r'\\b(?:new|grand)\\s+opening\\b',\n",
    "            r'\\b(?:hiring|recruiting|looking\\s+for)\\b'\n",
    "        ]\n",
    "        \n",
    "        # Irrelevant content patterns\n",
    "        self.irrelevant_patterns = [\n",
    "            r'\\b(?:politics|election|government|president|mayor|council)\\b',\n",
    "            r'\\b(?:religion|church|mosque|temple|spiritual)\\b',\n",
    "            r'\\b(?:personal|relationship|dating|marriage|divorce)\\b',\n",
    "            r'\\b(?:medical|health|doctor|hospital|surgery|medicine)\\b',\n",
    "            r'\\b(?:school|education|homework|exam|grade)\\b',\n",
    "            r'\\b(?:weather|rain|snow|sunny|cloudy)\\b',\n",
    "            r'\\b(?:sports|game|match|team|player|score)\\b',\n",
    "            r'\\b(?:movie|film|tv|show|actor|actress)\\b',\n",
    "            r'\\b(?:music|song|concert|band|album)\\b',\n",
    "            r'\\b(?:car|vehicle|traffic|parking|driving)\\b'\n",
    "        ]\n",
    "        \n",
    "        # Rant without visit patterns\n",
    "        self.rant_patterns = [\n",
    "            r'\\b(?:never\\s+(?:been|visited|went)|haven\\'t\\s+(?:been|visited))\\b',\n",
    "            r'\\b(?:heard|read|saw)\\s+(?:about|reviews|complaints)\\b',\n",
    "            r'\\b(?:based\\s+on|according\\s+to)\\s+(?:reviews|others|friends)\\b',\n",
    "            r'\\b(?:planning\\s+to|might|considering)\\s+(?:visit|go|try)\\b',\n",
    "            r'\\b(?:looks|seems|appears)\\s+(?:bad|terrible|awful|horrible)\\b',\n",
    "            r'\\b(?:reputation|known\\s+for)\\s+(?:being|having)\\b',\n",
    "            r'\\b(?:everyone\\s+says|people\\s+say|i\\'ve\\s+heard)\\b'\n",
    "        ]\n",
    "        \n",
    "        # Restaurant-related keywords (for relevance check)\n",
    "        self.restaurant_keywords = [\n",
    "            'food', 'meal', 'dish', 'restaurant', 'cafe', 'bar', 'service', 'waiter', 'waitress',\n",
    "            'menu', 'order', 'taste', 'flavor', 'delicious', 'cook', 'chef', 'kitchen',\n",
    "            'eat', 'dine', 'dining', 'lunch', 'dinner', 'breakfast', 'appetizer', 'dessert',\n",
    "            'drink', 'beverage', 'wine', 'beer', 'cocktail', 'table', 'reservation', 'staff'\n",
    "        ]\n",
    "    \n",
    "    def detect_advertisement(self, text: str) -> Tuple[bool, float, List[str]]:\n",
    "        \"\"\"Detect advertisement content\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        matches = []\n",
    "        score = 0\n",
    "        \n",
    "        for pattern in self.ad_patterns:\n",
    "            if re.search(pattern, text_lower):\n",
    "                matches.append(pattern)\n",
    "                score += 1\n",
    "        \n",
    "        # Normalize score\n",
    "        confidence = min(score / len(self.ad_patterns), 1.0)\n",
    "        is_ad = confidence > 0.3\n",
    "        \n",
    "        return is_ad, confidence, matches\n",
    "    \n",
    "    def detect_irrelevant_content(self, text: str) -> Tuple[bool, float, List[str]]:\n",
    "        \"\"\"Detect irrelevant content\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        matches = []\n",
    "        irrelevant_score = 0\n",
    "        relevant_score = 0\n",
    "        \n",
    "        # Check for irrelevant patterns\n",
    "        for pattern in self.irrelevant_patterns:\n",
    "            if re.search(pattern, text_lower):\n",
    "                matches.append(pattern)\n",
    "                irrelevant_score += 1\n",
    "        \n",
    "        # Check for restaurant relevance\n",
    "        for keyword in self.restaurant_keywords:\n",
    "            if keyword in text_lower:\n",
    "                relevant_score += 1\n",
    "        \n",
    "        # Calculate confidence\n",
    "        total_patterns = len(self.irrelevant_patterns)\n",
    "        if irrelevant_score > 0 and relevant_score == 0:\n",
    "            confidence = min(irrelevant_score / total_patterns, 1.0)\n",
    "            is_irrelevant = confidence > 0.2\n",
    "        else:\n",
    "            confidence = max(0, (irrelevant_score - relevant_score * 0.5) / total_patterns)\n",
    "            is_irrelevant = confidence > 0.3\n",
    "        \n",
    "        return is_irrelevant, max(confidence, 0), matches\n",
    "    \n",
    "    def detect_rant_without_visit(self, text: str) -> Tuple[bool, float, List[str]]:\n",
    "        \"\"\"Detect rants without actual visit\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        matches = []\n",
    "        score = 0\n",
    "        \n",
    "        for pattern in self.rant_patterns:\n",
    "            if re.search(pattern, text_lower):\n",
    "                matches.append(pattern)\n",
    "                score += 1\n",
    "        \n",
    "        # Additional checks for negative sentiment without visit indicators\n",
    "        negative_words = ['terrible', 'awful', 'horrible', 'worst', 'disgusting', 'hate']\n",
    "        visit_indicators = ['went', 'visited', 'ate', 'ordered', 'tried', 'had dinner', 'had lunch']\n",
    "        \n",
    "        has_negative = any(word in text_lower for word in negative_words)\n",
    "        has_visit = any(indicator in text_lower for indicator in visit_indicators)\n",
    "        \n",
    "        if has_negative and not has_visit:\n",
    "            score += 0.5\n",
    "        \n",
    "        # Normalize score\n",
    "        confidence = min(score / len(self.rant_patterns), 1.0)\n",
    "        is_rant = confidence > 0.3\n",
    "        \n",
    "        return is_rant, confidence, matches\n",
    "    \n",
    "    def analyze_review(self, text: str) -> Dict:\n",
    "        \"\"\"Comprehensive policy violation analysis\"\"\"\n",
    "        if not text or len(text.strip()) < 10:\n",
    "            return {\n",
    "                'is_violation': False,\n",
    "                'violation_type': None,\n",
    "                'confidence': 0.0,\n",
    "                'details': 'Text too short for analysis'\n",
    "            }\n",
    "        \n",
    "        # Run all detectors\n",
    "        is_ad, ad_conf, ad_matches = self.detect_advertisement(text)\n",
    "        is_irrelevant, irr_conf, irr_matches = self.detect_irrelevant_content(text)\n",
    "        is_rant, rant_conf, rant_matches = self.detect_rant_without_visit(text)\n",
    "        \n",
    "        # Determine primary violation\n",
    "        violations = [\n",
    "            ('advertisement', ad_conf, ad_matches),\n",
    "            ('irrelevant_content', irr_conf, irr_matches),\n",
    "            ('rant_without_visit', rant_conf, rant_matches)\n",
    "        ]\n",
    "        \n",
    "        violations.sort(key=lambda x: x[1], reverse=True)\n",
    "        primary_violation = violations[0]\n",
    "        \n",
    "        is_violation = primary_violation[1] > 0.3\n",
    "        \n",
    "        return {\n",
    "            'is_violation': is_violation,\n",
    "            'violation_type': primary_violation[0] if is_violation else None,\n",
    "            'confidence': primary_violation[1],\n",
    "            'all_scores': {\n",
    "                'advertisement': ad_conf,\n",
    "                'irrelevant_content': irr_conf,\n",
    "                'rant_without_visit': rant_conf\n",
    "            },\n",
    "            'matches': primary_violation[2] if is_violation else [],\n",
    "            'details': f\"Primary violation: {primary_violation[0]}\" if is_violation else \"No violation detected\"\n",
    "        }\n",
    "\n",
    "# Initialize policy detector\n",
    "policy_detector = PolicyViolationDetector()\n",
    "\n",
    "# Test with sample reviews\n",
    "test_reviews = [\n",
    "    \"Great food and excellent service! The pasta was amazing.\",\n",
    "    \"Call us now for the best deals! Visit our website www.example.com\",\n",
    "    \"I hate politics and this election is terrible. Nothing about food here.\",\n",
    "    \"I heard this place is awful, never been there but people say it's bad.\"\n",
    "]\n",
    "\n",
    "print(\"üîç Policy Violation Detection Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, review in enumerate(test_reviews, 1):\n",
    "    result = policy_detector.analyze_review(review)\n",
    "    print(f\"\\nüìù Review {i}: '{review[:50]}...'\")\n",
    "    print(f\"üö® Violation: {result['is_violation']}\")\n",
    "    if result['is_violation']:\n",
    "        print(f\"üìã Type: {result['violation_type']}\")\n",
    "        print(f\"üéØ Confidence: {result['confidence']:.3f}\")\n",
    "        print(f\"üìä All Scores: {result['all_scores']}\")\n",
    "    print(f\"üí° Details: {result['details']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758bcf29",
   "metadata": {},
   "source": [
    "## ü§ñ Gemma 3 12B Model Integration\n",
    "\n",
    "Using Google's Gemma 3 12B model with HuggingFace Inference Client for advanced policy detection and review classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb91c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Gemma 3 12B Classifier...\n",
      "üí° Note: You may need a HuggingFace token for full functionality\n",
      "‚úÖ Successfully initialized Gemma 3 12B model: google/gemma-3-12b-it\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "import os\n",
    "\n",
    "class GemmaReviewClassifier:\n",
    "    \"\"\"Advanced review classifier using Gemma 3 12B model\"\"\"\n",
    "    \n",
    "    def __init__(self, hf_token: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize Gemma classifier\n",
    "        \n",
    "        Args:\n",
    "            hf_token: HuggingFace token (optional, can be set in environment)\n",
    "        \"\"\"\n",
    "        self.model_name = \"google/gemma-3-12b-it\"\n",
    "        \n",
    "        # Set up HuggingFace token\n",
    "        if hf_token:\n",
    "            os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = hf_token\n",
    "        \n",
    "        try:\n",
    "            self.client = InferenceClient(\n",
    "                model=self.model_name,\n",
    "                token=hf_token or os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "            )\n",
    "            print(f\"‚úÖ Successfully initialized Gemma 3 12B model: {self.model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Could not initialize model. Error: {e}\")\n",
    "            print(\"üí° Note: You may need to provide a HuggingFace token or use a fallback model\")\n",
    "            self.client = None\n",
    "    \n",
    "    def create_policy_prompt(self, review_text: str) -> str:\n",
    "        \"\"\"Create a structured prompt for policy violation detection\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"You are an expert content moderator for restaurant review platforms. Analyze the following review and determine if it violates any of these policies:\n",
    "\n",
    "1. **Advertisement**: Reviews that promote businesses, include contact information, or solicit customers\n",
    "2. **Irrelevant Content**: Reviews about topics unrelated to the restaurant experience\n",
    "3. **Rant Without Visit**: Negative reviews from people who haven't actually visited the restaurant\n",
    "\n",
    "Review to analyze: \"{review_text}\"\n",
    "\n",
    "Please respond with a JSON object in this exact format:\n",
    "{{\n",
    "    \"is_violation\": true/false,\n",
    "    \"violation_type\": \"advertisement\" or \"irrelevant_content\" or \"rant_without_visit\" or null,\n",
    "    \"confidence\": 0.0-1.0,\n",
    "    \"reasoning\": \"Brief explanation of your decision\",\n",
    "    \"is_trustworthy\": true/false,\n",
    "    \"sentiment\": \"positive\" or \"negative\" or \"neutral\"\n",
    "}}\n",
    "\n",
    "Focus on:\n",
    "- Clear policy violations vs. legitimate reviews\n",
    "- Evidence of actual restaurant visit\n",
    "- Commercial intent vs. genuine feedback\n",
    "- Restaurant relevance vs. off-topic content\n",
    "\n",
    "Response:\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def create_quality_prompt(self, review_text: str) -> str:\n",
    "        \"\"\"Create a prompt for review quality assessment\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"As an expert in restaurant review quality assessment, evaluate this review for trustworthiness and usefulness:\n",
    "\n",
    "Review: \"{review_text}\"\n",
    "\n",
    "Assess the review on these dimensions:\n",
    "1. **Authenticity**: Does this seem like a genuine customer experience?\n",
    "2. **Specificity**: Does it provide specific details about food, service, or atmosphere?\n",
    "3. **Helpfulness**: Would this review help other customers make decisions?\n",
    "4. **Balance**: Does it provide constructive feedback rather than just complaints?\n",
    "\n",
    "Respond with JSON:\n",
    "{{\n",
    "    \"quality_score\": 0.0-1.0,\n",
    "    \"authenticity\": 0.0-1.0,\n",
    "    \"specificity\": 0.0-1.0,\n",
    "    \"helpfulness\": 0.0-1.0,\n",
    "    \"is_spam\": true/false,\n",
    "    \"is_fake\": true/false,\n",
    "    \"key_insights\": [\"insight1\", \"insight2\"],\n",
    "    \"recommendation\": \"keep\" or \"flag\" or \"remove\"\n",
    "}}\n",
    "\n",
    "Response:\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def classify_review(self, review_text: str, max_retries: int = 3) -> Dict:\n",
    "        \"\"\"Classify a review for policy violations and quality\"\"\"\n",
    "        \n",
    "        if not self.client:\n",
    "            return {\n",
    "                \"error\": \"Model not available\",\n",
    "                \"fallback\": \"Using rule-based detection only\"\n",
    "            }\n",
    "        \n",
    "        if not review_text or len(review_text.strip()) < 5:\n",
    "            return {\n",
    "                \"error\": \"Review text too short\",\n",
    "                \"is_violation\": False,\n",
    "                \"quality_score\": 0.0\n",
    "            }\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Policy violation detection\n",
    "        try:\n",
    "            policy_prompt = self.create_policy_prompt(review_text)\n",
    "            \n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    policy_response = self.client.text_generation(\n",
    "                        policy_prompt,\n",
    "                        max_new_tokens=200,\n",
    "                        temperature=0.1,\n",
    "                        do_sample=True,\n",
    "                        return_full_text=False\n",
    "                    )\n",
    "                    \n",
    "                    # Parse JSON response\n",
    "                    policy_data = self._parse_json_response(policy_response)\n",
    "                    if policy_data:\n",
    "                        results['policy'] = policy_data\n",
    "                        break\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    if attempt == max_retries - 1:\n",
    "                        results['policy_error'] = str(e)\n",
    "                    time.sleep(1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            results['policy_error'] = str(e)\n",
    "        \n",
    "        # Quality assessment\n",
    "        try:\n",
    "            quality_prompt = self.create_quality_prompt(review_text)\n",
    "            \n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    quality_response = self.client.text_generation(\n",
    "                        quality_prompt,\n",
    "                        max_new_tokens=200,\n",
    "                        temperature=0.1,\n",
    "                        do_sample=True,\n",
    "                        return_full_text=False\n",
    "                    )\n",
    "                    \n",
    "                    # Parse JSON response\n",
    "                    quality_data = self._parse_json_response(quality_response)\n",
    "                    if quality_data:\n",
    "                        results['quality'] = quality_data\n",
    "                        break\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    if attempt == max_retries - 1:\n",
    "                        results['quality_error'] = str(e)\n",
    "                    time.sleep(1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            results['quality_error'] = str(e)\n",
    "        \n",
    "        return self._consolidate_results(results)\n",
    "    \n",
    "    def _parse_json_response(self, response: str) -> Optional[Dict]:\n",
    "        \"\"\"Parse JSON from model response\"\"\"\n",
    "        try:\n",
    "            # Find JSON in response\n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                json_str = response[start_idx:end_idx]\n",
    "                return json.loads(json_str)\n",
    "            \n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response: {response[:200]}...\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _consolidate_results(self, results: Dict) -> Dict:\n",
    "        \"\"\"Consolidate policy and quality results\"\"\"\n",
    "        \n",
    "        consolidated = {\n",
    "            'timestamp': time.time(),\n",
    "            'model_used': self.model_name\n",
    "        }\n",
    "        \n",
    "        # Policy results\n",
    "        if 'policy' in results:\n",
    "            policy = results['policy']\n",
    "            consolidated.update({\n",
    "                'is_violation': policy.get('is_violation', False),\n",
    "                'violation_type': policy.get('violation_type'),\n",
    "                'policy_confidence': policy.get('confidence', 0.0),\n",
    "                'is_trustworthy': policy.get('is_trustworthy', True),\n",
    "                'sentiment': policy.get('sentiment', 'neutral'),\n",
    "                'policy_reasoning': policy.get('reasoning', '')\n",
    "            })\n",
    "        else:\n",
    "            consolidated.update({\n",
    "                'is_violation': False,\n",
    "                'violation_type': None,\n",
    "                'policy_confidence': 0.0,\n",
    "                'policy_error': results.get('policy_error', 'Unknown error')\n",
    "            })\n",
    "        \n",
    "        # Quality results\n",
    "        if 'quality' in results:\n",
    "            quality = results['quality']\n",
    "            consolidated.update({\n",
    "                'quality_score': quality.get('quality_score', 0.5),\n",
    "                'authenticity': quality.get('authenticity', 0.5),\n",
    "                'specificity': quality.get('specificity', 0.5),\n",
    "                'helpfulness': quality.get('helpfulness', 0.5),\n",
    "                'is_spam': quality.get('is_spam', False),\n",
    "                'is_fake': quality.get('is_fake', False),\n",
    "                'key_insights': quality.get('key_insights', []),\n",
    "                'recommendation': quality.get('recommendation', 'keep')\n",
    "            })\n",
    "        else:\n",
    "            consolidated.update({\n",
    "                'quality_score': 0.5,\n",
    "                'quality_error': results.get('quality_error', 'Unknown error')\n",
    "            })\n",
    "        \n",
    "        return consolidated\n",
    "    \n",
    "    def batch_classify(self, reviews: List[str], batch_size: int = 5) -> List[Dict]:\n",
    "        \"\"\"Classify multiple reviews in batches\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i in range(0, len(reviews), batch_size):\n",
    "            batch = reviews[i:i + batch_size]\n",
    "            print(f\"üîÑ Processing batch {i//batch_size + 1}/{(len(reviews)-1)//batch_size + 1}\")\n",
    "            \n",
    "            batch_results = []\n",
    "            for review in batch:\n",
    "                result = self.classify_review(review)\n",
    "                batch_results.append(result)\n",
    "                time.sleep(0.5)  # Rate limiting\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize Gemma classifier\n",
    "print(\"üöÄ Initializing Gemma 3 12B Classifier...\")\n",
    "print(\"üí° Note: You may need a HuggingFace token for full functionality\")\n",
    "\n",
    "# For Colab users, uncomment and add your token:\n",
    "# gemma_classifier = GemmaReviewClassifier(hf_token=\"your_hf_token_here\")\n",
    "\n",
    "# For token-less testing:\n",
    "try:\n",
    "    gemma_classifier = GemmaReviewClassifier()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not initialize Gemma model: {e}\")\n",
    "    print(\"üîÑ Continuing with rule-based detection only...\")\n",
    "    gemma_classifier = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c4fcfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ü§ñ SAMPLE REVIEW CLASSIFICATION - 200 REVIEWS\n",
      "======================================================================\n",
      "üß™ Testing JSONL parsing on your review-other.json file...\n",
      "‚úÖ Successfully parsed sample data:\n",
      "üìä Shape: (5, 8)\n",
      "üìã Original columns: ['user_id', 'name', 'time', 'rating', 'text', 'pics', 'resp', 'gmap_id']\n",
      "üßπ Applying Kaggle-style cleaning to DataFrame with columns: ['user_id', 'name', 'time', 'rating', 'text', 'pics', 'resp', 'gmap_id']\n",
      "üßπ Cleaned dataset: 5 ‚Üí 5 rows (removed 0)\n",
      "‚úÖ Cleaned sample:\n",
      "üìä Shape: (5, 6)\n",
      "üìã Columns: ['text', 'rating', 'business_name', 'author_name', 'photo', 'rating_category']\n",
      "üîç First few rows:\n",
      "                                                text  rating    business_name  \\\n",
      "0  Andrea is amazing. Our dog loves her and she a...       5  Amber Thibeault   \n",
      "1  Andrea does a wonderful  job  with our wild Pr...       5           Esther   \n",
      "2                                  Never called back       1      Bob Barrett   \n",
      "\n",
      "  author_name photo rating_category  \n",
      "0      user_0  <NA>            <NA>  \n",
      "1      user_1  <NA>            <NA>  \n",
      "2      user_2  <NA>            <NA>  \n",
      "üìÇ Searching for additional review datasets...\n",
      "üîÑ Attempting to load ./review-other.json...\n",
      "üìÑ Detected JSONL format (JSON Lines) - parsing line by line...\n",
      "‚úÖ Successfully parsed 162952 JSON objects from JSONL file\n",
      "‚úÖ Created DataFrame with 162952 rows and 8 columns\n",
      "üìã Original columns: ['user_id', 'name', 'time', 'rating', 'text', 'pics', 'resp', 'gmap_id']\n",
      "üßπ Applying Kaggle-style cleaning to DataFrame with columns: ['user_id', 'name', 'time', 'rating', 'text', 'pics', 'resp', 'gmap_id']\n",
      "üßπ Cleaned dataset: 162952 ‚Üí 105249 rows (removed 57703)\n",
      "‚ÑπÔ∏è File not found: ./Google Local review data.html\n",
      "üîÑ Merging 1 additional datasets with Kaggle data...\n",
      "   Adding dataset 1/1 with 145320 rows\n",
      "üìä Merged dataset statistics:\n",
      "   Total reviews: 95495\n",
      "   Kaggle reviews: 1100\n",
      "   Additional reviews: 94395\n",
      "   Duplicates removed: 50925\n",
      "üéØ Sampling 200 reviews from 95495 total reviews...\n",
      "üìä Final sample size: 200 reviews\n",
      "üìã Final columns: ['business_name', 'author_name', 'text', 'rating', 'photo', 'rating_category']\n",
      "üìù Using 'text' column for review text\n",
      "\n",
      "üìä SAMPLE DATASET INFORMATION:\n",
      "   Total reviews for processing: 200\n",
      "   Columns: ['business_name', 'author_name', 'text', 'rating', 'photo', 'rating_category']\n",
      "   Rating distribution: {1.0: np.int64(15), 2.0: np.int64(2), 3.0: np.int64(9), 4.0: np.int64(17), 5.0: np.int64(157)}\n",
      "\n",
      "üîç Sample of data:\n",
      "   1. Rating: 5.0 | Text: Awsome gifts\n",
      "   2. Rating: 5.0 | Text: Love the history and experience!\n",
      "   3. Rating: 5.0 | Text: Great company for people that are really trying to get their life together..\n",
      "   4. Rating: 5.0 | Text: I live in Georgia but own a property in Northeast Illinois. Ryan worked with me from a distance with...\n",
      "   5. Rating: 5.0 | Text: Excellent quality and the price isn‚Äôt too bad.\n",
      "\n",
      "üîÑ Processing 200 reviews with Gemma classifier...\n",
      "üö® RESULTS (Text + Labels):\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #1: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Awsome gifts\"\n",
      "\n",
      "üìù Review #2: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Love the history and experience!\"\n",
      "\n",
      "üìù Review #3: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great company for people that are really trying to get their life together..\"\n",
      "\n",
      "üìù Review #4: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I live in Georgia but own a property in Northeast Illinois. Ryan worked with me from a distance with a mouse problem we were having. He was reliable, ...\"\n",
      "\n",
      "üìù Review #5: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Excellent quality and the price isn‚Äôt too bad.\"\n",
      "\n",
      "üìù Review #6: LEGITIMATE\n",
      "‚≠ê Rating: 3.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Decent selection of food. Staff was sort of friendly. I don't remember seeing my waiter much. It was an interesting experience to say the least. Food ...\"\n",
      "\n",
      "üìù Review #7: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Incredible customer service. I‚Äôve ordered a couple of swimsuits and dresses from this site. I recently ordered a jumper for my daughter and I to match...\"\n",
      "\n",
      "üìù Review #8: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Cool little coffee shop!\"\n",
      "\n",
      "üìù Review #9: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"A less visited sight,  but very neat. If you are walking from the Washington monument over to Lincoln, I'd recommend it. It's lovely, we had a small l...\"\n",
      "\n",
      "üìä Progress: 10/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #10: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"The clothes are well- made. Especially the ones I bought that are for winter ( very thick and has 80% cotton) This is my first time buying from them a...\"\n",
      "\n",
      "üìù Review #11: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Awesome experience to work with\n",
      "Would do it again\n",
      "\n",
      "And the character did amazing everyone loved him\"\n",
      "\n",
      "üìù Review #12: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) Lots of variety of products and great price. To highlight above all the excellent customer service (in our case from the hand o...\"\n",
      "\n",
      "üìù Review #13: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Easy to book online. Quick response. Included a free (download) guide to Rome. I look forward to traveling on ItaliaRail.\"\n",
      "\n",
      "üìù Review #14: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Needed some advice on how to insulate my commercial roll up door and they were right on it!  Very helpful!\"\n",
      "\n",
      "üìù Review #15: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Yeah the food is not that great and it takes forever to arrive. They say 25 minutes but you may wait until the 2nd coming, or until you hit menopause....\"\n",
      "\n",
      "üìù Review #16: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Wonderful menu, excellent service, and who doesn't love a glass waterfall?\"\n",
      "\n",
      "üìù Review #17: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Very polite and quick solution of my requestüòâüëç\"\n",
      "\n",
      "üìù Review #18: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Used Bellhop for an out of state move to D.C. After getting quotes and reading reviews for 4 companies, Bellhop was the most affordable and most consi...\"\n",
      "\n",
      "üìù Review #19: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Shakari led us through historical and geographical insights about the recipe we were cooking and then easily led us into the preparation of the meal, ...\"\n",
      "\n",
      "üìä Progress: 20/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #20: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"First I want to say that the assistance and support I received, particularly as a new customer from ADM and from the owner and founder, Mr. Anthony Da...\"\n",
      "\n",
      "üìù Review #21: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"The best place in DC by far.  It's charming , beautiful gardens and walkways.\"\n",
      "\n",
      "üìù Review #22: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Amazing place!!!\"\n",
      "\n",
      "üìù Review #23: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Historical place\"\n",
      "\n",
      "üìù Review #24: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great service. Use weekly\"\n",
      "\n",
      "üìù Review #25: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Best udon in Paris. Well Korean celebrities visits it too. Just a little bit crowded.\"\n",
      "\n",
      "üìù Review #26: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Susie B was so helpful with my exchange. She was pleasant, efficient and fast in her response. I love PatPat clothes for my grand babies. The clothes ...\"\n",
      "\n",
      "üìù Review #27: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Hockey!!!!!!\"\n",
      "\n",
      "üìù Review #28: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Easy order. Took a little bit to get but the communication was great. When I received my order I was thrilled. 3 custom necklaces all perfect and I lo...\"\n",
      "\n",
      "üìù Review #29: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I love it, it was crowded\"\n",
      "\n",
      "üìä Progress: 30/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #30: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Jonny Wu is amazing! Best show ever!\"\n",
      "\n",
      "üìù Review #31: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Love the view.  Very unique\"\n",
      "\n",
      "üìù Review #32: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I found everything I needed. Staff were helpful and considerate!!\"\n",
      "\n",
      "üìù Review #33: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Their work is amazing!!! Thank you!!\"\n",
      "\n",
      "üìù Review #34: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"fast and friendly no scams here removed the account that i forgot the info for   it and now its good to use..\"\n",
      "\n",
      "üìù Review #35: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"They went out of their way to help me with my car out of their usual area of service on New YEARS Eve! I am so grateful and pleased with the service t...\"\n",
      "\n",
      "üìù Review #36: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Clyde's has been a favorite of mine for years.\"\n",
      "\n",
      "üìù Review #37: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Very good training. The devil is in the detail and Bradley goes into great detail at a wonderful pace. Thoroughly recommend!\"\n",
      "\n",
      "üìù Review #38: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"This guys are great! I called with an Amazon Issue and they told me to not hire anybody yet and to not spend money in something that could affect me. ...\"\n",
      "\n",
      "üìù Review #39: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"This was the first time using movers and I'm glad I went with Bellhops! Yann, Nicholas, and Joshua were quick and efficient. They really hustled even ...\"\n",
      "\n",
      "üìä Progress: 40/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #40: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I'm so glad I came upon this site. They had so many options and were flexible in their wording options. I decided not to pay for some of the embellish...\"\n",
      "\n",
      "üìù Review #41: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Pretty cool place to watch the planes take off. Free parking. Toilets on site are dirty. Use the bathroom before you go here.\"\n",
      "\n",
      "üìù Review #42: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Hazel provides excellent customer services.\"\n",
      "\n",
      "üìù Review #43: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Good amount of food choices, seating is nice\"\n",
      "\n",
      "üìù Review #44: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Jerell and his team were super awesome! I'm new to lawn care and landscaping and Jerell was super patient in answering all of my questions (regardless...\"\n",
      "\n",
      "üìù Review #45: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Had a great time at Prayer March 2020\"\n",
      "\n",
      "üìù Review #46: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Wasn‚Äôt sure if it was legit because I couldn‚Äôt find that many reviews but rest assured they got the goods and I am so glad :)\"\n",
      "\n",
      "üìù Review #47: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Had a great experience with Air Control LLC. The technician was running late b/c of traffic and was super apologetic when he arrives. Overall, the tec...\"\n",
      "\n",
      "üìù Review #48: LEGITIMATE\n",
      "‚≠ê Rating: 3.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) Nicely at Potomac\n",
      "\n",
      "(Original)\n",
      "Pent ved Potomac\"\n",
      "\n",
      "üìù Review #49: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Very fast and helpful customer service. Jayson was friendly and efficient in handling my return items. I bought a suze to big. I will be but I more fo...\"\n",
      "\n",
      "üìä Progress: 50/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #50: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Nick is very thorough  and honest\n",
      "Thanks for a great  inspection.\"\n",
      "\n",
      "üìù Review #51: LEGITIMATE\n",
      "‚≠ê Rating: 2.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"On my 3rd device in just a little over a month... first one didn‚Äôt hit right every time and i exchanged it where i got it. The second lasted a little ...\"\n",
      "\n",
      "üìù Review #52: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"The absolute best show ever.  We want to see him again and again.\"\n",
      "\n",
      "üìù Review #53: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great service and smooth process for ordering a new surfboard. For a long time I was looking for a store online where I can purchase my first board, b...\"\n",
      "\n",
      "üìù Review #54: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Super happy with these guys. I've wanted to join them for many years and now that I have, I couldn't imagine going anywhere else. They are like your m...\"\n",
      "\n",
      "üìù Review #55: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Very good selection of dishes insensible portion sizes.\"\n",
      "\n",
      "üìù Review #56: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I have recently purchased matching Christmas pyjamas for my whole family from this site, have to be honest was a little sceptical about products but w...\"\n",
      "\n",
      "üìù Review #57: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Good results. Price was very reasonable. Will recommend to others.\"\n",
      "\n",
      "üìù Review #58: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Better version of Chipotle.\"\n",
      "\n",
      "üìù Review #59: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I‚Äôve used this place multiple times and it is always a breeze. Exactly what you ask for. They are very good, fast, and reliable. U will use them again...\"\n",
      "\n",
      "üìä Progress: 60/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #60: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"great product.  Love the erformance\"\n",
      "\n",
      "üìù Review #61: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I called 2 days before our event and they where able to provide me with what I needed. Customer service was awesome as well and I would definitely use...\"\n",
      "\n",
      "üìù Review #62: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Good customer Service. Rachel solved our request promptly.\"\n",
      "\n",
      "üìù Review #63: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"A little slower than I expected, but the customer service was great! Order shipped within a week.\"\n",
      "\n",
      "üìù Review #64: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Increased my business into a lot of customers. Thankfully we found them saved my business. ü§óü§©\"\n",
      "\n",
      "üìù Review #65: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Really gorgeous decor and ambient was magnificent.  Bathroom on the second floor with a crazy loopy stairs a big minus but there's an elevator.  Resta...\"\n",
      "\n",
      "üìù Review #66: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"It is a very well kept site. I was honored to pay my respect to President Lincoln in visiting the home where he passed away.\"\n",
      "\n",
      "üìù Review #67: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"On time, professional, expert and quick.\"\n",
      "\n",
      "üìù Review #68: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Excellent work.  They are extremely nice and  friendly.  They are also accommodating with schedules for busy families.\"\n",
      "\n",
      "üìù Review #69: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) Quality\n",
      "\n",
      "(Original)\n",
      "Calidad\"\n",
      "\n",
      "üìä Progress: 70/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #70: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I had ordered in January and the payment has been done too..but still I haven't received my parcel.. People Please don't take risk buying here...they ...\"\n",
      "\n",
      "üìù Review #71: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Thoroughly enjoyed the Crimes and Scandals Tour of Embassy Row with Rebecca! Learned a ton of interesting facts and enjoyed her awesome personality. C...\"\n",
      "\n",
      "üìù Review #72: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I normally don't rate any business very harshly but this one deserves it. I will let others make their own judgement to visit or not. I did visit base...\"\n",
      "\n",
      "üìù Review #73: LEGITIMATE\n",
      "‚≠ê Rating: 3.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Very expensive and not a lot to offer\"\n",
      "\n",
      "üìù Review #74: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) Tasty tasty!!\n",
      "\n",
      "(Original)\n",
      "Rico rico!!\"\n",
      "\n",
      "üìù Review #75: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Absolutely amazing. Has helped me to grow as a new artist, person, and woman. I am immensely grateful for your love for art and teaching, who you are,...\"\n",
      "\n",
      "üìù Review #76: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"The software is incredibly easy use, even as someone that does not have any experience.  The team is there to support you if needed but have designed ...\"\n",
      "\n",
      "üìù Review #77: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"The product was exceptional!! The shipping was so fast I was shocked to see it on my doorstep. Thank you!!\"\n",
      "\n",
      "üìù Review #78: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Awesome food. CJ is the man. Get greens and the brisket!\"\n",
      "\n",
      "üìù Review #79: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Amazing costumer service! I ordered a few parts that were lost in transit. They took care of the problem right away. Which we actually received the or...\"\n",
      "\n",
      "üìä Progress: 80/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #80: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"As Always I Love This Sight For My Baby I‚Äôm Always Ordering Clothes... I Wanted To Get The Matching Christmas Pajamas For Pictures And What I Ordered ...\"\n",
      "\n",
      "üìù Review #81: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"very convenient for people to have a place to work with other business partners.   great to know this type of hotel to stay. will use this service mor...\"\n",
      "\n",
      "üìù Review #82: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Awesome tacos\"\n",
      "\n",
      "üìù Review #83: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Highly recommend, real fun virtual team outing!\"\n",
      "\n",
      "üìù Review #84: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"They are the best source of information for all things Amazon!  After a full year of trying to get my Amazon account back.  I called them last weeek a...\"\n",
      "\n",
      "üìù Review #85: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I just had a really bad experience with this eatery! Ordered food from here and the jollof rice arrived dead cold,  stale, and hopelessly unappealing!...\"\n",
      "\n",
      "üìù Review #86: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I did the White House at Night Scandals tour. Our guide Boglarka was great! She was really funny and knowledgeable. She was open to questions. She gav...\"\n",
      "\n",
      "üìù Review #87: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"This was overall a great experience. I came across Jungle Blunts on YouTube. I then placed a order and received them a lot soon these expected. I proc...\"\n",
      "\n",
      "üìù Review #88: LEGITIMATE\n",
      "‚≠ê Rating: 3.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"It's ok, but huge lines.\"\n",
      "\n",
      "üìù Review #89: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"This is the spot for all of your surfing needs.  They have all the selection, the best prices and are just cool to chat with. Board cave is also build...\"\n",
      "\n",
      "üìä Progress: 90/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #90: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Good drinks, good food...not very authentic Thai food though. The customer service was exceptional.\"\n",
      "\n",
      "üìù Review #91: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Delicious barbecue in a great location! Great quality meats and creative side options. Tons of seating with friendly service. Will definitely be back ...\"\n",
      "\n",
      "üìù Review #92: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Intimate dining with wonderful small plates representative of the street food found in countries across the world. Really well done.\"\n",
      "\n",
      "üìù Review #93: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Massive and awesome monument\"\n",
      "\n",
      "üìù Review #94: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Friendly staff, quick service, cash only, and as you would expect, tasty diner breakfast! Their description says it right, \"no frills!\"\"\n",
      "\n",
      "üìù Review #95: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Had so much fun and such a great workout!!\"\n",
      "\n",
      "üìù Review #96: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Food is EXCELLENT and people are awesome.\"\n",
      "\n",
      "üìù Review #97: LEGITIMATE\n",
      "‚≠ê Rating: 3.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"They alright just because\"\n",
      "\n",
      "üìù Review #98: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great service, thank you again.\"\n",
      "\n",
      "üìù Review #99: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) Thanks Rachel for your good management and great service! I recommend this page to buy, great attention!\n",
      "\n",
      "(Original)\n",
      "Gracias Ra...\"\n",
      "\n",
      "üìä Progress: 100/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #100: LEGITIMATE\n",
      "‚≠ê Rating: 3.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Food--AMAZING.  Got the something something sampler, everything DELICIOUS!  Staff was awesome and very knowledgeable and the food was ready in a SNAP!...\"\n",
      "\n",
      "üìù Review #101: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Wonderful scenery, exquisite food options and calming atmosphere. However the rodent control must be amped up.\"\n",
      "\n",
      "üìù Review #102: LEGITIMATE\n",
      "‚≠ê Rating: 3.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"They need to improve how people leave. Thousands of people trying to use a few escalators is dangerous. There was almost a trample incident last time ...\"\n",
      "\n",
      "üìù Review #103: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Didn't come when said! Mad if you don't buy off their overpriced truck. Technicians wonderful but boss had no customer service.\"\n",
      "\n",
      "üìù Review #104: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"East Meets Dress exceeded my expectations! I was so anxious about trying to find a cheongsam and making sure that it actually fits! They custom made m...\"\n",
      "\n",
      "üìù Review #105: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"When I read about the ingredients in Nutra Thrive, I decided that it might be beneficial for our aging 16 year-old Orange Tabby, Casanova. We have bee...\"\n",
      "\n",
      "üìù Review #106: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"The Lincoln, a very iconic monument. People come from all parts of the world to see it. I think it's very cool and very well done. Don't forget to exp...\"\n",
      "\n",
      "üìù Review #107: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Absolutely genius. Lucky to find people who are so dedicated to making other people's lives easier.\"\n",
      "\n",
      "üìù Review #108: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great company, great products\"\n",
      "\n",
      "üìù Review #109: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"If you're looking to build a web presence for your business this is the place to go. These guys are pros at digital marketing from websites to social ...\"\n",
      "\n",
      "üìä Progress: 110/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #110: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Capitals\"\n",
      "\n",
      "üìù Review #111: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"We entered parking lot B early Friday morning to catch our 8am flight. It was still dark out and there was very little lighting. The entrance into par...\"\n",
      "\n",
      "üìù Review #112: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"It's ok\"\n",
      "\n",
      "üìù Review #113: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I recommend Throtl, I got my Oil Catch can in less than 2 days. Awesome quality and great prices\"\n",
      "\n",
      "üìù Review #114: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"100% worth a visit.  It's best to let everyone order two small platers and then everyone shares what arrives.  Most food comes out quickly so it's eas...\"\n",
      "\n",
      "üìù Review #115: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Friendly staff and excellent service! They upgraded my computer to have an SSD and I couldn't be happier. 10/10 would recommend.\"\n",
      "\n",
      "üìù Review #116: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great tour that you should not miss in D.C.  Remember to book online, tons of guests, and the small exhibition in the back in interesting.\"\n",
      "\n",
      "üìù Review #117: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I have been having ornaments with love  make individualized ornaments for my five grandchildren and my pets for at least 12 years. The ornaments are a...\"\n",
      "\n",
      "üìù Review #118: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great food, ambiance, prices\"\n",
      "\n",
      "üìù Review #119: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"The booking site is great. Easy and quick. The step by step approach is quite clear and all options are easily displayed.\"\n",
      "\n",
      "üìä Progress: 120/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #120: LEGITIMATE\n",
      "‚≠ê Rating: 3.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"The web site is easy to use and I got the reservation made that I needed.  My biggest issue is that you cannot use this web site to make reservations ...\"\n",
      "\n",
      "üìù Review #121: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Incredible place..always!!!\"\n",
      "\n",
      "üìù Review #122: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"excellent!\"\n",
      "\n",
      "üìù Review #123: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Brad delivers material in a clear and straightforward method. He cares about the end result.\"\n",
      "\n",
      "üìù Review #124: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"DJ Christian was great! Thank you, Nice Entertainment, for taking the time to come DJ our preschool dance. The kids (and parents) loved it!\"\n",
      "\n",
      "üìù Review #125: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Good food, good environment GREAT location. Parking is a nightmare so Uber or Lyft if you can otherwise prepare to drive around for a while. Most near...\"\n",
      "\n",
      "üìù Review #126: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great low monthly payments\"\n",
      "\n",
      "üìù Review #127: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Clean, well run, on time.\"\n",
      "\n",
      "üìù Review #128: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Delicious bbq-weighed by the pound\"\n",
      "\n",
      "üìù Review #129: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I don't normally leave reviews, but Rose Farmers roses and customer service was so exemplary I had to give them 5 stars and share my experience. I ord...\"\n",
      "\n",
      "üìä Progress: 130/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #130: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Being able to have a reliable social presence is key! Highly recommended!\"\n",
      "\n",
      "üìù Review #131: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Has my five star. Top notch. Historic.\"\n",
      "\n",
      "üìù Review #132: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) Friendly, typical USA cuisine, good local craft beers (some too rare). Much atmosphere and lively\n",
      "\n",
      "(Original)\n",
      "Amables, t√≠pica c...\"\n",
      "\n",
      "üìù Review #133: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) Hello, I just moved from San Ysidro to Tijuana. Very fast indeed. Previously, when going from Mexico to the USA, I bought a rou...\"\n",
      "\n",
      "üìù Review #134: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Nice guys and effective. Couple of visits and the problem was resolved.\"\n",
      "\n",
      "üìù Review #135: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"A little loud, but the pork belly, pork loin, and greens were excellent.\"\n",
      "\n",
      "üìù Review #136: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"What to say, so many things. In a word \"Beautiful \" you have to see it.\"\n",
      "\n",
      "üìù Review #137: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) I love all the products, especially the rejuvenating oil because it has many uses, I use it in everything such as hair dye, mas...\"\n",
      "\n",
      "üìù Review #138: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Customer service is top notch Kuenzler went above and beyond to ensure I was satisfied with a replacement order. And the clothes are super cute.\"\n",
      "\n",
      "üìù Review #139: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"excellent food, very articulate and polite stuff. Fantastic place. Need to reserve.\"\n",
      "\n",
      "üìä Progress: 140/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #140: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Best quality products I have found to date.  Extremely fast shipping and excellent customer support.  You can really care LGB cares about their custom...\"\n",
      "\n",
      "üìù Review #141: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"A place to give your respects to those who have given their lives for others...many thanks to the police unity tour riders and the public who helps ke...\"\n",
      "\n",
      "üìù Review #142: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Played on someone else's server, and the quality was amazing, even with a bunch of people on. I just wish Minecraft server hosting had a free tier.\"\n",
      "\n",
      "üìù Review #143: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"As an IMG hoping to match into a residency program, I came across MD2B Connect during my search for externships. I reached out to Manish and I was giv...\"\n",
      "\n",
      "üìù Review #144: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Very popular place and sort of hard to get a good photo without getting photo bombed\"\n",
      "\n",
      "üìù Review #145: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"will use this facility from now on. air fare as well as travel time to Mexican destination is half of San Diego airport departure. signage from Tijuan...\"\n",
      "\n",
      "üìù Review #146: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Went to the Wizards game, I suggest you eat before you go. The food and drink prices are worst than an amusement park. However, the facility was very ...\"\n",
      "\n",
      "üìù Review #147: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Very good experience.  Worked with these guys to remove a large tree at a rental property.  Efficient, reasonably priced, and easy to work with, would...\"\n",
      "\n",
      "üìù Review #148: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Mr. Kim is the best tailor in Washington, DC.  Excellent service and great care.  Always a kind word and his work is impeccable.  I have never seen hi...\"\n",
      "\n",
      "üìù Review #149: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"It's easy to stop quickly to drop off and pick someone up.\"\n",
      "\n",
      "üìä Progress: 150/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #150: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"At first I was sceptical about the site and ordering but  I was pretty amazed with the prompt and effective delivery process. My package came safe and...\"\n",
      "\n",
      "üìù Review #151: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Ticketbud was recommended to me (after I expressed some dissatisfaction with the terms and conditions of Eventbrite) and I have not been disappointed ...\"\n",
      "\n",
      "üìù Review #152: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Monumental place with strong energy, inpressive view all around, lot of people of different nationalities and different age. Nice to spend time when w...\"\n",
      "\n",
      "üìù Review #153: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Amazing! Still can‚Äôt believe all the stuff that happened.\"\n",
      "\n",
      "üìù Review #154: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Nonstop harassing calls, ignore removal request. Spoof different numbers daily!\"\n",
      "\n",
      "üìù Review #155: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"So much variety! There‚Äôs always a good deal to be found!\"\n",
      "\n",
      "üìù Review #156: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Stephanie has been mentoring me since 2015. She has helped me with my resume, getting my foot in the door with my very first corporate job, and interv...\"\n",
      "\n",
      "üìù Review #157: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great shoes!!! Comfortable and seem to be durable!! Loving these shoes so far!\"\n",
      "\n",
      "üìù Review #158: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great facility and everyone was extremely friendly and helpful!\"\n",
      "\n",
      "üìù Review #159: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Don't even think about dealing with this company. I ordered my suspension from throtl back in march 29 and till this day I have not received any updat...\"\n",
      "\n",
      "üìä Progress: 160/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #160: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"She gave me so much relief after talking to my beloved dog on the other side.\"\n",
      "\n",
      "üìù Review #161: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great concerts!\"\n",
      "\n",
      "üìù Review #162: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Perfect place for concerts\"\n",
      "\n",
      "üìù Review #163: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Bought a pair of pro taper handle bar risers . they showed up in my mailbox from USPS the package was opened up with just the tags left in it. There w...\"\n",
      "\n",
      "üìù Review #164: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Love the refills on popcorn!\"\n",
      "\n",
      "üìù Review #165: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"From the very first time I called, I felt like I was dealing with a professional organization and that all of my questions would be answered properly....\"\n",
      "\n",
      "üìù Review #166: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"This is a very good website and there customer service is very responsive and I give them 5 star...and there products are of good quality and not pric...\"\n",
      "\n",
      "üìù Review #167: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Do not hesitate to call Rosenbaum Famularo, P.C. for help with you Amazon business issues!  So happy I found them. They are now my go-to attorneys for...\"\n",
      "\n",
      "üìù Review #168: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Very touching. Loved every minute of it.\"\n",
      "\n",
      "üìù Review #169: LEGITIMATE\n",
      "‚≠ê Rating: 3.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"They have a problem with the service; but if you're going to drink tea; they do it well. Your tea is always hot over the fire.\"\n",
      "\n",
      "üìä Progress: 170/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #170: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"RoseFarmers is an outstanding, #1 company you must visit online and see the collection yourself! These Rose-growing experts and breeders hand pick the...\"\n",
      "\n",
      "üìù Review #171: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Techloq are literally available 24 hours a day, whenever I have a issue - Techloq are there to assist instantly.\"\n",
      "\n",
      "üìù Review #172: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) Very good product quality, super helpful customer service. Shipping within 3 weeks.\n",
      "\n",
      "(Original)\n",
      "Bardzo dobra jako≈õƒá produkt√≥w, ...\"\n",
      "\n",
      "üìù Review #173: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Clyde's was operating very well with all of the current safety precautions. Each member of the staff was extremely friendly and helpful and the servic...\"\n",
      "\n",
      "üìù Review #174: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"very good and delicious salad\"\n",
      "\n",
      "üìù Review #175: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"The very best in Moon Bounce rentals.. What others charge for a couple of hours, they charge for the entire day!!! It was awesome.. If you are looking...\"\n",
      "\n",
      "üìù Review #176: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"So easy and efficient!  Saved valuable vacation time not going through the standard drawn out vehicle rental process.  The car was clean, blended in w...\"\n",
      "\n",
      "üìù Review #177: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Taste has deteriorated compared to the past. I guess it's because he's famous. I do not recommend; you can eat betters in other restourants.\"\n",
      "\n",
      "üìù Review #178: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"What kind of business is this place running, my card has already been charged and i haven't received not on item ive purchased. Ive sent severl emails...\"\n",
      "\n",
      "üìù Review #179: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I hired Joe & team from KJ Marble & Tile in November 2017 to remodel a bathroom in our Boca Raton home. My decision to hire them was based on their ma...\"\n",
      "\n",
      "üìä Progress: 180/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #180: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) It is a good place, very nice that place and the food is excellent it is also a very tidy and very decorated restaurant\n",
      "\n",
      "(Origi...\"\n",
      "\n",
      "üìù Review #181: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great place to watch a football game...\"\n",
      "\n",
      "üìù Review #182: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Dealt with Steve McCrea at Ed Hamilton for a crewed catamaran charter out of Split, Croatia in Sept. 2019.  Steve was great to work with and was very ...\"\n",
      "\n",
      "üìù Review #183: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Exotic Blooms does a fine job of communicating and delivering a positive experience to the customer!\"\n",
      "\n",
      "üìù Review #184: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Kerry McDonald has been always so helpful.\n",
      "She goes above and beyond to help the clients. Her responses are so prompt and accurate.\n",
      "\n",
      "Every time we con...\"\n",
      "\n",
      "üìù Review #185: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Extremely poor leads and customer service. Be Careful!!\"\n",
      "\n",
      "üìù Review #186: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"An horrible experience today in the butcher's department.  I have never been so disrespected!\"\n",
      "\n",
      "üìù Review #187: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Cool show!\"\n",
      "\n",
      "üìù Review #188: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) My experience with monat has been excellent, in the first month I earned 5 times more than I invested apart from this by follow...\"\n",
      "\n",
      "üìù Review #189: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"The shipping took a long time but the product is amazing. I love what I got\"\n",
      "\n",
      "üìä Progress: 190/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #190: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Loved the Gountlet. I recommend it for everyone who is on the journey to heal. You‚Äôll be amazed how much it does help. üíñüôåüèª\"\n",
      "\n",
      "üìù Review #191: LEGITIMATE\n",
      "‚≠ê Rating: 4.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"(Translated by Google) Ideal costume and slippers!\n",
      "\n",
      "(Original)\n",
      "Disfraz y zapatillas ideales!\"\n",
      "\n",
      "üìù Review #192: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great customer service with quick and wonderful resolution. Items look just as pictured on site.\"\n",
      "\n",
      "üìù Review #193: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great selection of plants\"\n",
      "\n",
      "üìù Review #194: LEGITIMATE\n",
      "‚≠ê Rating: 1.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"These people are ridiculous. Why do you have a phone number and email address if you don't use either? Then I call the embassy who proceeds to forward...\"\n",
      "\n",
      "üìù Review #195: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Finally, I got a soul to my songs after a long time. And all thanks to Mike. He turned my songs into a hit song and I actually liked the final project...\"\n",
      "\n",
      "üìù Review #196: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Len and his crew got the job done as promised before Christmas and house guests arriving.  The bathroom is beautiful - Thanks!!\"\n",
      "\n",
      "üìù Review #197: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"I am so glad I found Alltrue (formerly Causebox). The products I receive are so unique, Earth friendly and just plain lovely! Whether for myself or as...\"\n",
      "\n",
      "üìù Review #198: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Great mezze, not too expensive.\"\n",
      "\n",
      "üìù Review #199: LEGITIMATE\n",
      "‚≠ê Rating: 2.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"The price was not right; I bought a 2-piece menu; the burger and bread did not taste good.\"\n",
      "\n",
      "üìä Progress: 200/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Review #200: LEGITIMATE\n",
      "‚≠ê Rating: 5.0\n",
      "üéØ Confidence: 0.000\n",
      "üìÑ Text: \"Went here while visiting DC and was surprised! Wilmot was the man! The waffles in the chicken and waffles was the best I ever had!\"\n",
      "\n",
      "======================================================================\n",
      "üìä PROCESSING COMPLETE!\n",
      "üìã Label distribution:\n",
      "   LEGITIMATE: 200\n",
      "üíæ Results saved to: sample_200_reviews_with_labels_1756586233.csv\n",
      "üìä Output columns: ['index', 'text', 'rating', 'label', 'confidence', 'reason']\n",
      "\n",
      "üîç First 5 results:\n",
      "   index       label  rating\n",
      "0      1  LEGITIMATE     5.0\n",
      "1      2  LEGITIMATE     5.0\n",
      "2      3  LEGITIMATE     5.0\n",
      "3      4  LEGITIMATE     5.0\n",
      "4      5  LEGITIMATE     5.0\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Sample Review Classification - 200 Reviews with Text and Labels\n",
    "print(\"=\" * 70)\n",
    "print(\"ü§ñ SAMPLE REVIEW CLASSIFICATION - 200 REVIEWS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def load_additional_reviews():\n",
    "    \"\"\"Load additional review datasets - simplified to extract only text and rating\"\"\"\n",
    "    additional_dfs = []\n",
    "    \n",
    "    # Check for additional review files\n",
    "    additional_files = [\n",
    "        './review-other.json',\n",
    "        # Add more file paths as needed\n",
    "    ]\n",
    "    1\n",
    "    for file_path in additional_files:\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                if file_path.endswith('.json'):\n",
    "                    # Enhanced JSON loading with better error handling\n",
    "                    print(f\"üîÑ Attempting to load {file_path}...\")\n",
    "                    \n",
    "                    # First, peek at the file to determine format\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        first_line = f.readline().strip()\n",
    "                        second_line = f.readline().strip()\n",
    "                    \n",
    "                    # Check if it's JSONL format (each line is a JSON object)\n",
    "                    if (first_line.startswith('{') and first_line.endswith('}') and \n",
    "                        second_line.startswith('{') and second_line.endswith('}')):\n",
    "                        \n",
    "                        print(f\"üìÑ Detected JSONL format (JSON Lines) - parsing line by line...\")\n",
    "                        json_objects = []\n",
    "                        \n",
    "                        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                            for line_num, line in enumerate(f, 1):\n",
    "                                line = line.strip()\n",
    "                                if line:  # Skip empty lines\n",
    "                                    try:\n",
    "                                        obj = json.loads(line)\n",
    "                                        json_objects.append(obj)\n",
    "                                    except json.JSONDecodeError as e:\n",
    "                                        print(f\"‚ö†Ô∏è Skipping invalid JSON on line {line_num}: {e}\")\n",
    "                                        continue\n",
    "                        \n",
    "                        json_data = json_objects\n",
    "                        print(f\"‚úÖ Successfully parsed {len(json_data)} JSON objects from JSONL file\")\n",
    "                        \n",
    "                    else:\n",
    "                        # Try standard JSON formats\n",
    "                        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                            content = f.read().strip()\n",
    "                        \n",
    "                        if content.startswith('[') and content.endswith(']'):\n",
    "                            # Array of JSON objects\n",
    "                            json_data = json.loads(content)\n",
    "                            print(f\"‚úÖ Successfully parsed JSON array with {len(json_data)} objects\")\n",
    "                        elif content.startswith('{') and content.endswith('}'):\n",
    "                            # Single JSON object\n",
    "                            json_data = json.loads(content)\n",
    "                            print(f\"‚úÖ Successfully parsed single JSON object\")\n",
    "                        else:\n",
    "                            print(f\"‚ùå Unrecognized JSON format in {file_path}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Convert to DataFrame and apply same cleaning as Kaggle data\n",
    "                    if isinstance(json_data, list):\n",
    "                        if json_data:  # Check if list is not empty\n",
    "                            full_df = pd.DataFrame(json_data)\n",
    "                            print(f\"‚úÖ Created DataFrame with {len(full_df)} rows and {len(full_df.columns)} columns\")\n",
    "                            print(f\"üìã Original columns: {list(full_df.columns)}\")\n",
    "                            \n",
    "                            # Apply same cleaning process as Kaggle dataset\n",
    "                            cleaned_df = clean_json_data_like_kaggle(full_df)\n",
    "                            if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                                additional_dfs.append(cleaned_df)\n",
    "                        else:\n",
    "                            print(f\"‚ö†Ô∏è JSON file {file_path} contains empty array\")\n",
    "                    else:\n",
    "                        full_df = pd.json_normalize(json_data)\n",
    "                        print(f\"‚úÖ Created DataFrame with {len(full_df)} rows and {len(full_df.columns)} columns\")\n",
    "                        cleaned_df = clean_json_data_like_kaggle(full_df)\n",
    "                        if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                            additional_dfs.append(cleaned_df)\n",
    "                        \n",
    "                elif file_path.endswith('.html'):\n",
    "                    # Enhanced HTML parsing with dependency installation\n",
    "                    try:\n",
    "                        # First try to install lxml if not available\n",
    "                        try:\n",
    "                            import lxml\n",
    "                        except ImportError:\n",
    "                            print(f\"üì¶ Installing lxml for HTML parsing...\")\n",
    "                            import subprocess\n",
    "                            import sys\n",
    "                            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"lxml\"])\n",
    "                            print(f\"‚úÖ lxml installed successfully\")\n",
    "                        \n",
    "                        # Now try to parse HTML\n",
    "                        html_tables = pd.read_html(file_path, encoding='utf-8')\n",
    "                        if html_tables:\n",
    "                            # If multiple tables, try to find the one with review-like data\n",
    "                            best_table = None\n",
    "                            max_rows = 0\n",
    "                            \n",
    "                            for i, table in enumerate(html_tables):\n",
    "                                if len(table) > max_rows:\n",
    "                                    # Look for text-like columns\n",
    "                                    text_like_cols = [col for col in table.columns if \n",
    "                                                    any(keyword in str(col).lower() for keyword in \n",
    "                                                        ['text', 'review', 'comment', 'content', 'message'])]\n",
    "                                    if text_like_cols or len(table.columns) >= 3:  # Reasonable number of columns\n",
    "                                        best_table = table\n",
    "                                        max_rows = len(table)\n",
    "                            \n",
    "                            if best_table is not None:\n",
    "                                print(f\"‚úÖ Found table with {len(best_table)} rows from {file_path}\")\n",
    "                                cleaned_df = clean_json_data_like_kaggle(best_table)\n",
    "                                if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                                    additional_dfs.append(cleaned_df)\n",
    "                            else:\n",
    "                                print(f\"‚ö†Ô∏è No suitable table found in {file_path}\")\n",
    "                        else:\n",
    "                            print(f\"‚ö†Ô∏è No tables found in HTML file {file_path}\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Could not parse HTML file {file_path}: {e}\")\n",
    "                        print(f\"üí° Try converting the HTML file to CSV format manually\")\n",
    "                        \n",
    "                elif file_path.endswith('.csv'):\n",
    "                    try:\n",
    "                        # Try different encodings\n",
    "                        encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "                        full_df = None\n",
    "                        \n",
    "                        for encoding in encodings:\n",
    "                            try:\n",
    "                                full_df = pd.read_csv(file_path, encoding=encoding)\n",
    "                                print(f\"‚úÖ Loaded {len(full_df)} rows from {file_path} (encoding: {encoding})\")\n",
    "                                break\n",
    "                            except UnicodeDecodeError:\n",
    "                                continue\n",
    "                        \n",
    "                        if full_df is not None:\n",
    "                            cleaned_df = clean_json_data_like_kaggle(full_df)\n",
    "                            if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                                additional_dfs.append(cleaned_df)\n",
    "                        else:\n",
    "                            print(f\"‚ùå Could not read CSV file {file_path} with any encoding\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Error loading CSV {file_path}: {e}\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Unexpected error loading {file_path}: {e}\")\n",
    "                import traceback\n",
    "                print(f\"üìã Full error traceback:\")\n",
    "                traceback.print_exc()\n",
    "        else:\n",
    "            print(f\"‚ÑπÔ∏è File not found: {file_path}\")\n",
    "    \n",
    "    return additional_dfs\n",
    "\n",
    "def clean_json_data_like_kaggle(df):\n",
    "    \"\"\"Clean JSON data using the same method as Kaggle dataset (clean_reviews_dataset)\"\"\"\n",
    "    \n",
    "    print(f\"üßπ Applying Kaggle-style cleaning to DataFrame with columns: {list(df.columns)}\")\n",
    "    \n",
    "    try:\n",
    "        # Use the same _find_col function and cleaning logic as Kaggle dataset\n",
    "        col_business = _find_col(df, [\"business_name\", \"restaurant\", \"place_name\", \"name\"], required=False)\n",
    "        col_author   = _find_col(df, [\"author_name\", \"user\", \"user_name\", \"reviewer\"], required=False)\n",
    "        col_text     = _find_col(df, [\"text\", \"review_text\", \"comment\", \"content\", \"review\"], required=True)\n",
    "        col_rating   = _find_col(df, [\"rating\", \"stars\", \"score\", \"star_rating\"], required=False)\n",
    "\n",
    "        # Optional columns may or may not exist\n",
    "        col_photo          = _find_col(df, [\"photo\"], required=False)\n",
    "        col_rating_category= _find_col(df, [\"rating_category\"], required=False)\n",
    "\n",
    "        # Work on a copy\n",
    "        d = df.copy()\n",
    "\n",
    "        # Normalize whitespace for string fields (only if they exist)\n",
    "        if col_text:\n",
    "            d[col_text] = d[col_text].astype(str).str.strip()\n",
    "        if col_business:\n",
    "            d[col_business] = d[col_business].astype(str).str.strip()\n",
    "        if col_author:\n",
    "            d[col_author] = d[col_author].astype(str).str.strip()\n",
    "\n",
    "        # Coerce rating to numeric if exists\n",
    "        if col_rating:\n",
    "            d[col_rating] = pd.to_numeric(d[col_rating], errors=\"coerce\")\n",
    "            d[col_rating] = d[col_rating].fillna(3)  # Default to 3 if NaN\n",
    "            d[col_rating] = d[col_rating].clip(1, 5)  # Ensure 1-5 range\n",
    "\n",
    "        # Drop rows with missing/empty required fields\n",
    "        before = len(d)\n",
    "        d = d.dropna(subset=[col_text])\n",
    "        # Remove empty-string rows in text column\n",
    "        d = d[d[col_text] != \"\"]\n",
    "        # Remove very short reviews\n",
    "        d = d[d[col_text].str.len() >= 5]\n",
    "\n",
    "        removed = before - len(d)\n",
    "        print(f\"üßπ Cleaned dataset: {before} ‚Üí {len(d)} rows (removed {removed})\")\n",
    "\n",
    "        if len(d) == 0:\n",
    "            print(\"‚ö†Ô∏è No valid reviews remaining after cleaning\")\n",
    "            return None\n",
    "\n",
    "        # Rebuild output with target column names in the same format as Kaggle\n",
    "        out_data = {\n",
    "            \"text\": d[col_text],\n",
    "            \"rating\": d[col_rating] if col_rating else pd.Series([3]*len(d))\n",
    "        }\n",
    "        \n",
    "        # Add optional columns if they exist\n",
    "        if col_business:\n",
    "            out_data[\"business_name\"] = d[col_business]\n",
    "        else:\n",
    "            out_data[\"business_name\"] = pd.Series(['Unknown Business']*len(d))\n",
    "            \n",
    "        if col_author:\n",
    "            out_data[\"author_name\"] = d[col_author]\n",
    "        else:\n",
    "            out_data[\"author_name\"] = pd.Series([f'user_{i}' for i in range(len(d))])\n",
    "\n",
    "        out = pd.DataFrame(out_data)\n",
    "        \n",
    "        # Attach optional columns if present\n",
    "        if col_photo and col_photo in d.columns:\n",
    "            out[\"photo\"] = d[col_photo]\n",
    "        else:\n",
    "            out[\"photo\"] = pd.Series([pd.NA]*len(d))\n",
    "            \n",
    "        if col_rating_category and col_rating_category in d.columns:\n",
    "            out[\"rating_category\"] = d[col_rating_category]\n",
    "        else:\n",
    "            out[\"rating_category\"] = pd.Series([pd.NA]*len(d))\n",
    "\n",
    "        return out.reset_index(drop=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during cleaning: {e}\")\n",
    "        return None\n",
    "\n",
    "def merge_all_datasets_and_sample(kaggle_df, additional_dfs, sample_size=200):\n",
    "    \"\"\"Merge all datasets and sample specified number of reviews\"\"\"\n",
    "    \n",
    "    if not additional_dfs:\n",
    "        print(\"‚ÑπÔ∏è No additional datasets found, using Kaggle data only\")\n",
    "        combined_df = kaggle_df.copy()\n",
    "    else:\n",
    "        print(f\"üîÑ Merging {len(additional_dfs)} additional datasets with Kaggle data...\")\n",
    "        \n",
    "        # Combine all datasets\n",
    "        all_dfs = [kaggle_df]\n",
    "        \n",
    "        for i, add_df in enumerate(additional_dfs):\n",
    "            print(f\"   Adding dataset {i+1}/{len(additional_dfs)} with {len(add_df)} rows\")\n",
    "            all_dfs.append(add_df)\n",
    "        \n",
    "        try:\n",
    "            combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "            \n",
    "            # Remove duplicates based on text content\n",
    "            original_len = len(combined_df)\n",
    "            combined_df = combined_df.drop_duplicates(subset=['text'], keep='first')\n",
    "            duplicates_removed = original_len - len(combined_df)\n",
    "            \n",
    "            print(f\"üìä Merged dataset statistics:\")\n",
    "            print(f\"   Total reviews: {len(combined_df)}\")\n",
    "            print(f\"   Kaggle reviews: {len(kaggle_df)}\")\n",
    "            print(f\"   Additional reviews: {len(combined_df) - len(kaggle_df)}\")\n",
    "            print(f\"   Duplicates removed: {duplicates_removed}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error merging datasets: {e}\")\n",
    "            print(\"üîÑ Falling back to Kaggle data only\")\n",
    "            combined_df = kaggle_df.copy()\n",
    "    \n",
    "    # Sample the specified number of reviews\n",
    "    if len(combined_df) > sample_size:\n",
    "        print(f\"üéØ Sampling {sample_size} reviews from {len(combined_df)} total reviews...\")\n",
    "        sampled_df = combined_df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        print(f\"üîÑ Using all {len(combined_df)} reviews (less than requested {sample_size})\")\n",
    "        sampled_df = combined_df.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"üìä Final sample size: {len(sampled_df)} reviews\")\n",
    "    print(f\"üìã Final columns: {list(sampled_df.columns)}\")\n",
    "    \n",
    "    return sampled_df\n",
    "\n",
    "# Test the JSONL parsing specifically\n",
    "print(\"üß™ Testing JSONL parsing on your review-other.json file...\")\n",
    "test_path = './review-other.json'\n",
    "\n",
    "if os.path.exists(test_path):\n",
    "    try:\n",
    "        # Load and show sample data\n",
    "        sample_objects = []\n",
    "        with open(test_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= 5:  # Just get first 5 lines for testing\n",
    "                    break\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    try:\n",
    "                        obj = json.loads(line)\n",
    "                        sample_objects.append(obj)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"‚ùå Error parsing line {i+1}: {e}\")\n",
    "        \n",
    "        if sample_objects:\n",
    "            sample_df = pd.DataFrame(sample_objects)\n",
    "            print(f\"‚úÖ Successfully parsed sample data:\")\n",
    "            print(f\"üìä Shape: {sample_df.shape}\")\n",
    "            print(f\"üìã Original columns: {list(sample_df.columns)}\")\n",
    "            \n",
    "            # Test cleaning\n",
    "            cleaned_sample = clean_json_data_like_kaggle(sample_df)\n",
    "            if cleaned_sample is not None:\n",
    "                print(f\"‚úÖ Cleaned sample:\")\n",
    "                print(f\"üìä Shape: {cleaned_sample.shape}\")\n",
    "                print(f\"üìã Columns: {list(cleaned_sample.columns)}\")\n",
    "                print(f\"üîç First few rows:\")\n",
    "                print(cleaned_sample.head(3))\n",
    "        else:\n",
    "            print(\"‚ùå No valid JSON objects found in sample\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing JSONL parsing: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå File not found: {test_path}\")\n",
    "\n",
    "# Check if we have a loaded dataframe\n",
    "if 'df' in locals() and not df.empty:\n",
    "    \n",
    "    # Load additional review datasets\n",
    "    print(\"üìÇ Searching for additional review datasets...\")\n",
    "    additional_datasets = load_additional_reviews()\n",
    "    \n",
    "    # Merge all datasets and sample 200 reviews\n",
    "    sample_df = merge_all_datasets_and_sample(df, additional_datasets, sample_size=200)\n",
    "    \n",
    "    # Verify we have the required columns\n",
    "    if 'text' not in sample_df.columns:\n",
    "        print(\"‚ùå No text column found in sample dataset\")\n",
    "        print(\"üîÑ Please check your data sources\")\n",
    "    else:\n",
    "        print(f\"üìù Using 'text' column for review text\")\n",
    "        \n",
    "        # Display sample dataset information\n",
    "        print(f\"\\nüìä SAMPLE DATASET INFORMATION:\")\n",
    "        print(f\"   Total reviews for processing: {len(sample_df)}\")\n",
    "        print(f\"   Columns: {list(sample_df.columns)}\")\n",
    "        \n",
    "        if 'rating' in sample_df.columns:\n",
    "            rating_dist = dict(sample_df['rating'].value_counts().sort_index())\n",
    "            print(f\"   Rating distribution: {rating_dist}\")\n",
    "        \n",
    "        # Show a sample of the data\n",
    "        print(f\"\\nüîç Sample of data:\")\n",
    "        for i, row in sample_df.head(5).iterrows():\n",
    "            text = str(row['text'])[:100]\n",
    "            rating = row.get('rating', 'N/A')\n",
    "            print(f\"   {i+1}. Rating: {rating} | Text: {text}{'...' if len(str(row['text'])) > 100 else ''}\")\n",
    "        print()\n",
    "        \n",
    "        # Process reviews and generate labels\n",
    "        if gemma_classifier and gemma_classifier.client:\n",
    "            print(f\"üîÑ Processing {len(sample_df)} reviews with Gemma classifier...\")\n",
    "            print(f\"üö® RESULTS (Text + Labels):\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            results_for_output = []\n",
    "            \n",
    "            for idx, row in sample_df.iterrows():\n",
    "                review_text = str(row['text']) if pd.notna(row['text']) else \"\"\n",
    "                review_rating = row.get('rating', 3)\n",
    "                \n",
    "                # Progress indicator\n",
    "                if (idx + 1) % 10 == 0:\n",
    "                    print(f\"\\nüìä Progress: {idx + 1}/{len(sample_df)} reviews\")\n",
    "                    print(\"-\" * 60)\n",
    "                \n",
    "                # Skip empty reviews\n",
    "                if len(review_text.strip()) < 5:\n",
    "                    results_for_output.append({\n",
    "                        'index': idx + 1,\n",
    "                        'text': review_text,\n",
    "                        'rating': review_rating,\n",
    "                        'label': 'INVALID',\n",
    "                        'reason': 'Review too short'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Classify with Gemma\n",
    "                    result = gemma_classifier.classify_review(review_text)\n",
    "                    \n",
    "                    # Determine label\n",
    "                    is_violation = result.get('is_violation', False)\n",
    "                    violation_type = result.get('violation_type', 'unknown')\n",
    "                    confidence = result.get('policy_confidence', 0.0)\n",
    "                    \n",
    "                    if is_violation:\n",
    "                        label = f\"VIOLATION ({violation_type.upper()})\"\n",
    "                    else:\n",
    "                        label = \"LEGITIMATE\"\n",
    "                    \n",
    "                    results_for_output.append({\n",
    "                        'index': idx + 1,\n",
    "                        'text': review_text,\n",
    "                        'rating': review_rating,\n",
    "                        'label': label,\n",
    "                        'confidence': confidence,\n",
    "                        'reason': result.get('policy_reasoning', '')\n",
    "                    })\n",
    "                    \n",
    "                    # Display result\n",
    "                    print(f\"\\nüìù Review #{idx + 1}: {label}\")\n",
    "                    print(f\"‚≠ê Rating: {review_rating}\")\n",
    "                    print(f\"üéØ Confidence: {confidence:.3f}\")\n",
    "                    print(f\"üìÑ Text: \\\"{review_text[:150]}{'...' if len(review_text) > 150 else ''}\\\"\")\n",
    "                    if result.get('policy_reasoning'):\n",
    "                        print(f\"üí° Reason: {result.get('policy_reasoning', '')[:100]}{'...' if len(result.get('policy_reasoning', '')) > 100 else ''}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    results_for_output.append({\n",
    "                        'index': idx + 1,\n",
    "                        'text': review_text,\n",
    "                        'rating': review_rating,\n",
    "                        'label': 'ERROR',\n",
    "                        'reason': str(e)\n",
    "                    })\n",
    "                    print(f\"\\n‚ùå ERROR processing review #{idx + 1}: {str(e)}\")\n",
    "                \n",
    "                # Rate limiting\n",
    "                time.sleep(0.8)\n",
    "            \n",
    "            # Final summary and save results\n",
    "            print(f\"\\n\" + \"=\"*70)\n",
    "            print(f\"üìä PROCESSING COMPLETE!\")\n",
    "            \n",
    "            # Count labels\n",
    "            label_counts = {}\n",
    "            for result in results_for_output:\n",
    "                label = result['label'].split(' (')[0]  # Get main label part\n",
    "                label_counts[label] = label_counts.get(label, 0) + 1\n",
    "            \n",
    "            print(f\"üìã Label distribution:\")\n",
    "            for label, count in label_counts.items():\n",
    "                print(f\"   {label}: {count}\")\n",
    "            \n",
    "            # Save results to CSV\n",
    "            results_df = pd.DataFrame(results_for_output)\n",
    "            output_filename = f\"sample_200_reviews_with_labels_{int(time.time())}.csv\"\n",
    "            results_df.to_csv(output_filename, index=False)\n",
    "            print(f\"üíæ Results saved to: {output_filename}\")\n",
    "            print(f\"üìä Output columns: {list(results_df.columns)}\")\n",
    "            \n",
    "            # Show first few results\n",
    "            print(f\"\\nüîç First 5 results:\")\n",
    "            print(results_df[['index', 'label', 'rating']].head())\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Gemma classifier not available\")\n",
    "            print(\"üí° Generating simple output without ML classification...\")\n",
    "            \n",
    "            # Simple output without classification\n",
    "            simple_results = []\n",
    "            for idx, row in sample_df.iterrows():\n",
    "                simple_results.append({\n",
    "                    'index': idx + 1,\n",
    "                    'text': str(row['text']),\n",
    "                    'rating': row.get('rating', 'N/A'),\n",
    "                    'label': 'NOT_CLASSIFIED',\n",
    "                    'reason': 'Classifier not available'\n",
    "                })\n",
    "            \n",
    "            # Save simple results\n",
    "            simple_df = pd.DataFrame(simple_results)\n",
    "            output_filename = f\"sample_200_reviews_no_classification_{int(time.time())}.csv\"\n",
    "            simple_df.to_csv(output_filename, index=False)\n",
    "            print(f\"üíæ Simple results saved to: {output_filename}\")\n",
    "\n",
    "elif 'df' not in locals() or df.empty:\n",
    "    print(\"‚ö†Ô∏è No dataset loaded yet\")\n",
    "    print(\"üí° Please run the data loading cells first to load your review dataset\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Dataset not available\")\n",
    "    print(\"üîÑ Please ensure dataset is properly loaded\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1500a3",
   "metadata": {},
   "source": [
    "## üéØ Summary & Next Steps\n",
    "\n",
    "### üèÜ What We've Built\n",
    "\n",
    "Our **Trustworthy Location Review System** includes:\n",
    "\n",
    "1. **üîç Advanced Feature Engineering**\n",
    "   - 40+ textual and non-textual features\n",
    "   - Sentiment analysis, spam detection, readability metrics\n",
    "   - Restaurant & Establishments relevancy indicators\n",
    "\n",
    "2. **üö´ Rule-Based Policy Detection**\n",
    "   - Advertisement detection (contact info, promotional language)\n",
    "   - Irrelevant content filtering* (off-topic discussions)\n",
    "   - Rant without visit identification* (hearsay reviews)\n",
    "\n",
    "3. **ü§ñ Gemma 3 12B Integration**\n",
    "   - Our LLM of choice for policy violation detection\n",
    "   - Quality assessment and authenticity scoring\n",
    "   - HuggingFace Inference Client integration\n",
    "\n",
    "### üìä System Capabilities\n",
    "\n",
    "- **Policy Violation Detection**: Identifies advertisements, irrelevant content, and fake rants\n",
    "- **Quality Assessment**: Evaluates review authenticity and helpfulness\n",
    "- **Batch Processing**: Handles large datasets efficiently\n",
    "- **Ensemble Decision Making**: Leverages multiple approaches for robust predictions\n",
    "- **Explainable AI**: Provides reasoning for each classification decision\n",
    "\n",
    "### üöÄ Production Readiness\n",
    "\n",
    "The system is designed for:\n",
    "- **Scalability**: Batch processing with configurable sizes\n",
    "- **Reliability**: Fallback mechanisms when individual components fail\n",
    "- **Flexibility**: Adjustable weights and thresholds\n",
    "- **Monitoring**: Comprehensive performance analytics\n",
    "\n",
    "### üìà Next Steps\n",
    "\n",
    "1. **üîß Fine-Tuning**\n",
    "   - Adjust ensemble weights based on validation data\n",
    "   - Optimize decision thresholds\n",
    "   - Add domain-specific rules\n",
    "\n",
    "2. **üìä Evaluation**\n",
    "   - Test on larger datasets\n",
    "   - Measure precision, recall, F1-score\n",
    "   - A/B test different configurations\n",
    "\n",
    "3. **üöÄ Further Improvements**\n",
    "   - Find more \"bad\" examples to train the model better\n",
    "   - Implement monitoring dashboard\n",
    "\n",
    "### üéâ Hackathon Impact\n",
    "\n",
    "This solution addresses the critical problem of **review trustworthiness** by:\n",
    "- **Filtering noise** from restaurant review platforms\n",
    "- **Protecting consumers** from misleading information\n",
    "- **Supporting businesses** with authentic feedback\n",
    "- **Improving platform quality** through automated moderation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
