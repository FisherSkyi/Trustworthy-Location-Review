{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1187d7fc",
   "metadata": {},
   "source": [
    "# Filtering the Noise: ML for Trustworthy Location Reviews\n",
    "\n",
    "**Team:** OIIA OIIA \n",
    "**Date:** August 31, 2025  \n",
    "**Challenge:** Design and implement an ML-based system to evaluate the quality and relevancy of Google location reviews\n",
    "\n",
    "### Problem Statement\n",
    "- **Gauge review quality**: Detect spam, advertisements*, irrelevant content*, and rants*\n",
    "- **Assess relevancy**: Determine if review content is genuinely related to the location\n",
    "- **Enforce policies**: Automatically flag reviews violating predefined policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b4810",
   "metadata": {},
   "source": [
    "## 🔨 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3fd6026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (4.56.0)\n",
      "Requirement already satisfied: torch in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (2.8.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (4.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (3.10.6)\n",
      "Requirement already satisfied: seaborn in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (0.13.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (6.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2025.8.29)\n",
      "Requirement already satisfied: requests in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from plotly) (2.2.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from fsspec->torch) (3.12.15)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.20.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (0.34.4)\n",
      "Requirement already satisfied: accelerate in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (1.10.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub) (4.15.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (2.3.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (3.9.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (3.8.7)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (1.9.4)\n",
      "Requirement already satisfied: click in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (2025.8.29)\n",
      "Requirement already satisfied: tqdm in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from wordcloud) (11.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from wordcloud) (3.10.6)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: wrapt in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kaggle in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (2025.8.3)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (3.4.3)\n",
      "Requirement already satisfied: idna in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (6.32.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\program files\\python311\\lib\\site-packages (from kaggle) (65.5.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textstat in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (0.7.8)\n",
      "Requirement already satisfied: pyphen in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: cmudict in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from textstat) (1.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from textstat) (65.5.0)\n",
      "Requirement already satisfied: importlib-metadata>=5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from cmudict->textstat) (8.7.0)\n",
      "Requirement already satisfied: importlib-resources>=5 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from cmudict->textstat) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\seanh\\appdata\\roaming\\python\\python311\\site-packages (from importlib-metadata>=5->cmudict->textstat) (3.23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "All packages installed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ⚠️ Run this cell only if fresh runtime or first time setup\n",
    "\n",
    "# Install required packages\n",
    "%pip install transformers torch datasets pandas numpy scikit-learn matplotlib seaborn plotly\n",
    "%pip install huggingface-hub accelerate\n",
    "%pip install nltk spacy wordcloud\n",
    "%pip install kaggle\n",
    "%pip install textstat\n",
    "print(\"All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b987589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanh\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\seanh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\seanh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\seanh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ⚠️ Run this cell only if fresh runtime or first time setup\n",
    "\n",
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# NLP and ML libraries\n",
    "import nltk\n",
    "import spacy\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Data processing\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Terminal commands\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bfc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ Run this cell only if fresh runtime or first time setup\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Kaggle API Setup & Downloading of Dataset to ./kaggle_data directory\n",
    "def config_kaggle_api_token():\n",
    "    # kaggle_dir = Path.home() / '.config' / 'kaggle'\n",
    "    kaggle_dir = Path.home() / '.kaggle'\n",
    "    kaggle_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    shutil.copy('./kaggle.json', kaggle_dir / 'kaggle.json')\n",
    "    os.chmod(kaggle_dir / 'kaggle.json', 0o600)\n",
    "\n",
    "def download_kaggle_dataset(path='./kaggle_data', dataset_name=\"denizbilginn/google-maps-restaurant-reviews\"):\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    dataset_name=\"denizbilginn/google-maps-restaurant-reviews\"\n",
    "    api.dataset_download_files(dataset_name,\n",
    "                            path=path,\n",
    "                            unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b39ba",
   "metadata": {},
   "source": [
    "## 📊 Data Collection & Loading\n",
    "\n",
    "We'll use the provided Google Local Reviews dataset. You can also supplement with additional data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c52343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/denizbilginn/google-maps-restaurant-reviews\n"
     ]
    }
   ],
   "source": [
    "# ⚠️ Run this cell only if fresh runtime or first time setup\n",
    "\n",
    "# Download Kaggle Dataset\n",
    "config_kaggle_api_token()\n",
    "download_kaggle_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Functions\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    \"\"\"Load dataset from local CSV file\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"✅ Loaded {len(df)} rows from {file_path}\")\n",
    "            # df = standardize_columns(df)\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"❌ File not found: {file_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading local file: {e}\")\n",
    "        return None\n",
    "\n",
    "def standardize_columns(df):\n",
    "    \"\"\"Standardize column names to match our expected format\"\"\"\n",
    "    # Common column mappings\n",
    "    column_mappings = {\n",
    "        'text': 'review_text',\n",
    "        'review': 'review_text',\n",
    "        'comment': 'review_text',\n",
    "        'content': 'review_text',\n",
    "        'review_text': 'review_text',\n",
    "\n",
    "        'rating': 'rating',\n",
    "        'stars': 'rating',\n",
    "        'score': 'rating',\n",
    "        'star_rating': 'rating',\n",
    "\n",
    "        'business': 'business_name',\n",
    "        'restaurant': 'business_name',\n",
    "        'place_name': 'business_name',\n",
    "        'name': 'business_name',\n",
    "\n",
    "        'user': 'user_id',\n",
    "        'user_name': 'user_id',\n",
    "        'reviewer': 'user_id',\n",
    "\n",
    "        'date': 'timestamp',\n",
    "        'time': 'timestamp',\n",
    "        'created_at': 'timestamp',\n",
    "        'review_date': 'timestamp'\n",
    "    }\n",
    "\n",
    "    # Convert column names to lowercase for matching\n",
    "    df_columns_lower = [col.lower() for col in df.columns]\n",
    "\n",
    "    # Apply mappings\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        if col_lower in column_mappings:\n",
    "            new_columns.append(column_mappings[col_lower])\n",
    "        else:\n",
    "            new_columns.append(col)\n",
    "\n",
    "    df.columns = new_columns\n",
    "\n",
    "    # Ensure we have required columns\n",
    "    required_columns = ['review_text', 'rating']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            if col == 'review_text':\n",
    "                # Try to find any text column\n",
    "                text_cols = [c for c in df.columns if 'text' in c.lower() or 'review' in c.lower() or 'comment' in c.lower()]\n",
    "                if text_cols:\n",
    "                    df['review_text'] = df[text_cols[0]]\n",
    "                else:\n",
    "                    print(f\"⚠️ Could not find text column, creating placeholder\")\n",
    "                    df['review_text'] = \"Sample review text\"\n",
    "            elif col == 'rating':\n",
    "                # Try to find any rating column\n",
    "                rating_cols = [c for c in df.columns if 'rating' in c.lower() or 'star' in c.lower() or 'score' in c.lower()]\n",
    "                if rating_cols:\n",
    "                    df['rating'] = df[rating_cols[0]]\n",
    "                else:\n",
    "                    print(f\"⚠️ Could not find rating column, creating placeholder\")\n",
    "                    df['rating'] = 3  # Default neutral rating\n",
    "\n",
    "    # Add missing optional columns\n",
    "    if 'business_name' not in df.columns:\n",
    "        df['business_name'] = 'Unknown Business'\n",
    "    if 'user_id' not in df.columns:\n",
    "        df['user_id'] = [f'user_{i}' for i in range(len(df))]\n",
    "    if 'timestamp' not in df.columns:\n",
    "        df['timestamp'] = pd.date_range('2024-01-01', periods=len(df), freq='D')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd1608a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1100 rows from ./kaggle_data/reviews.csv\n",
      "🔧 Introduced a missing value in row 5 (text column)\n",
      "\n",
      "🧹 Cleaned dataset: 1100 → 1100 rows (removed 0)\n",
      "\n",
      "📋 Cleaned Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100 entries, 0 to 1099\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   business_name    1100 non-null   object\n",
      " 1   author_name      1100 non-null   object\n",
      " 2   text             1100 non-null   object\n",
      " 3   rating           1100 non-null   int64 \n",
      " 4   photo            1100 non-null   object\n",
      " 5   rating_category  1100 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 51.7+ KB\n",
      "None\n",
      "\n",
      "📊 Dataset shape: (1100, 6)\n",
      "\n",
      "🔍 First 5 reviews:\n",
      "                     business_name    author_name  \\\n",
      "0  Haci'nin Yeri - Yigit Lokantasi    Gulsum Akar   \n",
      "1  Haci'nin Yeri - Yigit Lokantasi  Oguzhan Cetin   \n",
      "2  Haci'nin Yeri - Yigit Lokantasi     Yasin Kuyu   \n",
      "3  Haci'nin Yeri - Yigit Lokantasi     Orhan Kapu   \n",
      "4  Haci'nin Yeri - Yigit Lokantasi     Ozgur Sati   \n",
      "\n",
      "                                                text  rating  \\\n",
      "0  We went to Marmaris with my wife for a holiday...       5   \n",
      "1  During my holiday in Marmaris we ate here to f...       4   \n",
      "2  Prices are very affordable. The menu in the ph...       3   \n",
      "3  Turkey's cheapest artisan restaurant and its f...       5   \n",
      "4  I don't know what you will look for in terms o...       3   \n",
      "\n",
      "                                               photo     rating_category  \n",
      "0         dataset/taste/hacinin_yeri_gulsum_akar.png               taste  \n",
      "1        dataset/menu/hacinin_yeri_oguzhan_cetin.png                menu  \n",
      "2  dataset/outdoor_atmosphere/hacinin_yeri_yasin_...  outdoor_atmosphere  \n",
      "3  dataset/indoor_atmosphere/hacinin_yeri_orhan_k...   indoor_atmosphere  \n",
      "4           dataset/menu/hacinin_yeri_ozgur_sati.png                menu  \n",
      "\n",
      "✅ Data Quality Check:\n",
      "- Total reviews: 1100\n",
      "- Unique businesses: 100\n",
      "- Rating distribution: {1: np.int64(80), 2: np.int64(72), 3: np.int64(172), 4: np.int64(316), 5: np.int64(460)}\n",
      "- Missing values: 0\n",
      "- Average review length: 110.8 characters\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = load_dataset('./kaggle_data/reviews.csv')\n",
    "\n",
    "# 👇 Simulate a bad row (make the 5th row's text missing)\n",
    "df.loc[4, \"review_text\"] = \"\"   # or \"\" to test empty-string removal\n",
    "print(\"🔧 Introduced a missing value in row 5 (text column)\\n\")\n",
    "\n",
    "df = clean_reviews_dataset(df)\n",
    "\n",
    "print(\"\\n📋 Cleaned Dataset Info:\")\n",
    "print(df.info())\n",
    "print(f\"\\n📊 Dataset shape: {df.shape}\")\n",
    "print(\"\\n🔍 First 5 reviews:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display data quality info\n",
    "print(f\"\\n✅ Data Quality Check:\")\n",
    "print(f\"- Total reviews: {len(df)}\")\n",
    "print(f\"- Unique businesses: {df['business_name'].nunique()}\")\n",
    "print(f\"- Rating distribution: {dict(df['rating'].value_counts().sort_index())}\")\n",
    "print(f\"- Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"- Average review length: {df['text'].str.len().mean():.1f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fd5f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleanup\n",
    "\n",
    "def _find_col(df, aliases, required=True):\n",
    "    \"\"\"Return the first matching column from aliases; None if not found and required=False.\"\"\"\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    for a in aliases:\n",
    "        if a.lower() in cols_lower:\n",
    "            return cols_lower[a.lower()]\n",
    "    if required:\n",
    "        raise KeyError(f\"None of the aliases {aliases} found in columns: {list(df.columns)}\")\n",
    "    return None\n",
    "\n",
    "def clean_reviews_dataset(df):\n",
    "    \"\"\"\n",
    "    Keep rows that have ALL of the following (non-empty, non-NaN):\n",
    "      - business_name\n",
    "      - author_name\n",
    "      - text\n",
    "      - rating\n",
    "    Allow missing: photo, rating_category\n",
    "    Preserve output columns in original schema.\n",
    "    \"\"\"\n",
    "\n",
    "    # Resolve columns even if earlier steps renamed them\n",
    "    col_business = _find_col(df, [\"business_name\", \"restaurant\", \"place_name\", \"name\"])\n",
    "    col_author   = _find_col(df, [\"author_name\", \"user\", \"user_name\", \"reviewer\"])\n",
    "    col_text     = _find_col(df, [\"text\", \"review_text\", \"comment\", \"content\"])\n",
    "    col_rating   = _find_col(df, [\"rating\", \"stars\", \"score\", \"star_rating\"])\n",
    "\n",
    "    # Optional columns may or may not exist\n",
    "    col_photo          = _find_col(df, [\"photo\"], required=False)\n",
    "    col_rating_category= _find_col(df, [\"rating_category\"], required=False)\n",
    "\n",
    "    # Work on a copy\n",
    "    d = df.copy()\n",
    "\n",
    "    # Normalize whitespace for string fields (only if they exist)\n",
    "    for c in [col_business, col_author, col_text]:\n",
    "        d[c] = d[c].astype(str).str.strip()\n",
    "\n",
    "    # Coerce rating to numeric\n",
    "    d[col_rating] = pd.to_numeric(d[col_rating], errors=\"coerce\")\n",
    "\n",
    "    # Drop rows with missing/empty required fields\n",
    "    before = len(d)\n",
    "    d = d.dropna(subset=[col_business, col_author, col_text, col_rating])\n",
    "    # Remove empty-string rows in required text columns\n",
    "    for c in [col_business, col_author, col_text]:\n",
    "        d = d[d[c] != \"\"]\n",
    "    # Optionally enforce valid rating range (comment out if you want raw)\n",
    "    d = d[(d[col_rating] >= 1) & (d[col_rating] <= 5)]\n",
    "\n",
    "    removed = before - len(d)\n",
    "    print(f\"🧹 Cleaned dataset: {before} → {len(d)} rows (removed {removed})\")\n",
    "\n",
    "    # Rebuild output with your target column names in the same format\n",
    "    out = pd.DataFrame({\n",
    "        \"business_name\":    d[col_business],\n",
    "        \"author_name\":      d[col_author],\n",
    "        \"text\":             d[col_text],\n",
    "        \"rating\":           d[col_rating],\n",
    "    })\n",
    "\n",
    "    # Attach optional columns if present; else create with NaN\n",
    "    out[\"photo\"] = d[col_photo] if col_photo in d.columns else pd.Series([pd.NA]*len(d))\n",
    "    out[\"rating_category\"] = d[col_rating_category] if col_rating_category in d.columns else pd.Series([pd.NA]*len(d))\n",
    "\n",
    "    # Keep any extra columns? If you want to strictly keep only the six, return `out` as is.\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9692e1",
   "metadata": {},
   "source": [
    "## 🔧 Feature Engineering\n",
    "\n",
    "Extract comprehensive textual and non-textual features from review data for ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faad4094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ textstat module loaded successfully\n",
      "🔧 Extracting features...\n",
      "📋 Available columns: ['business_name', 'author_name', 'text', 'rating', 'photo', 'rating_category']\n",
      "✅ Using 'text' as the text column\n",
      "   Processing row 0/1100\n",
      "   Processing row 1000/1100\n",
      "✅ Feature extraction complete! Extracted 44 features\n",
      "\n",
      "📊 Dataset with features shape: (1100, 50)\n",
      "\n",
      "🔍 Feature columns extracted:\n",
      "    1. text_length\n",
      "    2. word_count\n",
      "    3. sentence_count\n",
      "    4. avg_word_length\n",
      "    5. uppercase_count\n",
      "    6. punctuation_count\n",
      "    7. digit_count\n",
      "    8. exclamation_count\n",
      "    9. question_count\n",
      "   10. uppercase_ratio\n",
      "   11. punctuation_ratio\n",
      "   12. digit_ratio\n",
      "   13. sentiment_pos\n",
      "   14. sentiment_neu\n",
      "   15. sentiment_neg\n",
      "   16. sentiment_compound\n",
      "   17. has_url\n",
      "   18. has_email\n",
      "   19. has_phone\n",
      "   20. first_person_count\n",
      "   21. second_person_count\n",
      "   22. third_person_count\n",
      "   23. first_person_ratio\n",
      "   24. second_person_ratio\n",
      "   25. third_person_ratio\n",
      "   26. spam_keyword_count\n",
      "   27. spam_keyword_ratio\n",
      "   28. restaurant_keyword_count\n",
      "   29. restaurant_keyword_ratio\n",
      "   30. flesch_reading_ease\n",
      "   31. flesch_kincaid_grade\n",
      "   32. all_caps_word_count\n",
      "   33. all_caps_ratio\n",
      "   34. unique_word_ratio\n",
      "   35. rating\n",
      "   36. is_extreme_rating\n",
      "   37. is_low_rating\n",
      "   38. is_high_rating\n",
      "   39. is_neutral_rating\n",
      "   40. author_name_length\n",
      "   41. author_has_numbers\n",
      "   42. author_all_caps\n",
      "   43. business_name_length\n",
      "   44. has_photo\n",
      "\n",
      "📈 Feature Statistics Summary:\n",
      "       text_length  word_count  sentence_count  avg_word_length  \\\n",
      "count     1100.000    1100.000        1100.000         1100.000   \n",
      "mean       110.834      20.052           2.145            4.807   \n",
      "std         69.154      12.978           1.233            0.947   \n",
      "min          5.000       1.000           1.000            3.269   \n",
      "25%         62.000      11.000           1.000            4.248   \n",
      "50%        104.000      19.000           2.000            4.615   \n",
      "75%        147.000      27.000           3.000            5.056   \n",
      "max        914.000     179.000          17.000           12.000   \n",
      "\n",
      "       uppercase_count  punctuation_count  digit_count  exclamation_count  \\\n",
      "count         1100.000           1100.000     1100.000           1100.000   \n",
      "mean             2.768              3.663        0.313              0.085   \n",
      "std              1.999              2.213        1.090              0.321   \n",
      "min              0.000              0.000        0.000              0.000   \n",
      "25%              1.000              2.000        0.000              0.000   \n",
      "50%              2.000              3.000        0.000              0.000   \n",
      "75%              3.000              5.000        0.000              0.000   \n",
      "max             23.000             22.000        9.000              4.000   \n",
      "\n",
      "       question_count  uppercase_ratio  ...    rating  is_extreme_rating  \\\n",
      "count        1100.000         1100.000  ...  1100.000           1100.000   \n",
      "mean            0.006            0.030  ...     3.913              0.491   \n",
      "std             0.080            0.024  ...     1.218              0.500   \n",
      "min             0.000            0.000  ...     1.000              0.000   \n",
      "25%             0.000            0.018  ...     3.000              0.000   \n",
      "50%             0.000            0.025  ...     4.000              0.000   \n",
      "75%             0.000            0.035  ...     5.000              1.000   \n",
      "max             1.000            0.333  ...     5.000              1.000   \n",
      "\n",
      "       is_low_rating  is_high_rating  is_neutral_rating  author_name_length  \\\n",
      "count       1100.000        1100.000           1100.000            1100.000   \n",
      "mean           0.138           0.705              0.156              12.005   \n",
      "std            0.345           0.456              0.363               2.069   \n",
      "min            0.000           0.000              0.000               6.000   \n",
      "25%            0.000           0.000              0.000              11.000   \n",
      "50%            0.000           1.000              0.000              12.000   \n",
      "75%            0.000           1.000              0.000              13.000   \n",
      "max            1.000           1.000              1.000              20.000   \n",
      "\n",
      "       author_has_numbers  author_all_caps  business_name_length  has_photo  \n",
      "count              1100.0           1100.0              1100.000     1100.0  \n",
      "mean                  0.0              0.0                12.300        1.0  \n",
      "std                   0.0              0.0                 5.085        0.0  \n",
      "min                   0.0              0.0                 3.000        1.0  \n",
      "25%                   0.0              0.0                 8.000        1.0  \n",
      "50%                   0.0              0.0                12.000        1.0  \n",
      "75%                   0.0              0.0                16.000        1.0  \n",
      "max                   0.0              0.0                31.000        1.0  \n",
      "\n",
      "[8 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from datetime import datetime\n",
    "\n",
    "# Try to import textstat, use fallback if not available\n",
    "try:\n",
    "    from textstat import flesch_reading_ease, flesch_kincaid_grade\n",
    "    TEXTSTAT_AVAILABLE = True\n",
    "    print(\"✅ textstat module loaded successfully\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ textstat module not found. Readability metrics will be set to default values.\")\n",
    "    print(\"💡 To install: pip install textstat\")\n",
    "    TEXTSTAT_AVAILABLE = False\n",
    "    \n",
    "    # Fallback functions\n",
    "    def flesch_reading_ease(text):\n",
    "        return 50.0  # Default neutral readability score\n",
    "    \n",
    "    def flesch_kincaid_grade(text):\n",
    "        return 8.0   # Default grade level\n",
    "\n",
    "class AdvancedFeatureExtractor:\n",
    "    \"\"\"Extract comprehensive textual and non-textual features from review data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sia = SentimentIntensityAnalyzer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # Common spam/promotional keywords\n",
    "        self.spam_keywords = [\n",
    "            'discount', 'promo', 'deal', 'offer', 'sale', 'buy', 'purchase', \n",
    "            'visit', 'click', 'link', 'website', 'free', 'win', 'prize'\n",
    "        ]\n",
    "        \n",
    "        # Restaurant-related keywords for relevancy\n",
    "        self.restaurant_keywords = [\n",
    "            'food', 'meal', 'eat', 'taste', 'flavor', 'delicious', 'menu',\n",
    "            'service', 'waiter', 'waitress', 'staff', 'cook', 'chef',\n",
    "            'restaurant', 'cafe', 'dine', 'dining', 'lunch', 'dinner',\n",
    "            'breakfast', 'appetizer', 'entree', 'dessert', 'drink'\n",
    "        ]\n",
    "        \n",
    "    def extract_textual_features(self, text):\n",
    "        \"\"\"Extract comprehensive textual features\"\"\"\n",
    "        features = {}\n",
    "        text_lower = text.lower()\n",
    "        words = text.split()\n",
    "        \n",
    "        # Basic text statistics\n",
    "        features['text_length'] = len(text)\n",
    "        features['word_count'] = len(words)\n",
    "        features['sentence_count'] = len([s for s in text.split('.') if s.strip()])\n",
    "        features['avg_word_length'] = np.mean([len(word) for word in words]) if words else 0\n",
    "        \n",
    "        # Character-level features\n",
    "        features['uppercase_count'] = sum(1 for c in text if c.isupper())\n",
    "        features['punctuation_count'] = sum(1 for c in text if c in string.punctuation)\n",
    "        features['digit_count'] = sum(1 for c in text if c.isdigit())\n",
    "        features['exclamation_count'] = text.count('!')\n",
    "        features['question_count'] = text.count('?')\n",
    "        \n",
    "        # Ratios\n",
    "        total_chars = len(text) if len(text) > 0 else 1\n",
    "        features['uppercase_ratio'] = features['uppercase_count'] / total_chars\n",
    "        features['punctuation_ratio'] = features['punctuation_count'] / total_chars\n",
    "        features['digit_ratio'] = features['digit_count'] / total_chars\n",
    "        \n",
    "        # Sentiment analysis\n",
    "        sentiment_scores = self.sia.polarity_scores(text)\n",
    "        features.update({\n",
    "            'sentiment_pos': sentiment_scores['pos'],\n",
    "            'sentiment_neu': sentiment_scores['neu'],\n",
    "            'sentiment_neg': sentiment_scores['neg'],\n",
    "            'sentiment_compound': sentiment_scores['compound']\n",
    "        })\n",
    "        \n",
    "        # URL and contact detection\n",
    "        features['has_url'] = bool(re.search(r'http[s]?://\\S+|www\\.\\w+\\.\\w+', text_lower))\n",
    "        features['has_email'] = bool(re.search(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text))\n",
    "        features['has_phone'] = bool(re.search(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', text))\n",
    "        \n",
    "        # Personal pronouns and perspective\n",
    "        first_person_words = ['i', 'me', 'my', 'myself', 'we', 'us', 'our']\n",
    "        second_person_words = ['you', 'your', 'yours']\n",
    "        third_person_words = ['he', 'she', 'it', 'they', 'them', 'their']\n",
    "        \n",
    "        words_lower = [w.lower().strip(string.punctuation) for w in words]\n",
    "        features['first_person_count'] = sum(1 for word in words_lower if word in first_person_words)\n",
    "        features['second_person_count'] = sum(1 for word in words_lower if word in second_person_words)\n",
    "        features['third_person_count'] = sum(1 for word in words_lower if word in third_person_words)\n",
    "        \n",
    "        total_words = len(words) if len(words) > 0 else 1\n",
    "        features['first_person_ratio'] = features['first_person_count'] / total_words\n",
    "        features['second_person_ratio'] = features['second_person_count'] / total_words\n",
    "        features['third_person_ratio'] = features['third_person_count'] / total_words\n",
    "        \n",
    "        # Spam/promotional indicators\n",
    "        features['spam_keyword_count'] = sum(1 for keyword in self.spam_keywords if keyword in text_lower)\n",
    "        features['spam_keyword_ratio'] = features['spam_keyword_count'] / total_words\n",
    "        \n",
    "        # Restaurant relevancy indicators\n",
    "        features['restaurant_keyword_count'] = sum(1 for keyword in self.restaurant_keywords if keyword in text_lower)\n",
    "        features['restaurant_keyword_ratio'] = features['restaurant_keyword_count'] / total_words\n",
    "        \n",
    "        # Readability metrics with fallback\n",
    "        try:\n",
    "            if TEXTSTAT_AVAILABLE:\n",
    "                features['flesch_reading_ease'] = flesch_reading_ease(text)\n",
    "                features['flesch_kincaid_grade'] = flesch_kincaid_grade(text)\n",
    "            else:\n",
    "                # Use simple fallback calculations\n",
    "                avg_sentence_length = features['word_count'] / max(features['sentence_count'], 1)\n",
    "                features['flesch_reading_ease'] = max(0, min(100, 206.835 - (1.015 * avg_sentence_length) - (84.6 * features['avg_word_length'])))\n",
    "                features['flesch_kincaid_grade'] = max(0, (0.39 * avg_sentence_length) + (11.8 * features['avg_word_length']) - 15.59)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Readability calculation failed: {e}\")\n",
    "            features['flesch_reading_ease'] = 50.0  # Default neutral score\n",
    "            features['flesch_kincaid_grade'] = 8.0   # Default grade level\n",
    "        \n",
    "        # All caps words (often indicates spam/shouting)\n",
    "        all_caps_words = [w for w in words if w.isupper() and len(w) > 1]\n",
    "        features['all_caps_word_count'] = len(all_caps_words)\n",
    "        features['all_caps_ratio'] = len(all_caps_words) / total_words\n",
    "        \n",
    "        # Repetitive patterns\n",
    "        unique_words = set(words_lower)\n",
    "        features['unique_word_ratio'] = len(unique_words) / total_words\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def extract_non_textual_features(self, row):\n",
    "        \"\"\"Extract non-textual features from metadata\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Rating-based features\n",
    "        features['rating'] = row['rating']\n",
    "        features['is_extreme_rating'] = 1 if row['rating'] in [1, 5] else 0\n",
    "        features['is_low_rating'] = 1 if row['rating'] <= 2 else 0\n",
    "        features['is_high_rating'] = 1 if row['rating'] >= 4 else 0\n",
    "        features['is_neutral_rating'] = 1 if row['rating'] == 3 else 0\n",
    "        \n",
    "        # Author-based features\n",
    "        if 'author_name' in row:\n",
    "            author_name = str(row['author_name'])\n",
    "            features['author_name_length'] = len(author_name)\n",
    "            features['author_has_numbers'] = 1 if any(c.isdigit() for c in author_name) else 0\n",
    "            features['author_all_caps'] = 1 if author_name.isupper() else 0\n",
    "        else:\n",
    "            features['author_name_length'] = 0\n",
    "            features['author_has_numbers'] = 0\n",
    "            features['author_all_caps'] = 0\n",
    "        \n",
    "        # Business-based features\n",
    "        if 'business_name' in row:\n",
    "            business_name = str(row['business_name'])\n",
    "            features['business_name_length'] = len(business_name)\n",
    "        else:\n",
    "            features['business_name_length'] = 0\n",
    "        \n",
    "        # Photo presence\n",
    "        if 'photo' in row and pd.notna(row['photo']):\n",
    "            features['has_photo'] = 1\n",
    "        else:\n",
    "            features['has_photo'] = 0\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def extract_all_features(self, df):\n",
    "        \"\"\"Extract all features for the entire dataset\"\"\"\n",
    "        print(\"🔧 Extracting features...\")\n",
    "        if not TEXTSTAT_AVAILABLE:\n",
    "            print(\"⚠️ Using fallback readability calculations (textstat not available)\")\n",
    "        \n",
    "        # 🔍 COLUMN NAME DETECTION AND VALIDATION\n",
    "        print(f\"📋 Available columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Find the text column dynamically\n",
    "        text_column = None\n",
    "        possible_text_columns = ['text', 'review_text', 'review', 'content', 'comment']\n",
    "        \n",
    "        for col in possible_text_columns:\n",
    "            if col in df.columns:\n",
    "                text_column = col\n",
    "                break\n",
    "        \n",
    "        if text_column is None:\n",
    "            raise ValueError(f\"❌ No text column found! Available columns: {list(df.columns)}\")\n",
    "        \n",
    "        print(f\"✅ Using '{text_column}' as the text column\")\n",
    "        \n",
    "        all_features = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if idx % 1000 == 0:\n",
    "                print(f\"   Processing row {idx}/{len(df)}\")\n",
    "            \n",
    "            # Use the detected text column instead of hardcoded 'review_text'\n",
    "            text_features = self.extract_textual_features(row[text_column])\n",
    "            non_text_features = self.extract_non_textual_features(row)\n",
    "            \n",
    "            # Combine all features\n",
    "            combined_features = {**text_features, **non_text_features}\n",
    "            all_features.append(combined_features)\n",
    "        \n",
    "        features_df = pd.DataFrame(all_features)\n",
    "        print(f\"✅ Feature extraction complete! Extracted {len(features_df.columns)} features\")\n",
    "        return features_df\n",
    "\n",
    "# Initialize feature extractor\n",
    "feature_extractor = AdvancedFeatureExtractor()\n",
    "\n",
    "# Extract features from the dataset\n",
    "features_df = feature_extractor.extract_all_features(df)\n",
    "\n",
    "# Combine with original data\n",
    "df_with_features = pd.concat([df.reset_index(drop=True), features_df], axis=1)\n",
    "\n",
    "print(f\"\\n📊 Dataset with features shape: {df_with_features.shape}\")\n",
    "print(f\"\\n🔍 Feature columns extracted:\")\n",
    "for i, col in enumerate(features_df.columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "# Display feature statistics\n",
    "print(\"\\n📈 Feature Statistics Summary:\")\n",
    "print(features_df.describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff5045",
   "metadata": {},
   "source": [
    "## 🚫 Policy Detection Module\n",
    "\n",
    "Implement rule-based and ML-based policy violation detectors for the three main categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "195e4d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Policy Violation Detection Results:\n",
      "==================================================\n",
      "\n",
      "📝 Review 1: 'Great food and excellent service! The pasta was am...'\n",
      "🚨 Violation: False\n",
      "💡 Details: No violation detected\n",
      "\n",
      "📝 Review 2: 'Call us now for the best deals! Visit our website ...'\n",
      "🚨 Violation: True\n",
      "📋 Type: advertisement\n",
      "🎯 Confidence: 0.333\n",
      "📊 All Scores: {'advertisement': 0.3333333333333333, 'irrelevant_content': 0, 'rant_without_visit': 0.0}\n",
      "💡 Details: Primary violation: advertisement\n",
      "\n",
      "📝 Review 3: 'I hate politics and this election is terrible. Not...'\n",
      "🚨 Violation: False\n",
      "💡 Details: No violation detected\n",
      "\n",
      "📝 Review 4: 'I heard this place is awful, never been there but ...'\n",
      "🚨 Violation: True\n",
      "📋 Type: rant_without_visit\n",
      "🎯 Confidence: 0.357\n",
      "📊 All Scores: {'advertisement': 0.0, 'irrelevant_content': 0, 'rant_without_visit': 0.35714285714285715}\n",
      "💡 Details: Primary violation: rant_without_visit\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import Dict, Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PolicyViolationDetector:\n",
    "    \"\"\"Rule-based policy violation detector for restaurant reviews\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Advertisement detection patterns\n",
    "        self.ad_patterns = [\n",
    "            r'\\b(?:call|text|contact|visit|website|phone|email|dm|message)\\s+(?:us|me|now|today)\\b',\n",
    "            r'\\b(?:best|cheapest|lowest|highest|top)\\s+(?:price|deal|offer|service)\\b',\n",
    "            r'\\b(?:free|discount|sale|promo|special|offer|deal)\\b.*\\b(?:today|now|limited|expires)\\b',\n",
    "            r'\\b(?:check|visit|see|follow)\\s+(?:our|my)\\s+(?:website|page|profile|instagram|facebook)\\b',\n",
    "            r'\\b(?:book|order|reserve)\\s+(?:now|today|online)\\b',\n",
    "            r'(?:www\\.|http|\\.com|\\.org|\\.net)',\n",
    "            r'\\b(?:delivery|takeout|pickup)\\s+(?:available|service)\\b',\n",
    "            r'\\b(?:new|grand)\\s+opening\\b',\n",
    "            r'\\b(?:hiring|recruiting|looking\\s+for)\\b'\n",
    "        ]\n",
    "        \n",
    "        # Irrelevant content patterns\n",
    "        self.irrelevant_patterns = [\n",
    "            r'\\b(?:politics|election|government|president|mayor|council)\\b',\n",
    "            r'\\b(?:religion|church|mosque|temple|spiritual)\\b',\n",
    "            r'\\b(?:personal|relationship|dating|marriage|divorce)\\b',\n",
    "            r'\\b(?:medical|health|doctor|hospital|surgery|medicine)\\b',\n",
    "            r'\\b(?:school|education|homework|exam|grade)\\b',\n",
    "            r'\\b(?:weather|rain|snow|sunny|cloudy)\\b',\n",
    "            r'\\b(?:sports|game|match|team|player|score)\\b',\n",
    "            r'\\b(?:movie|film|tv|show|actor|actress)\\b',\n",
    "            r'\\b(?:music|song|concert|band|album)\\b',\n",
    "            r'\\b(?:car|vehicle|traffic|parking|driving)\\b'\n",
    "        ]\n",
    "        \n",
    "        # Rant without visit patterns\n",
    "        self.rant_patterns = [\n",
    "            r'\\b(?:never\\s+(?:been|visited|went)|haven\\'t\\s+(?:been|visited))\\b',\n",
    "            r'\\b(?:heard|read|saw)\\s+(?:about|reviews|complaints)\\b',\n",
    "            r'\\b(?:based\\s+on|according\\s+to)\\s+(?:reviews|others|friends)\\b',\n",
    "            r'\\b(?:planning\\s+to|might|considering)\\s+(?:visit|go|try)\\b',\n",
    "            r'\\b(?:looks|seems|appears)\\s+(?:bad|terrible|awful|horrible)\\b',\n",
    "            r'\\b(?:reputation|known\\s+for)\\s+(?:being|having)\\b',\n",
    "            r'\\b(?:everyone\\s+says|people\\s+say|i\\'ve\\s+heard)\\b'\n",
    "        ]\n",
    "        \n",
    "        # Restaurant-related keywords (for relevance check)\n",
    "        self.restaurant_keywords = [\n",
    "            'food', 'meal', 'dish', 'restaurant', 'cafe', 'bar', 'service', 'waiter', 'waitress',\n",
    "            'menu', 'order', 'taste', 'flavor', 'delicious', 'cook', 'chef', 'kitchen',\n",
    "            'eat', 'dine', 'dining', 'lunch', 'dinner', 'breakfast', 'appetizer', 'dessert',\n",
    "            'drink', 'beverage', 'wine', 'beer', 'cocktail', 'table', 'reservation', 'staff'\n",
    "        ]\n",
    "    \n",
    "    def detect_advertisement(self, text: str) -> Tuple[bool, float, List[str]]:\n",
    "        \"\"\"Detect advertisement content\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        matches = []\n",
    "        score = 0\n",
    "        \n",
    "        for pattern in self.ad_patterns:\n",
    "            if re.search(pattern, text_lower):\n",
    "                matches.append(pattern)\n",
    "                score += 1\n",
    "        \n",
    "        # Normalize score\n",
    "        confidence = min(score / len(self.ad_patterns), 1.0)\n",
    "        is_ad = confidence > 0.3\n",
    "        \n",
    "        return is_ad, confidence, matches\n",
    "    \n",
    "    def detect_irrelevant_content(self, text: str) -> Tuple[bool, float, List[str]]:\n",
    "        \"\"\"Detect irrelevant content\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        matches = []\n",
    "        irrelevant_score = 0\n",
    "        relevant_score = 0\n",
    "        \n",
    "        # Check for irrelevant patterns\n",
    "        for pattern in self.irrelevant_patterns:\n",
    "            if re.search(pattern, text_lower):\n",
    "                matches.append(pattern)\n",
    "                irrelevant_score += 1\n",
    "        \n",
    "        # Check for restaurant relevance\n",
    "        for keyword in self.restaurant_keywords:\n",
    "            if keyword in text_lower:\n",
    "                relevant_score += 1\n",
    "        \n",
    "        # Calculate confidence\n",
    "        total_patterns = len(self.irrelevant_patterns)\n",
    "        if irrelevant_score > 0 and relevant_score == 0:\n",
    "            confidence = min(irrelevant_score / total_patterns, 1.0)\n",
    "            is_irrelevant = confidence > 0.2\n",
    "        else:\n",
    "            confidence = max(0, (irrelevant_score - relevant_score * 0.5) / total_patterns)\n",
    "            is_irrelevant = confidence > 0.3\n",
    "        \n",
    "        return is_irrelevant, max(confidence, 0), matches\n",
    "    \n",
    "    def detect_rant_without_visit(self, text: str) -> Tuple[bool, float, List[str]]:\n",
    "        \"\"\"Detect rants without actual visit\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        matches = []\n",
    "        score = 0\n",
    "        \n",
    "        for pattern in self.rant_patterns:\n",
    "            if re.search(pattern, text_lower):\n",
    "                matches.append(pattern)\n",
    "                score += 1\n",
    "        \n",
    "        # Additional checks for negative sentiment without visit indicators\n",
    "        negative_words = ['terrible', 'awful', 'horrible', 'worst', 'disgusting', 'hate']\n",
    "        visit_indicators = ['went', 'visited', 'ate', 'ordered', 'tried', 'had dinner', 'had lunch']\n",
    "        \n",
    "        has_negative = any(word in text_lower for word in negative_words)\n",
    "        has_visit = any(indicator in text_lower for indicator in visit_indicators)\n",
    "        \n",
    "        if has_negative and not has_visit:\n",
    "            score += 0.5\n",
    "        \n",
    "        # Normalize score\n",
    "        confidence = min(score / len(self.rant_patterns), 1.0)\n",
    "        is_rant = confidence > 0.3\n",
    "        \n",
    "        return is_rant, confidence, matches\n",
    "    \n",
    "    def analyze_review(self, text: str) -> Dict:\n",
    "        \"\"\"Comprehensive policy violation analysis\"\"\"\n",
    "        if not text or len(text.strip()) < 10:\n",
    "            return {\n",
    "                'is_violation': False,\n",
    "                'violation_type': None,\n",
    "                'confidence': 0.0,\n",
    "                'details': 'Text too short for analysis'\n",
    "            }\n",
    "        \n",
    "        # Run all detectors\n",
    "        is_ad, ad_conf, ad_matches = self.detect_advertisement(text)\n",
    "        is_irrelevant, irr_conf, irr_matches = self.detect_irrelevant_content(text)\n",
    "        is_rant, rant_conf, rant_matches = self.detect_rant_without_visit(text)\n",
    "        \n",
    "        # Determine primary violation\n",
    "        violations = [\n",
    "            ('advertisement', ad_conf, ad_matches),\n",
    "            ('irrelevant_content', irr_conf, irr_matches),\n",
    "            ('rant_without_visit', rant_conf, rant_matches)\n",
    "        ]\n",
    "        \n",
    "        violations.sort(key=lambda x: x[1], reverse=True)\n",
    "        primary_violation = violations[0]\n",
    "        \n",
    "        is_violation = primary_violation[1] > 0.3\n",
    "        \n",
    "        return {\n",
    "            'is_violation': is_violation,\n",
    "            'violation_type': primary_violation[0] if is_violation else None,\n",
    "            'confidence': primary_violation[1],\n",
    "            'all_scores': {\n",
    "                'advertisement': ad_conf,\n",
    "                'irrelevant_content': irr_conf,\n",
    "                'rant_without_visit': rant_conf\n",
    "            },\n",
    "            'matches': primary_violation[2] if is_violation else [],\n",
    "            'details': f\"Primary violation: {primary_violation[0]}\" if is_violation else \"No violation detected\"\n",
    "        }\n",
    "\n",
    "# Initialize policy detector\n",
    "policy_detector = PolicyViolationDetector()\n",
    "\n",
    "# Test with sample reviews\n",
    "test_reviews = [\n",
    "    \"Great food and excellent service! The pasta was amazing.\",\n",
    "    \"Call us now for the best deals! Visit our website www.example.com\",\n",
    "    \"I hate politics and this election is terrible. Nothing about food here.\",\n",
    "    \"I heard this place is awful, never been there but people say it's bad.\"\n",
    "]\n",
    "\n",
    "print(\"🔍 Policy Violation Detection Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, review in enumerate(test_reviews, 1):\n",
    "    result = policy_detector.analyze_review(review)\n",
    "    print(f\"\\n📝 Review {i}: '{review[:50]}...'\")\n",
    "    print(f\"🚨 Violation: {result['is_violation']}\")\n",
    "    if result['is_violation']:\n",
    "        print(f\"📋 Type: {result['violation_type']}\")\n",
    "        print(f\"🎯 Confidence: {result['confidence']:.3f}\")\n",
    "        print(f\"📊 All Scores: {result['all_scores']}\")\n",
    "    print(f\"💡 Details: {result['details']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758bcf29",
   "metadata": {},
   "source": [
    "## 🤖 Gemma 3 12B Model Integration\n",
    "\n",
    "Using Google's Gemma 3 12B model with HuggingFace Inference Client for advanced policy detection and review classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb91c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Initializing Gemma 3 12B Classifier...\n",
      "💡 Note: You may need a HuggingFace token for full functionality\n",
      "✅ Successfully initialized Gemma 3 12B model: google/gemma-3-12b-it\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "import os\n",
    "\n",
    "class GemmaReviewClassifier:\n",
    "    \"\"\"Advanced review classifier using Gemma 3 12B model\"\"\"\n",
    "    \n",
    "    def __init__(self, hf_token: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize Gemma classifier\n",
    "        \n",
    "        Args:\n",
    "            hf_token: HuggingFace token (optional, can be set in environment)\n",
    "        \"\"\"\n",
    "        self.model_name = \"google/gemma-3-12b-it\"\n",
    "        \n",
    "        # Set up HuggingFace token\n",
    "        if hf_token:\n",
    "            os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = hf_token\n",
    "        \n",
    "        try:\n",
    "            self.client = InferenceClient(\n",
    "                model=self.model_name,\n",
    "                token=hf_token or os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "            )\n",
    "            print(f\"✅ Successfully initialized Gemma 3 12B model: {self.model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Warning: Could not initialize model. Error: {e}\")\n",
    "            print(\"💡 Note: You may need to provide a HuggingFace token or use a fallback model\")\n",
    "            self.client = None\n",
    "    \n",
    "    def create_policy_prompt(self, review_text: str) -> str:\n",
    "        \"\"\"Create a structured prompt for policy violation detection\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"You are an expert content moderator for restaurant review platforms. Analyze the following review and determine if it violates any of these policies:\n",
    "\n",
    "1. **Advertisement**: Reviews that promote businesses, include contact information, or solicit customers\n",
    "2. **Irrelevant Content**: Reviews about topics unrelated to the restaurant experience\n",
    "3. **Rant Without Visit**: Negative reviews from people who haven't actually visited the restaurant\n",
    "\n",
    "Review to analyze: \"{review_text}\"\n",
    "\n",
    "Please respond with a JSON object in this exact format:\n",
    "{{\n",
    "    \"is_violation\": true/false,\n",
    "    \"violation_type\": \"advertisement\" or \"irrelevant_content\" or \"rant_without_visit\" or null,\n",
    "    \"confidence\": 0.0-1.0,\n",
    "    \"reasoning\": \"Brief explanation of your decision\",\n",
    "    \"is_trustworthy\": true/false,\n",
    "    \"sentiment\": \"positive\" or \"negative\" or \"neutral\"\n",
    "}}\n",
    "\n",
    "Focus on:\n",
    "- Clear policy violations vs. legitimate reviews\n",
    "- Evidence of actual restaurant visit\n",
    "- Commercial intent vs. genuine feedback\n",
    "- Restaurant relevance vs. off-topic content\n",
    "\n",
    "Response:\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def create_quality_prompt(self, review_text: str) -> str:\n",
    "        \"\"\"Create a prompt for review quality assessment\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"As an expert in restaurant review quality assessment, evaluate this review for trustworthiness and usefulness:\n",
    "\n",
    "Review: \"{review_text}\"\n",
    "\n",
    "Assess the review on these dimensions:\n",
    "1. **Authenticity**: Does this seem like a genuine customer experience?\n",
    "2. **Specificity**: Does it provide specific details about food, service, or atmosphere?\n",
    "3. **Helpfulness**: Would this review help other customers make decisions?\n",
    "4. **Balance**: Does it provide constructive feedback rather than just complaints?\n",
    "\n",
    "Respond with JSON:\n",
    "{{\n",
    "    \"quality_score\": 0.0-1.0,\n",
    "    \"authenticity\": 0.0-1.0,\n",
    "    \"specificity\": 0.0-1.0,\n",
    "    \"helpfulness\": 0.0-1.0,\n",
    "    \"is_spam\": true/false,\n",
    "    \"is_fake\": true/false,\n",
    "    \"key_insights\": [\"insight1\", \"insight2\"],\n",
    "    \"recommendation\": \"keep\" or \"flag\" or \"remove\"\n",
    "}}\n",
    "\n",
    "Response:\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def classify_review(self, review_text: str, max_retries: int = 3) -> Dict:\n",
    "        \"\"\"Classify a review for policy violations and quality\"\"\"\n",
    "        \n",
    "        if not self.client:\n",
    "            return {\n",
    "                \"error\": \"Model not available\",\n",
    "                \"fallback\": \"Using rule-based detection only\"\n",
    "            }\n",
    "        \n",
    "        if not review_text or len(review_text.strip()) < 5:\n",
    "            return {\n",
    "                \"error\": \"Review text too short\",\n",
    "                \"is_violation\": False,\n",
    "                \"quality_score\": 0.0\n",
    "            }\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Policy violation detection\n",
    "        try:\n",
    "            policy_prompt = self.create_policy_prompt(review_text)\n",
    "            \n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    policy_response = self.client.text_generation(\n",
    "                        policy_prompt,\n",
    "                        max_new_tokens=200,\n",
    "                        temperature=0.1,\n",
    "                        do_sample=True,\n",
    "                        return_full_text=False\n",
    "                    )\n",
    "                    \n",
    "                    # Parse JSON response\n",
    "                    policy_data = self._parse_json_response(policy_response)\n",
    "                    if policy_data:\n",
    "                        results['policy'] = policy_data\n",
    "                        break\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    if attempt == max_retries - 1:\n",
    "                        results['policy_error'] = str(e)\n",
    "                    time.sleep(1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            results['policy_error'] = str(e)\n",
    "        \n",
    "        # Quality assessment\n",
    "        try:\n",
    "            quality_prompt = self.create_quality_prompt(review_text)\n",
    "            \n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    quality_response = self.client.text_generation(\n",
    "                        quality_prompt,\n",
    "                        max_new_tokens=200,\n",
    "                        temperature=0.1,\n",
    "                        do_sample=True,\n",
    "                        return_full_text=False\n",
    "                    )\n",
    "                    \n",
    "                    # Parse JSON response\n",
    "                    quality_data = self._parse_json_response(quality_response)\n",
    "                    if quality_data:\n",
    "                        results['quality'] = quality_data\n",
    "                        break\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    if attempt == max_retries - 1:\n",
    "                        results['quality_error'] = str(e)\n",
    "                    time.sleep(1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            results['quality_error'] = str(e)\n",
    "        \n",
    "        return self._consolidate_results(results)\n",
    "    \n",
    "    def _parse_json_response(self, response: str) -> Optional[Dict]:\n",
    "        \"\"\"Parse JSON from model response\"\"\"\n",
    "        try:\n",
    "            # Find JSON in response\n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                json_str = response[start_idx:end_idx]\n",
    "                return json.loads(json_str)\n",
    "            \n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response: {response[:200]}...\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _consolidate_results(self, results: Dict) -> Dict:\n",
    "        \"\"\"Consolidate policy and quality results\"\"\"\n",
    "        \n",
    "        consolidated = {\n",
    "            'timestamp': time.time(),\n",
    "            'model_used': self.model_name\n",
    "        }\n",
    "        \n",
    "        # Policy results\n",
    "        if 'policy' in results:\n",
    "            policy = results['policy']\n",
    "            consolidated.update({\n",
    "                'is_violation': policy.get('is_violation', False),\n",
    "                'violation_type': policy.get('violation_type'),\n",
    "                'policy_confidence': policy.get('confidence', 0.0),\n",
    "                'is_trustworthy': policy.get('is_trustworthy', True),\n",
    "                'sentiment': policy.get('sentiment', 'neutral'),\n",
    "                'policy_reasoning': policy.get('reasoning', '')\n",
    "            })\n",
    "        else:\n",
    "            consolidated.update({\n",
    "                'is_violation': False,\n",
    "                'violation_type': None,\n",
    "                'policy_confidence': 0.0,\n",
    "                'policy_error': results.get('policy_error', 'Unknown error')\n",
    "            })\n",
    "        \n",
    "        # Quality results\n",
    "        if 'quality' in results:\n",
    "            quality = results['quality']\n",
    "            consolidated.update({\n",
    "                'quality_score': quality.get('quality_score', 0.5),\n",
    "                'authenticity': quality.get('authenticity', 0.5),\n",
    "                'specificity': quality.get('specificity', 0.5),\n",
    "                'helpfulness': quality.get('helpfulness', 0.5),\n",
    "                'is_spam': quality.get('is_spam', False),\n",
    "                'is_fake': quality.get('is_fake', False),\n",
    "                'key_insights': quality.get('key_insights', []),\n",
    "                'recommendation': quality.get('recommendation', 'keep')\n",
    "            })\n",
    "        else:\n",
    "            consolidated.update({\n",
    "                'quality_score': 0.5,\n",
    "                'quality_error': results.get('quality_error', 'Unknown error')\n",
    "            })\n",
    "        \n",
    "        return consolidated\n",
    "    \n",
    "    def batch_classify(self, reviews: List[str], batch_size: int = 5) -> List[Dict]:\n",
    "        \"\"\"Classify multiple reviews in batches\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i in range(0, len(reviews), batch_size):\n",
    "            batch = reviews[i:i + batch_size]\n",
    "            print(f\"🔄 Processing batch {i//batch_size + 1}/{(len(reviews)-1)//batch_size + 1}\")\n",
    "            \n",
    "            batch_results = []\n",
    "            for review in batch:\n",
    "                result = self.classify_review(review)\n",
    "                batch_results.append(result)\n",
    "                time.sleep(0.5)  # Rate limiting\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize Gemma classifier\n",
    "print(\"🚀 Initializing Gemma 3 12B Classifier...\")\n",
    "print(\"💡 Note: You may need a HuggingFace token for full functionality\")\n",
    "\n",
    "# For Colab users, uncomment and add your token:\n",
    "# gemma_classifier = GemmaReviewClassifier(hf_token=\"your_hf_token_here\")\n",
    "\n",
    "# For token-less testing:\n",
    "try:\n",
    "    gemma_classifier = GemmaReviewClassifier()\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not initialize Gemma model: {e}\")\n",
    "    print(\"🔄 Continuing with rule-based detection only...\")\n",
    "    gemma_classifier = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c4fcfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🤖 SAMPLE REVIEW CLASSIFICATION - 200 REVIEWS\n",
      "======================================================================\n",
      "🧪 Testing JSONL parsing on your review-other.json file...\n",
      "✅ Successfully parsed sample data:\n",
      "📊 Shape: (5, 8)\n",
      "📋 Original columns: ['user_id', 'name', 'time', 'rating', 'text', 'pics', 'resp', 'gmap_id']\n",
      "🧹 Applying Kaggle-style cleaning to DataFrame with columns: ['user_id', 'name', 'time', 'rating', 'text', 'pics', 'resp', 'gmap_id']\n",
      "🧹 Cleaned dataset: 5 → 5 rows (removed 0)\n",
      "✅ Cleaned sample:\n",
      "📊 Shape: (5, 6)\n",
      "📋 Columns: ['text', 'rating', 'business_name', 'author_name', 'photo', 'rating_category']\n",
      "🔍 First few rows:\n",
      "                                                text  rating    business_name  \\\n",
      "0  Andrea is amazing. Our dog loves her and she a...       5  Amber Thibeault   \n",
      "1  Andrea does a wonderful  job  with our wild Pr...       5           Esther   \n",
      "2                                  Never called back       1      Bob Barrett   \n",
      "\n",
      "  author_name photo rating_category  \n",
      "0      user_0  <NA>            <NA>  \n",
      "1      user_1  <NA>            <NA>  \n",
      "2      user_2  <NA>            <NA>  \n",
      "📂 Searching for additional review datasets...\n",
      "🔄 Attempting to load ./review-other.json...\n",
      "📄 Detected JSONL format (JSON Lines) - parsing line by line...\n",
      "✅ Successfully parsed 162952 JSON objects from JSONL file\n",
      "✅ Created DataFrame with 162952 rows and 8 columns\n",
      "📋 Original columns: ['user_id', 'name', 'time', 'rating', 'text', 'pics', 'resp', 'gmap_id']\n",
      "🧹 Applying Kaggle-style cleaning to DataFrame with columns: ['user_id', 'name', 'time', 'rating', 'text', 'pics', 'resp', 'gmap_id']\n",
      "🧹 Cleaned dataset: 162952 → 105249 rows (removed 57703)\n",
      "ℹ️ File not found: ./Google Local review data.html\n",
      "🔄 Merging 1 additional datasets with Kaggle data...\n",
      "   Adding dataset 1/1 with 145320 rows\n",
      "📊 Merged dataset statistics:\n",
      "   Total reviews: 95495\n",
      "   Kaggle reviews: 1100\n",
      "   Additional reviews: 94395\n",
      "   Duplicates removed: 50925\n",
      "🎯 Sampling 200 reviews from 95495 total reviews...\n",
      "📊 Final sample size: 200 reviews\n",
      "📋 Final columns: ['business_name', 'author_name', 'text', 'rating', 'photo', 'rating_category']\n",
      "📝 Using 'text' column for review text\n",
      "\n",
      "📊 SAMPLE DATASET INFORMATION:\n",
      "   Total reviews for processing: 200\n",
      "   Columns: ['business_name', 'author_name', 'text', 'rating', 'photo', 'rating_category']\n",
      "   Rating distribution: {1.0: np.int64(15), 2.0: np.int64(2), 3.0: np.int64(9), 4.0: np.int64(17), 5.0: np.int64(157)}\n",
      "\n",
      "🔍 Sample of data:\n",
      "   1. Rating: 5.0 | Text: Awsome gifts\n",
      "   2. Rating: 5.0 | Text: Love the history and experience!\n",
      "   3. Rating: 5.0 | Text: Great company for people that are really trying to get their life together..\n",
      "   4. Rating: 5.0 | Text: I live in Georgia but own a property in Northeast Illinois. Ryan worked with me from a distance with...\n",
      "   5. Rating: 5.0 | Text: Excellent quality and the price isn’t too bad.\n",
      "\n",
      "🔄 Processing 200 reviews with Gemma classifier...\n",
      "🚨 RESULTS (Text + Labels):\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #1: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Awsome gifts\"\n",
      "\n",
      "📝 Review #2: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Love the history and experience!\"\n",
      "\n",
      "📝 Review #3: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great company for people that are really trying to get their life together..\"\n",
      "\n",
      "📝 Review #4: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I live in Georgia but own a property in Northeast Illinois. Ryan worked with me from a distance with a mouse problem we were having. He was reliable, ...\"\n",
      "\n",
      "📝 Review #5: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Excellent quality and the price isn’t too bad.\"\n",
      "\n",
      "📝 Review #6: LEGITIMATE\n",
      "⭐ Rating: 3.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Decent selection of food. Staff was sort of friendly. I don't remember seeing my waiter much. It was an interesting experience to say the least. Food ...\"\n",
      "\n",
      "📝 Review #7: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Incredible customer service. I’ve ordered a couple of swimsuits and dresses from this site. I recently ordered a jumper for my daughter and I to match...\"\n",
      "\n",
      "📝 Review #8: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Cool little coffee shop!\"\n",
      "\n",
      "📝 Review #9: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"A less visited sight,  but very neat. If you are walking from the Washington monument over to Lincoln, I'd recommend it. It's lovely, we had a small l...\"\n",
      "\n",
      "📊 Progress: 10/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #10: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"The clothes are well- made. Especially the ones I bought that are for winter ( very thick and has 80% cotton) This is my first time buying from them a...\"\n",
      "\n",
      "📝 Review #11: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Awesome experience to work with\n",
      "Would do it again\n",
      "\n",
      "And the character did amazing everyone loved him\"\n",
      "\n",
      "📝 Review #12: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) Lots of variety of products and great price. To highlight above all the excellent customer service (in our case from the hand o...\"\n",
      "\n",
      "📝 Review #13: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Easy to book online. Quick response. Included a free (download) guide to Rome. I look forward to traveling on ItaliaRail.\"\n",
      "\n",
      "📝 Review #14: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Needed some advice on how to insulate my commercial roll up door and they were right on it!  Very helpful!\"\n",
      "\n",
      "📝 Review #15: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Yeah the food is not that great and it takes forever to arrive. They say 25 minutes but you may wait until the 2nd coming, or until you hit menopause....\"\n",
      "\n",
      "📝 Review #16: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Wonderful menu, excellent service, and who doesn't love a glass waterfall?\"\n",
      "\n",
      "📝 Review #17: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Very polite and quick solution of my request😉👍\"\n",
      "\n",
      "📝 Review #18: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Used Bellhop for an out of state move to D.C. After getting quotes and reading reviews for 4 companies, Bellhop was the most affordable and most consi...\"\n",
      "\n",
      "📝 Review #19: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Shakari led us through historical and geographical insights about the recipe we were cooking and then easily led us into the preparation of the meal, ...\"\n",
      "\n",
      "📊 Progress: 20/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #20: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"First I want to say that the assistance and support I received, particularly as a new customer from ADM and from the owner and founder, Mr. Anthony Da...\"\n",
      "\n",
      "📝 Review #21: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"The best place in DC by far.  It's charming , beautiful gardens and walkways.\"\n",
      "\n",
      "📝 Review #22: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Amazing place!!!\"\n",
      "\n",
      "📝 Review #23: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Historical place\"\n",
      "\n",
      "📝 Review #24: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great service. Use weekly\"\n",
      "\n",
      "📝 Review #25: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Best udon in Paris. Well Korean celebrities visits it too. Just a little bit crowded.\"\n",
      "\n",
      "📝 Review #26: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Susie B was so helpful with my exchange. She was pleasant, efficient and fast in her response. I love PatPat clothes for my grand babies. The clothes ...\"\n",
      "\n",
      "📝 Review #27: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Hockey!!!!!!\"\n",
      "\n",
      "📝 Review #28: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Easy order. Took a little bit to get but the communication was great. When I received my order I was thrilled. 3 custom necklaces all perfect and I lo...\"\n",
      "\n",
      "📝 Review #29: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I love it, it was crowded\"\n",
      "\n",
      "📊 Progress: 30/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #30: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Jonny Wu is amazing! Best show ever!\"\n",
      "\n",
      "📝 Review #31: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Love the view.  Very unique\"\n",
      "\n",
      "📝 Review #32: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I found everything I needed. Staff were helpful and considerate!!\"\n",
      "\n",
      "📝 Review #33: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Their work is amazing!!! Thank you!!\"\n",
      "\n",
      "📝 Review #34: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"fast and friendly no scams here removed the account that i forgot the info for   it and now its good to use..\"\n",
      "\n",
      "📝 Review #35: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"They went out of their way to help me with my car out of their usual area of service on New YEARS Eve! I am so grateful and pleased with the service t...\"\n",
      "\n",
      "📝 Review #36: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Clyde's has been a favorite of mine for years.\"\n",
      "\n",
      "📝 Review #37: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Very good training. The devil is in the detail and Bradley goes into great detail at a wonderful pace. Thoroughly recommend!\"\n",
      "\n",
      "📝 Review #38: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"This guys are great! I called with an Amazon Issue and they told me to not hire anybody yet and to not spend money in something that could affect me. ...\"\n",
      "\n",
      "📝 Review #39: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"This was the first time using movers and I'm glad I went with Bellhops! Yann, Nicholas, and Joshua were quick and efficient. They really hustled even ...\"\n",
      "\n",
      "📊 Progress: 40/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #40: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I'm so glad I came upon this site. They had so many options and were flexible in their wording options. I decided not to pay for some of the embellish...\"\n",
      "\n",
      "📝 Review #41: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Pretty cool place to watch the planes take off. Free parking. Toilets on site are dirty. Use the bathroom before you go here.\"\n",
      "\n",
      "📝 Review #42: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Hazel provides excellent customer services.\"\n",
      "\n",
      "📝 Review #43: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Good amount of food choices, seating is nice\"\n",
      "\n",
      "📝 Review #44: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Jerell and his team were super awesome! I'm new to lawn care and landscaping and Jerell was super patient in answering all of my questions (regardless...\"\n",
      "\n",
      "📝 Review #45: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Had a great time at Prayer March 2020\"\n",
      "\n",
      "📝 Review #46: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Wasn’t sure if it was legit because I couldn’t find that many reviews but rest assured they got the goods and I am so glad :)\"\n",
      "\n",
      "📝 Review #47: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Had a great experience with Air Control LLC. The technician was running late b/c of traffic and was super apologetic when he arrives. Overall, the tec...\"\n",
      "\n",
      "📝 Review #48: LEGITIMATE\n",
      "⭐ Rating: 3.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) Nicely at Potomac\n",
      "\n",
      "(Original)\n",
      "Pent ved Potomac\"\n",
      "\n",
      "📝 Review #49: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Very fast and helpful customer service. Jayson was friendly and efficient in handling my return items. I bought a suze to big. I will be but I more fo...\"\n",
      "\n",
      "📊 Progress: 50/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #50: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Nick is very thorough  and honest\n",
      "Thanks for a great  inspection.\"\n",
      "\n",
      "📝 Review #51: LEGITIMATE\n",
      "⭐ Rating: 2.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"On my 3rd device in just a little over a month... first one didn’t hit right every time and i exchanged it where i got it. The second lasted a little ...\"\n",
      "\n",
      "📝 Review #52: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"The absolute best show ever.  We want to see him again and again.\"\n",
      "\n",
      "📝 Review #53: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great service and smooth process for ordering a new surfboard. For a long time I was looking for a store online where I can purchase my first board, b...\"\n",
      "\n",
      "📝 Review #54: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Super happy with these guys. I've wanted to join them for many years and now that I have, I couldn't imagine going anywhere else. They are like your m...\"\n",
      "\n",
      "📝 Review #55: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Very good selection of dishes insensible portion sizes.\"\n",
      "\n",
      "📝 Review #56: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I have recently purchased matching Christmas pyjamas for my whole family from this site, have to be honest was a little sceptical about products but w...\"\n",
      "\n",
      "📝 Review #57: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Good results. Price was very reasonable. Will recommend to others.\"\n",
      "\n",
      "📝 Review #58: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Better version of Chipotle.\"\n",
      "\n",
      "📝 Review #59: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I’ve used this place multiple times and it is always a breeze. Exactly what you ask for. They are very good, fast, and reliable. U will use them again...\"\n",
      "\n",
      "📊 Progress: 60/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #60: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"great product.  Love the erformance\"\n",
      "\n",
      "📝 Review #61: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I called 2 days before our event and they where able to provide me with what I needed. Customer service was awesome as well and I would definitely use...\"\n",
      "\n",
      "📝 Review #62: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Good customer Service. Rachel solved our request promptly.\"\n",
      "\n",
      "📝 Review #63: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"A little slower than I expected, but the customer service was great! Order shipped within a week.\"\n",
      "\n",
      "📝 Review #64: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Increased my business into a lot of customers. Thankfully we found them saved my business. 🤗🤩\"\n",
      "\n",
      "📝 Review #65: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Really gorgeous decor and ambient was magnificent.  Bathroom on the second floor with a crazy loopy stairs a big minus but there's an elevator.  Resta...\"\n",
      "\n",
      "📝 Review #66: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"It is a very well kept site. I was honored to pay my respect to President Lincoln in visiting the home where he passed away.\"\n",
      "\n",
      "📝 Review #67: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"On time, professional, expert and quick.\"\n",
      "\n",
      "📝 Review #68: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Excellent work.  They are extremely nice and  friendly.  They are also accommodating with schedules for busy families.\"\n",
      "\n",
      "📝 Review #69: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) Quality\n",
      "\n",
      "(Original)\n",
      "Calidad\"\n",
      "\n",
      "📊 Progress: 70/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #70: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I had ordered in January and the payment has been done too..but still I haven't received my parcel.. People Please don't take risk buying here...they ...\"\n",
      "\n",
      "📝 Review #71: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Thoroughly enjoyed the Crimes and Scandals Tour of Embassy Row with Rebecca! Learned a ton of interesting facts and enjoyed her awesome personality. C...\"\n",
      "\n",
      "📝 Review #72: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I normally don't rate any business very harshly but this one deserves it. I will let others make their own judgement to visit or not. I did visit base...\"\n",
      "\n",
      "📝 Review #73: LEGITIMATE\n",
      "⭐ Rating: 3.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Very expensive and not a lot to offer\"\n",
      "\n",
      "📝 Review #74: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) Tasty tasty!!\n",
      "\n",
      "(Original)\n",
      "Rico rico!!\"\n",
      "\n",
      "📝 Review #75: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Absolutely amazing. Has helped me to grow as a new artist, person, and woman. I am immensely grateful for your love for art and teaching, who you are,...\"\n",
      "\n",
      "📝 Review #76: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"The software is incredibly easy use, even as someone that does not have any experience.  The team is there to support you if needed but have designed ...\"\n",
      "\n",
      "📝 Review #77: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"The product was exceptional!! The shipping was so fast I was shocked to see it on my doorstep. Thank you!!\"\n",
      "\n",
      "📝 Review #78: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Awesome food. CJ is the man. Get greens and the brisket!\"\n",
      "\n",
      "📝 Review #79: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Amazing costumer service! I ordered a few parts that were lost in transit. They took care of the problem right away. Which we actually received the or...\"\n",
      "\n",
      "📊 Progress: 80/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #80: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"As Always I Love This Sight For My Baby I’m Always Ordering Clothes... I Wanted To Get The Matching Christmas Pajamas For Pictures And What I Ordered ...\"\n",
      "\n",
      "📝 Review #81: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"very convenient for people to have a place to work with other business partners.   great to know this type of hotel to stay. will use this service mor...\"\n",
      "\n",
      "📝 Review #82: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Awesome tacos\"\n",
      "\n",
      "📝 Review #83: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Highly recommend, real fun virtual team outing!\"\n",
      "\n",
      "📝 Review #84: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"They are the best source of information for all things Amazon!  After a full year of trying to get my Amazon account back.  I called them last weeek a...\"\n",
      "\n",
      "📝 Review #85: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I just had a really bad experience with this eatery! Ordered food from here and the jollof rice arrived dead cold,  stale, and hopelessly unappealing!...\"\n",
      "\n",
      "📝 Review #86: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I did the White House at Night Scandals tour. Our guide Boglarka was great! She was really funny and knowledgeable. She was open to questions. She gav...\"\n",
      "\n",
      "📝 Review #87: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"This was overall a great experience. I came across Jungle Blunts on YouTube. I then placed a order and received them a lot soon these expected. I proc...\"\n",
      "\n",
      "📝 Review #88: LEGITIMATE\n",
      "⭐ Rating: 3.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"It's ok, but huge lines.\"\n",
      "\n",
      "📝 Review #89: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"This is the spot for all of your surfing needs.  They have all the selection, the best prices and are just cool to chat with. Board cave is also build...\"\n",
      "\n",
      "📊 Progress: 90/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #90: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Good drinks, good food...not very authentic Thai food though. The customer service was exceptional.\"\n",
      "\n",
      "📝 Review #91: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Delicious barbecue in a great location! Great quality meats and creative side options. Tons of seating with friendly service. Will definitely be back ...\"\n",
      "\n",
      "📝 Review #92: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Intimate dining with wonderful small plates representative of the street food found in countries across the world. Really well done.\"\n",
      "\n",
      "📝 Review #93: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Massive and awesome monument\"\n",
      "\n",
      "📝 Review #94: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Friendly staff, quick service, cash only, and as you would expect, tasty diner breakfast! Their description says it right, \"no frills!\"\"\n",
      "\n",
      "📝 Review #95: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Had so much fun and such a great workout!!\"\n",
      "\n",
      "📝 Review #96: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Food is EXCELLENT and people are awesome.\"\n",
      "\n",
      "📝 Review #97: LEGITIMATE\n",
      "⭐ Rating: 3.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"They alright just because\"\n",
      "\n",
      "📝 Review #98: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great service, thank you again.\"\n",
      "\n",
      "📝 Review #99: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) Thanks Rachel for your good management and great service! I recommend this page to buy, great attention!\n",
      "\n",
      "(Original)\n",
      "Gracias Ra...\"\n",
      "\n",
      "📊 Progress: 100/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #100: LEGITIMATE\n",
      "⭐ Rating: 3.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Food--AMAZING.  Got the something something sampler, everything DELICIOUS!  Staff was awesome and very knowledgeable and the food was ready in a SNAP!...\"\n",
      "\n",
      "📝 Review #101: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Wonderful scenery, exquisite food options and calming atmosphere. However the rodent control must be amped up.\"\n",
      "\n",
      "📝 Review #102: LEGITIMATE\n",
      "⭐ Rating: 3.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"They need to improve how people leave. Thousands of people trying to use a few escalators is dangerous. There was almost a trample incident last time ...\"\n",
      "\n",
      "📝 Review #103: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Didn't come when said! Mad if you don't buy off their overpriced truck. Technicians wonderful but boss had no customer service.\"\n",
      "\n",
      "📝 Review #104: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"East Meets Dress exceeded my expectations! I was so anxious about trying to find a cheongsam and making sure that it actually fits! They custom made m...\"\n",
      "\n",
      "📝 Review #105: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"When I read about the ingredients in Nutra Thrive, I decided that it might be beneficial for our aging 16 year-old Orange Tabby, Casanova. We have bee...\"\n",
      "\n",
      "📝 Review #106: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"The Lincoln, a very iconic monument. People come from all parts of the world to see it. I think it's very cool and very well done. Don't forget to exp...\"\n",
      "\n",
      "📝 Review #107: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Absolutely genius. Lucky to find people who are so dedicated to making other people's lives easier.\"\n",
      "\n",
      "📝 Review #108: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great company, great products\"\n",
      "\n",
      "📝 Review #109: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"If you're looking to build a web presence for your business this is the place to go. These guys are pros at digital marketing from websites to social ...\"\n",
      "\n",
      "📊 Progress: 110/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #110: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Capitals\"\n",
      "\n",
      "📝 Review #111: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"We entered parking lot B early Friday morning to catch our 8am flight. It was still dark out and there was very little lighting. The entrance into par...\"\n",
      "\n",
      "📝 Review #112: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"It's ok\"\n",
      "\n",
      "📝 Review #113: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I recommend Throtl, I got my Oil Catch can in less than 2 days. Awesome quality and great prices\"\n",
      "\n",
      "📝 Review #114: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"100% worth a visit.  It's best to let everyone order two small platers and then everyone shares what arrives.  Most food comes out quickly so it's eas...\"\n",
      "\n",
      "📝 Review #115: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Friendly staff and excellent service! They upgraded my computer to have an SSD and I couldn't be happier. 10/10 would recommend.\"\n",
      "\n",
      "📝 Review #116: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great tour that you should not miss in D.C.  Remember to book online, tons of guests, and the small exhibition in the back in interesting.\"\n",
      "\n",
      "📝 Review #117: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I have been having ornaments with love  make individualized ornaments for my five grandchildren and my pets for at least 12 years. The ornaments are a...\"\n",
      "\n",
      "📝 Review #118: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great food, ambiance, prices\"\n",
      "\n",
      "📝 Review #119: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"The booking site is great. Easy and quick. The step by step approach is quite clear and all options are easily displayed.\"\n",
      "\n",
      "📊 Progress: 120/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #120: LEGITIMATE\n",
      "⭐ Rating: 3.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"The web site is easy to use and I got the reservation made that I needed.  My biggest issue is that you cannot use this web site to make reservations ...\"\n",
      "\n",
      "📝 Review #121: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Incredible place..always!!!\"\n",
      "\n",
      "📝 Review #122: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"excellent!\"\n",
      "\n",
      "📝 Review #123: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Brad delivers material in a clear and straightforward method. He cares about the end result.\"\n",
      "\n",
      "📝 Review #124: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"DJ Christian was great! Thank you, Nice Entertainment, for taking the time to come DJ our preschool dance. The kids (and parents) loved it!\"\n",
      "\n",
      "📝 Review #125: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Good food, good environment GREAT location. Parking is a nightmare so Uber or Lyft if you can otherwise prepare to drive around for a while. Most near...\"\n",
      "\n",
      "📝 Review #126: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great low monthly payments\"\n",
      "\n",
      "📝 Review #127: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Clean, well run, on time.\"\n",
      "\n",
      "📝 Review #128: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Delicious bbq-weighed by the pound\"\n",
      "\n",
      "📝 Review #129: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I don't normally leave reviews, but Rose Farmers roses and customer service was so exemplary I had to give them 5 stars and share my experience. I ord...\"\n",
      "\n",
      "📊 Progress: 130/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #130: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Being able to have a reliable social presence is key! Highly recommended!\"\n",
      "\n",
      "📝 Review #131: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Has my five star. Top notch. Historic.\"\n",
      "\n",
      "📝 Review #132: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) Friendly, typical USA cuisine, good local craft beers (some too rare). Much atmosphere and lively\n",
      "\n",
      "(Original)\n",
      "Amables, típica c...\"\n",
      "\n",
      "📝 Review #133: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) Hello, I just moved from San Ysidro to Tijuana. Very fast indeed. Previously, when going from Mexico to the USA, I bought a rou...\"\n",
      "\n",
      "📝 Review #134: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Nice guys and effective. Couple of visits and the problem was resolved.\"\n",
      "\n",
      "📝 Review #135: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"A little loud, but the pork belly, pork loin, and greens were excellent.\"\n",
      "\n",
      "📝 Review #136: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"What to say, so many things. In a word \"Beautiful \" you have to see it.\"\n",
      "\n",
      "📝 Review #137: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) I love all the products, especially the rejuvenating oil because it has many uses, I use it in everything such as hair dye, mas...\"\n",
      "\n",
      "📝 Review #138: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Customer service is top notch Kuenzler went above and beyond to ensure I was satisfied with a replacement order. And the clothes are super cute.\"\n",
      "\n",
      "📝 Review #139: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"excellent food, very articulate and polite stuff. Fantastic place. Need to reserve.\"\n",
      "\n",
      "📊 Progress: 140/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #140: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Best quality products I have found to date.  Extremely fast shipping and excellent customer support.  You can really care LGB cares about their custom...\"\n",
      "\n",
      "📝 Review #141: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"A place to give your respects to those who have given their lives for others...many thanks to the police unity tour riders and the public who helps ke...\"\n",
      "\n",
      "📝 Review #142: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Played on someone else's server, and the quality was amazing, even with a bunch of people on. I just wish Minecraft server hosting had a free tier.\"\n",
      "\n",
      "📝 Review #143: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"As an IMG hoping to match into a residency program, I came across MD2B Connect during my search for externships. I reached out to Manish and I was giv...\"\n",
      "\n",
      "📝 Review #144: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Very popular place and sort of hard to get a good photo without getting photo bombed\"\n",
      "\n",
      "📝 Review #145: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"will use this facility from now on. air fare as well as travel time to Mexican destination is half of San Diego airport departure. signage from Tijuan...\"\n",
      "\n",
      "📝 Review #146: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Went to the Wizards game, I suggest you eat before you go. The food and drink prices are worst than an amusement park. However, the facility was very ...\"\n",
      "\n",
      "📝 Review #147: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Very good experience.  Worked with these guys to remove a large tree at a rental property.  Efficient, reasonably priced, and easy to work with, would...\"\n",
      "\n",
      "📝 Review #148: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Mr. Kim is the best tailor in Washington, DC.  Excellent service and great care.  Always a kind word and his work is impeccable.  I have never seen hi...\"\n",
      "\n",
      "📝 Review #149: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"It's easy to stop quickly to drop off and pick someone up.\"\n",
      "\n",
      "📊 Progress: 150/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #150: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"At first I was sceptical about the site and ordering but  I was pretty amazed with the prompt and effective delivery process. My package came safe and...\"\n",
      "\n",
      "📝 Review #151: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Ticketbud was recommended to me (after I expressed some dissatisfaction with the terms and conditions of Eventbrite) and I have not been disappointed ...\"\n",
      "\n",
      "📝 Review #152: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Monumental place with strong energy, inpressive view all around, lot of people of different nationalities and different age. Nice to spend time when w...\"\n",
      "\n",
      "📝 Review #153: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Amazing! Still can’t believe all the stuff that happened.\"\n",
      "\n",
      "📝 Review #154: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Nonstop harassing calls, ignore removal request. Spoof different numbers daily!\"\n",
      "\n",
      "📝 Review #155: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"So much variety! There’s always a good deal to be found!\"\n",
      "\n",
      "📝 Review #156: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Stephanie has been mentoring me since 2015. She has helped me with my resume, getting my foot in the door with my very first corporate job, and interv...\"\n",
      "\n",
      "📝 Review #157: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great shoes!!! Comfortable and seem to be durable!! Loving these shoes so far!\"\n",
      "\n",
      "📝 Review #158: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great facility and everyone was extremely friendly and helpful!\"\n",
      "\n",
      "📝 Review #159: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Don't even think about dealing with this company. I ordered my suspension from throtl back in march 29 and till this day I have not received any updat...\"\n",
      "\n",
      "📊 Progress: 160/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #160: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"She gave me so much relief after talking to my beloved dog on the other side.\"\n",
      "\n",
      "📝 Review #161: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great concerts!\"\n",
      "\n",
      "📝 Review #162: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Perfect place for concerts\"\n",
      "\n",
      "📝 Review #163: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Bought a pair of pro taper handle bar risers . they showed up in my mailbox from USPS the package was opened up with just the tags left in it. There w...\"\n",
      "\n",
      "📝 Review #164: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Love the refills on popcorn!\"\n",
      "\n",
      "📝 Review #165: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"From the very first time I called, I felt like I was dealing with a professional organization and that all of my questions would be answered properly....\"\n",
      "\n",
      "📝 Review #166: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"This is a very good website and there customer service is very responsive and I give them 5 star...and there products are of good quality and not pric...\"\n",
      "\n",
      "📝 Review #167: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Do not hesitate to call Rosenbaum Famularo, P.C. for help with you Amazon business issues!  So happy I found them. They are now my go-to attorneys for...\"\n",
      "\n",
      "📝 Review #168: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Very touching. Loved every minute of it.\"\n",
      "\n",
      "📝 Review #169: LEGITIMATE\n",
      "⭐ Rating: 3.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"They have a problem with the service; but if you're going to drink tea; they do it well. Your tea is always hot over the fire.\"\n",
      "\n",
      "📊 Progress: 170/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #170: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"RoseFarmers is an outstanding, #1 company you must visit online and see the collection yourself! These Rose-growing experts and breeders hand pick the...\"\n",
      "\n",
      "📝 Review #171: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Techloq are literally available 24 hours a day, whenever I have a issue - Techloq are there to assist instantly.\"\n",
      "\n",
      "📝 Review #172: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) Very good product quality, super helpful customer service. Shipping within 3 weeks.\n",
      "\n",
      "(Original)\n",
      "Bardzo dobra jakość produktów, ...\"\n",
      "\n",
      "📝 Review #173: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Clyde's was operating very well with all of the current safety precautions. Each member of the staff was extremely friendly and helpful and the servic...\"\n",
      "\n",
      "📝 Review #174: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"very good and delicious salad\"\n",
      "\n",
      "📝 Review #175: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"The very best in Moon Bounce rentals.. What others charge for a couple of hours, they charge for the entire day!!! It was awesome.. If you are looking...\"\n",
      "\n",
      "📝 Review #176: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"So easy and efficient!  Saved valuable vacation time not going through the standard drawn out vehicle rental process.  The car was clean, blended in w...\"\n",
      "\n",
      "📝 Review #177: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Taste has deteriorated compared to the past. I guess it's because he's famous. I do not recommend; you can eat betters in other restourants.\"\n",
      "\n",
      "📝 Review #178: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"What kind of business is this place running, my card has already been charged and i haven't received not on item ive purchased. Ive sent severl emails...\"\n",
      "\n",
      "📝 Review #179: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I hired Joe & team from KJ Marble & Tile in November 2017 to remodel a bathroom in our Boca Raton home. My decision to hire them was based on their ma...\"\n",
      "\n",
      "📊 Progress: 180/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #180: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) It is a good place, very nice that place and the food is excellent it is also a very tidy and very decorated restaurant\n",
      "\n",
      "(Origi...\"\n",
      "\n",
      "📝 Review #181: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great place to watch a football game...\"\n",
      "\n",
      "📝 Review #182: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Dealt with Steve McCrea at Ed Hamilton for a crewed catamaran charter out of Split, Croatia in Sept. 2019.  Steve was great to work with and was very ...\"\n",
      "\n",
      "📝 Review #183: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Exotic Blooms does a fine job of communicating and delivering a positive experience to the customer!\"\n",
      "\n",
      "📝 Review #184: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Kerry McDonald has been always so helpful.\n",
      "She goes above and beyond to help the clients. Her responses are so prompt and accurate.\n",
      "\n",
      "Every time we con...\"\n",
      "\n",
      "📝 Review #185: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Extremely poor leads and customer service. Be Careful!!\"\n",
      "\n",
      "📝 Review #186: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"An horrible experience today in the butcher's department.  I have never been so disrespected!\"\n",
      "\n",
      "📝 Review #187: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Cool show!\"\n",
      "\n",
      "📝 Review #188: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) My experience with monat has been excellent, in the first month I earned 5 times more than I invested apart from this by follow...\"\n",
      "\n",
      "📝 Review #189: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"The shipping took a long time but the product is amazing. I love what I got\"\n",
      "\n",
      "📊 Progress: 190/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #190: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Loved the Gountlet. I recommend it for everyone who is on the journey to heal. You’ll be amazed how much it does help. 💖🙌🏻\"\n",
      "\n",
      "📝 Review #191: LEGITIMATE\n",
      "⭐ Rating: 4.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"(Translated by Google) Ideal costume and slippers!\n",
      "\n",
      "(Original)\n",
      "Disfraz y zapatillas ideales!\"\n",
      "\n",
      "📝 Review #192: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great customer service with quick and wonderful resolution. Items look just as pictured on site.\"\n",
      "\n",
      "📝 Review #193: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great selection of plants\"\n",
      "\n",
      "📝 Review #194: LEGITIMATE\n",
      "⭐ Rating: 1.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"These people are ridiculous. Why do you have a phone number and email address if you don't use either? Then I call the embassy who proceeds to forward...\"\n",
      "\n",
      "📝 Review #195: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Finally, I got a soul to my songs after a long time. And all thanks to Mike. He turned my songs into a hit song and I actually liked the final project...\"\n",
      "\n",
      "📝 Review #196: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Len and his crew got the job done as promised before Christmas and house guests arriving.  The bathroom is beautiful - Thanks!!\"\n",
      "\n",
      "📝 Review #197: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"I am so glad I found Alltrue (formerly Causebox). The products I receive are so unique, Earth friendly and just plain lovely! Whether for myself or as...\"\n",
      "\n",
      "📝 Review #198: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Great mezze, not too expensive.\"\n",
      "\n",
      "📝 Review #199: LEGITIMATE\n",
      "⭐ Rating: 2.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"The price was not right; I bought a 2-piece menu; the burger and bread did not taste good.\"\n",
      "\n",
      "📊 Progress: 200/200 reviews\n",
      "------------------------------------------------------------\n",
      "\n",
      "📝 Review #200: LEGITIMATE\n",
      "⭐ Rating: 5.0\n",
      "🎯 Confidence: 0.000\n",
      "📄 Text: \"Went here while visiting DC and was surprised! Wilmot was the man! The waffles in the chicken and waffles was the best I ever had!\"\n",
      "\n",
      "======================================================================\n",
      "📊 PROCESSING COMPLETE!\n",
      "📋 Label distribution:\n",
      "   LEGITIMATE: 200\n",
      "💾 Results saved to: sample_200_reviews_with_labels_1756586233.csv\n",
      "📊 Output columns: ['index', 'text', 'rating', 'label', 'confidence', 'reason']\n",
      "\n",
      "🔍 First 5 results:\n",
      "   index       label  rating\n",
      "0      1  LEGITIMATE     5.0\n",
      "1      2  LEGITIMATE     5.0\n",
      "2      3  LEGITIMATE     5.0\n",
      "3      4  LEGITIMATE     5.0\n",
      "4      5  LEGITIMATE     5.0\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Sample Review Classification - 200 Reviews with Text and Labels\n",
    "print(\"=\" * 70)\n",
    "print(\"🤖 SAMPLE REVIEW CLASSIFICATION - 200 REVIEWS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def load_additional_reviews():\n",
    "    \"\"\"Load additional review datasets - simplified to extract only text and rating\"\"\"\n",
    "    additional_dfs = []\n",
    "    \n",
    "    # Check for additional review files\n",
    "    additional_files = [\n",
    "        './review-other.json',\n",
    "        # Add more file paths as needed\n",
    "    ]\n",
    "    1\n",
    "    for file_path in additional_files:\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                if file_path.endswith('.json'):\n",
    "                    # Enhanced JSON loading with better error handling\n",
    "                    print(f\"🔄 Attempting to load {file_path}...\")\n",
    "                    \n",
    "                    # First, peek at the file to determine format\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        first_line = f.readline().strip()\n",
    "                        second_line = f.readline().strip()\n",
    "                    \n",
    "                    # Check if it's JSONL format (each line is a JSON object)\n",
    "                    if (first_line.startswith('{') and first_line.endswith('}') and \n",
    "                        second_line.startswith('{') and second_line.endswith('}')):\n",
    "                        \n",
    "                        print(f\"📄 Detected JSONL format (JSON Lines) - parsing line by line...\")\n",
    "                        json_objects = []\n",
    "                        \n",
    "                        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                            for line_num, line in enumerate(f, 1):\n",
    "                                line = line.strip()\n",
    "                                if line:  # Skip empty lines\n",
    "                                    try:\n",
    "                                        obj = json.loads(line)\n",
    "                                        json_objects.append(obj)\n",
    "                                    except json.JSONDecodeError as e:\n",
    "                                        print(f\"⚠️ Skipping invalid JSON on line {line_num}: {e}\")\n",
    "                                        continue\n",
    "                        \n",
    "                        json_data = json_objects\n",
    "                        print(f\"✅ Successfully parsed {len(json_data)} JSON objects from JSONL file\")\n",
    "                        \n",
    "                    else:\n",
    "                        # Try standard JSON formats\n",
    "                        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                            content = f.read().strip()\n",
    "                        \n",
    "                        if content.startswith('[') and content.endswith(']'):\n",
    "                            # Array of JSON objects\n",
    "                            json_data = json.loads(content)\n",
    "                            print(f\"✅ Successfully parsed JSON array with {len(json_data)} objects\")\n",
    "                        elif content.startswith('{') and content.endswith('}'):\n",
    "                            # Single JSON object\n",
    "                            json_data = json.loads(content)\n",
    "                            print(f\"✅ Successfully parsed single JSON object\")\n",
    "                        else:\n",
    "                            print(f\"❌ Unrecognized JSON format in {file_path}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Convert to DataFrame and apply same cleaning as Kaggle data\n",
    "                    if isinstance(json_data, list):\n",
    "                        if json_data:  # Check if list is not empty\n",
    "                            full_df = pd.DataFrame(json_data)\n",
    "                            print(f\"✅ Created DataFrame with {len(full_df)} rows and {len(full_df.columns)} columns\")\n",
    "                            print(f\"📋 Original columns: {list(full_df.columns)}\")\n",
    "                            \n",
    "                            # Apply same cleaning process as Kaggle dataset\n",
    "                            cleaned_df = clean_json_data_like_kaggle(full_df)\n",
    "                            if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                                additional_dfs.append(cleaned_df)\n",
    "                        else:\n",
    "                            print(f\"⚠️ JSON file {file_path} contains empty array\")\n",
    "                    else:\n",
    "                        full_df = pd.json_normalize(json_data)\n",
    "                        print(f\"✅ Created DataFrame with {len(full_df)} rows and {len(full_df.columns)} columns\")\n",
    "                        cleaned_df = clean_json_data_like_kaggle(full_df)\n",
    "                        if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                            additional_dfs.append(cleaned_df)\n",
    "                        \n",
    "                elif file_path.endswith('.html'):\n",
    "                    # Enhanced HTML parsing with dependency installation\n",
    "                    try:\n",
    "                        # First try to install lxml if not available\n",
    "                        try:\n",
    "                            import lxml\n",
    "                        except ImportError:\n",
    "                            print(f\"📦 Installing lxml for HTML parsing...\")\n",
    "                            import subprocess\n",
    "                            import sys\n",
    "                            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"lxml\"])\n",
    "                            print(f\"✅ lxml installed successfully\")\n",
    "                        \n",
    "                        # Now try to parse HTML\n",
    "                        html_tables = pd.read_html(file_path, encoding='utf-8')\n",
    "                        if html_tables:\n",
    "                            # If multiple tables, try to find the one with review-like data\n",
    "                            best_table = None\n",
    "                            max_rows = 0\n",
    "                            \n",
    "                            for i, table in enumerate(html_tables):\n",
    "                                if len(table) > max_rows:\n",
    "                                    # Look for text-like columns\n",
    "                                    text_like_cols = [col for col in table.columns if \n",
    "                                                    any(keyword in str(col).lower() for keyword in \n",
    "                                                        ['text', 'review', 'comment', 'content', 'message'])]\n",
    "                                    if text_like_cols or len(table.columns) >= 3:  # Reasonable number of columns\n",
    "                                        best_table = table\n",
    "                                        max_rows = len(table)\n",
    "                            \n",
    "                            if best_table is not None:\n",
    "                                print(f\"✅ Found table with {len(best_table)} rows from {file_path}\")\n",
    "                                cleaned_df = clean_json_data_like_kaggle(best_table)\n",
    "                                if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                                    additional_dfs.append(cleaned_df)\n",
    "                            else:\n",
    "                                print(f\"⚠️ No suitable table found in {file_path}\")\n",
    "                        else:\n",
    "                            print(f\"⚠️ No tables found in HTML file {file_path}\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Could not parse HTML file {file_path}: {e}\")\n",
    "                        print(f\"💡 Try converting the HTML file to CSV format manually\")\n",
    "                        \n",
    "                elif file_path.endswith('.csv'):\n",
    "                    try:\n",
    "                        # Try different encodings\n",
    "                        encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "                        full_df = None\n",
    "                        \n",
    "                        for encoding in encodings:\n",
    "                            try:\n",
    "                                full_df = pd.read_csv(file_path, encoding=encoding)\n",
    "                                print(f\"✅ Loaded {len(full_df)} rows from {file_path} (encoding: {encoding})\")\n",
    "                                break\n",
    "                            except UnicodeDecodeError:\n",
    "                                continue\n",
    "                        \n",
    "                        if full_df is not None:\n",
    "                            cleaned_df = clean_json_data_like_kaggle(full_df)\n",
    "                            if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                                additional_dfs.append(cleaned_df)\n",
    "                        else:\n",
    "                            print(f\"❌ Could not read CSV file {file_path} with any encoding\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Error loading CSV {file_path}: {e}\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Unexpected error loading {file_path}: {e}\")\n",
    "                import traceback\n",
    "                print(f\"📋 Full error traceback:\")\n",
    "                traceback.print_exc()\n",
    "        else:\n",
    "            print(f\"ℹ️ File not found: {file_path}\")\n",
    "    \n",
    "    return additional_dfs\n",
    "\n",
    "def clean_json_data_like_kaggle(df):\n",
    "    \"\"\"Clean JSON data using the same method as Kaggle dataset (clean_reviews_dataset)\"\"\"\n",
    "    \n",
    "    print(f\"🧹 Applying Kaggle-style cleaning to DataFrame with columns: {list(df.columns)}\")\n",
    "    \n",
    "    try:\n",
    "        # Use the same _find_col function and cleaning logic as Kaggle dataset\n",
    "        col_business = _find_col(df, [\"business_name\", \"restaurant\", \"place_name\", \"name\"], required=False)\n",
    "        col_author   = _find_col(df, [\"author_name\", \"user\", \"user_name\", \"reviewer\"], required=False)\n",
    "        col_text     = _find_col(df, [\"text\", \"review_text\", \"comment\", \"content\", \"review\"], required=True)\n",
    "        col_rating   = _find_col(df, [\"rating\", \"stars\", \"score\", \"star_rating\"], required=False)\n",
    "\n",
    "        # Optional columns may or may not exist\n",
    "        col_photo          = _find_col(df, [\"photo\"], required=False)\n",
    "        col_rating_category= _find_col(df, [\"rating_category\"], required=False)\n",
    "\n",
    "        # Work on a copy\n",
    "        d = df.copy()\n",
    "\n",
    "        # Normalize whitespace for string fields (only if they exist)\n",
    "        if col_text:\n",
    "            d[col_text] = d[col_text].astype(str).str.strip()\n",
    "        if col_business:\n",
    "            d[col_business] = d[col_business].astype(str).str.strip()\n",
    "        if col_author:\n",
    "            d[col_author] = d[col_author].astype(str).str.strip()\n",
    "\n",
    "        # Coerce rating to numeric if exists\n",
    "        if col_rating:\n",
    "            d[col_rating] = pd.to_numeric(d[col_rating], errors=\"coerce\")\n",
    "            d[col_rating] = d[col_rating].fillna(3)  # Default to 3 if NaN\n",
    "            d[col_rating] = d[col_rating].clip(1, 5)  # Ensure 1-5 range\n",
    "\n",
    "        # Drop rows with missing/empty required fields\n",
    "        before = len(d)\n",
    "        d = d.dropna(subset=[col_text])\n",
    "        # Remove empty-string rows in text column\n",
    "        d = d[d[col_text] != \"\"]\n",
    "        # Remove very short reviews\n",
    "        d = d[d[col_text].str.len() >= 5]\n",
    "\n",
    "        removed = before - len(d)\n",
    "        print(f\"🧹 Cleaned dataset: {before} → {len(d)} rows (removed {removed})\")\n",
    "\n",
    "        if len(d) == 0:\n",
    "            print(\"⚠️ No valid reviews remaining after cleaning\")\n",
    "            return None\n",
    "\n",
    "        # Rebuild output with target column names in the same format as Kaggle\n",
    "        out_data = {\n",
    "            \"text\": d[col_text],\n",
    "            \"rating\": d[col_rating] if col_rating else pd.Series([3]*len(d))\n",
    "        }\n",
    "        \n",
    "        # Add optional columns if they exist\n",
    "        if col_business:\n",
    "            out_data[\"business_name\"] = d[col_business]\n",
    "        else:\n",
    "            out_data[\"business_name\"] = pd.Series(['Unknown Business']*len(d))\n",
    "            \n",
    "        if col_author:\n",
    "            out_data[\"author_name\"] = d[col_author]\n",
    "        else:\n",
    "            out_data[\"author_name\"] = pd.Series([f'user_{i}' for i in range(len(d))])\n",
    "\n",
    "        out = pd.DataFrame(out_data)\n",
    "        \n",
    "        # Attach optional columns if present\n",
    "        if col_photo and col_photo in d.columns:\n",
    "            out[\"photo\"] = d[col_photo]\n",
    "        else:\n",
    "            out[\"photo\"] = pd.Series([pd.NA]*len(d))\n",
    "            \n",
    "        if col_rating_category and col_rating_category in d.columns:\n",
    "            out[\"rating_category\"] = d[col_rating_category]\n",
    "        else:\n",
    "            out[\"rating_category\"] = pd.Series([pd.NA]*len(d))\n",
    "\n",
    "        return out.reset_index(drop=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during cleaning: {e}\")\n",
    "        return None\n",
    "\n",
    "def merge_all_datasets_and_sample(kaggle_df, additional_dfs, sample_size=200):\n",
    "    \"\"\"Merge all datasets and sample specified number of reviews\"\"\"\n",
    "    \n",
    "    if not additional_dfs:\n",
    "        print(\"ℹ️ No additional datasets found, using Kaggle data only\")\n",
    "        combined_df = kaggle_df.copy()\n",
    "    else:\n",
    "        print(f\"🔄 Merging {len(additional_dfs)} additional datasets with Kaggle data...\")\n",
    "        \n",
    "        # Combine all datasets\n",
    "        all_dfs = [kaggle_df]\n",
    "        \n",
    "        for i, add_df in enumerate(additional_dfs):\n",
    "            print(f\"   Adding dataset {i+1}/{len(additional_dfs)} with {len(add_df)} rows\")\n",
    "            all_dfs.append(add_df)\n",
    "        \n",
    "        try:\n",
    "            combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "            \n",
    "            # Remove duplicates based on text content\n",
    "            original_len = len(combined_df)\n",
    "            combined_df = combined_df.drop_duplicates(subset=['text'], keep='first')\n",
    "            duplicates_removed = original_len - len(combined_df)\n",
    "            \n",
    "            print(f\"📊 Merged dataset statistics:\")\n",
    "            print(f\"   Total reviews: {len(combined_df)}\")\n",
    "            print(f\"   Kaggle reviews: {len(kaggle_df)}\")\n",
    "            print(f\"   Additional reviews: {len(combined_df) - len(kaggle_df)}\")\n",
    "            print(f\"   Duplicates removed: {duplicates_removed}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error merging datasets: {e}\")\n",
    "            print(\"🔄 Falling back to Kaggle data only\")\n",
    "            combined_df = kaggle_df.copy()\n",
    "    \n",
    "    # Sample the specified number of reviews\n",
    "    if len(combined_df) > sample_size:\n",
    "        print(f\"🎯 Sampling {sample_size} reviews from {len(combined_df)} total reviews...\")\n",
    "        sampled_df = combined_df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        print(f\"🔄 Using all {len(combined_df)} reviews (less than requested {sample_size})\")\n",
    "        sampled_df = combined_df.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"📊 Final sample size: {len(sampled_df)} reviews\")\n",
    "    print(f\"📋 Final columns: {list(sampled_df.columns)}\")\n",
    "    \n",
    "    return sampled_df\n",
    "\n",
    "# Test the JSONL parsing specifically\n",
    "print(\"🧪 Testing JSONL parsing on your review-other.json file...\")\n",
    "test_path = './review-other.json'\n",
    "\n",
    "if os.path.exists(test_path):\n",
    "    try:\n",
    "        # Load and show sample data\n",
    "        sample_objects = []\n",
    "        with open(test_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= 5:  # Just get first 5 lines for testing\n",
    "                    break\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    try:\n",
    "                        obj = json.loads(line)\n",
    "                        sample_objects.append(obj)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"❌ Error parsing line {i+1}: {e}\")\n",
    "        \n",
    "        if sample_objects:\n",
    "            sample_df = pd.DataFrame(sample_objects)\n",
    "            print(f\"✅ Successfully parsed sample data:\")\n",
    "            print(f\"📊 Shape: {sample_df.shape}\")\n",
    "            print(f\"📋 Original columns: {list(sample_df.columns)}\")\n",
    "            \n",
    "            # Test cleaning\n",
    "            cleaned_sample = clean_json_data_like_kaggle(sample_df)\n",
    "            if cleaned_sample is not None:\n",
    "                print(f\"✅ Cleaned sample:\")\n",
    "                print(f\"📊 Shape: {cleaned_sample.shape}\")\n",
    "                print(f\"📋 Columns: {list(cleaned_sample.columns)}\")\n",
    "                print(f\"🔍 First few rows:\")\n",
    "                print(cleaned_sample.head(3))\n",
    "        else:\n",
    "            print(\"❌ No valid JSON objects found in sample\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error testing JSONL parsing: {e}\")\n",
    "else:\n",
    "    print(f\"❌ File not found: {test_path}\")\n",
    "\n",
    "# Check if we have a loaded dataframe\n",
    "if 'df' in locals() and not df.empty:\n",
    "    \n",
    "    # Load additional review datasets\n",
    "    print(\"📂 Searching for additional review datasets...\")\n",
    "    additional_datasets = load_additional_reviews()\n",
    "    \n",
    "    # Merge all datasets and sample 200 reviews\n",
    "    sample_df = merge_all_datasets_and_sample(df, additional_datasets, sample_size=200)\n",
    "    \n",
    "    # Verify we have the required columns\n",
    "    if 'text' not in sample_df.columns:\n",
    "        print(\"❌ No text column found in sample dataset\")\n",
    "        print(\"🔄 Please check your data sources\")\n",
    "    else:\n",
    "        print(f\"📝 Using 'text' column for review text\")\n",
    "        \n",
    "        # Display sample dataset information\n",
    "        print(f\"\\n📊 SAMPLE DATASET INFORMATION:\")\n",
    "        print(f\"   Total reviews for processing: {len(sample_df)}\")\n",
    "        print(f\"   Columns: {list(sample_df.columns)}\")\n",
    "        \n",
    "        if 'rating' in sample_df.columns:\n",
    "            rating_dist = dict(sample_df['rating'].value_counts().sort_index())\n",
    "            print(f\"   Rating distribution: {rating_dist}\")\n",
    "        \n",
    "        # Show a sample of the data\n",
    "        print(f\"\\n🔍 Sample of data:\")\n",
    "        for i, row in sample_df.head(5).iterrows():\n",
    "            text = str(row['text'])[:100]\n",
    "            rating = row.get('rating', 'N/A')\n",
    "            print(f\"   {i+1}. Rating: {rating} | Text: {text}{'...' if len(str(row['text'])) > 100 else ''}\")\n",
    "        print()\n",
    "        \n",
    "        # Process reviews and generate labels\n",
    "        if gemma_classifier and gemma_classifier.client:\n",
    "            print(f\"🔄 Processing {len(sample_df)} reviews with Gemma classifier...\")\n",
    "            print(f\"🚨 RESULTS (Text + Labels):\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            results_for_output = []\n",
    "            \n",
    "            for idx, row in sample_df.iterrows():\n",
    "                review_text = str(row['text']) if pd.notna(row['text']) else \"\"\n",
    "                review_rating = row.get('rating', 3)\n",
    "                \n",
    "                # Progress indicator\n",
    "                if (idx + 1) % 10 == 0:\n",
    "                    print(f\"\\n📊 Progress: {idx + 1}/{len(sample_df)} reviews\")\n",
    "                    print(\"-\" * 60)\n",
    "                \n",
    "                # Skip empty reviews\n",
    "                if len(review_text.strip()) < 5:\n",
    "                    results_for_output.append({\n",
    "                        'index': idx + 1,\n",
    "                        'text': review_text,\n",
    "                        'rating': review_rating,\n",
    "                        'label': 'INVALID',\n",
    "                        'reason': 'Review too short'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Classify with Gemma\n",
    "                    result = gemma_classifier.classify_review(review_text)\n",
    "                    \n",
    "                    # Determine label\n",
    "                    is_violation = result.get('is_violation', False)\n",
    "                    violation_type = result.get('violation_type', 'unknown')\n",
    "                    confidence = result.get('policy_confidence', 0.0)\n",
    "                    \n",
    "                    if is_violation:\n",
    "                        label = f\"VIOLATION ({violation_type.upper()})\"\n",
    "                    else:\n",
    "                        label = \"LEGITIMATE\"\n",
    "                    \n",
    "                    results_for_output.append({\n",
    "                        'index': idx + 1,\n",
    "                        'text': review_text,\n",
    "                        'rating': review_rating,\n",
    "                        'label': label,\n",
    "                        'confidence': confidence,\n",
    "                        'reason': result.get('policy_reasoning', '')\n",
    "                    })\n",
    "                    \n",
    "                    # Display result\n",
    "                    print(f\"\\n📝 Review #{idx + 1}: {label}\")\n",
    "                    print(f\"⭐ Rating: {review_rating}\")\n",
    "                    print(f\"🎯 Confidence: {confidence:.3f}\")\n",
    "                    print(f\"📄 Text: \\\"{review_text[:150]}{'...' if len(review_text) > 150 else ''}\\\"\")\n",
    "                    if result.get('policy_reasoning'):\n",
    "                        print(f\"💡 Reason: {result.get('policy_reasoning', '')[:100]}{'...' if len(result.get('policy_reasoning', '')) > 100 else ''}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    results_for_output.append({\n",
    "                        'index': idx + 1,\n",
    "                        'text': review_text,\n",
    "                        'rating': review_rating,\n",
    "                        'label': 'ERROR',\n",
    "                        'reason': str(e)\n",
    "                    })\n",
    "                    print(f\"\\n❌ ERROR processing review #{idx + 1}: {str(e)}\")\n",
    "                \n",
    "                # Rate limiting\n",
    "                time.sleep(0.8)\n",
    "            \n",
    "            # Final summary and save results\n",
    "            print(f\"\\n\" + \"=\"*70)\n",
    "            print(f\"📊 PROCESSING COMPLETE!\")\n",
    "            \n",
    "            # Count labels\n",
    "            label_counts = {}\n",
    "            for result in results_for_output:\n",
    "                label = result['label'].split(' (')[0]  # Get main label part\n",
    "                label_counts[label] = label_counts.get(label, 0) + 1\n",
    "            \n",
    "            print(f\"📋 Label distribution:\")\n",
    "            for label, count in label_counts.items():\n",
    "                print(f\"   {label}: {count}\")\n",
    "            \n",
    "            # Save results to CSV\n",
    "            results_df = pd.DataFrame(results_for_output)\n",
    "            output_filename = f\"sample_200_reviews_with_labels_{int(time.time())}.csv\"\n",
    "            results_df.to_csv(output_filename, index=False)\n",
    "            print(f\"💾 Results saved to: {output_filename}\")\n",
    "            print(f\"📊 Output columns: {list(results_df.columns)}\")\n",
    "            \n",
    "            # Show first few results\n",
    "            print(f\"\\n🔍 First 5 results:\")\n",
    "            print(results_df[['index', 'label', 'rating']].head())\n",
    "            \n",
    "        else:\n",
    "            print(\"⚠️ Gemma classifier not available\")\n",
    "            print(\"💡 Generating simple output without ML classification...\")\n",
    "            \n",
    "            # Simple output without classification\n",
    "            simple_results = []\n",
    "            for idx, row in sample_df.iterrows():\n",
    "                simple_results.append({\n",
    "                    'index': idx + 1,\n",
    "                    'text': str(row['text']),\n",
    "                    'rating': row.get('rating', 'N/A'),\n",
    "                    'label': 'NOT_CLASSIFIED',\n",
    "                    'reason': 'Classifier not available'\n",
    "                })\n",
    "            \n",
    "            # Save simple results\n",
    "            simple_df = pd.DataFrame(simple_results)\n",
    "            output_filename = f\"sample_200_reviews_no_classification_{int(time.time())}.csv\"\n",
    "            simple_df.to_csv(output_filename, index=False)\n",
    "            print(f\"💾 Simple results saved to: {output_filename}\")\n",
    "\n",
    "elif 'df' not in locals() or df.empty:\n",
    "    print(\"⚠️ No dataset loaded yet\")\n",
    "    print(\"💡 Please run the data loading cells first to load your review dataset\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Dataset not available\")\n",
    "    print(\"🔄 Please ensure dataset is properly loaded\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1500a3",
   "metadata": {},
   "source": [
    "## 🎯 Summary & Next Steps\n",
    "\n",
    "### 🏆 What We've Built\n",
    "\n",
    "Our **Trustworthy Location Review System** includes:\n",
    "\n",
    "1. **🔍 Advanced Feature Engineering**\n",
    "   - 40+ textual and non-textual features\n",
    "   - Sentiment analysis, spam detection, readability metrics\n",
    "   - Restaurant & Establishments relevancy indicators\n",
    "\n",
    "2. **🚫 Rule-Based Policy Detection**\n",
    "   - Advertisement detection (contact info, promotional language)\n",
    "   - Irrelevant content filtering* (off-topic discussions)\n",
    "   - Rant without visit identification* (hearsay reviews)\n",
    "\n",
    "3. **🤖 Gemma 3 12B Integration**\n",
    "   - Our LLM of choice for policy violation detection\n",
    "   - Quality assessment and authenticity scoring\n",
    "   - HuggingFace Inference Client integration\n",
    "\n",
    "### 📊 System Capabilities\n",
    "\n",
    "- **Policy Violation Detection**: Identifies advertisements, irrelevant content, and fake rants\n",
    "- **Quality Assessment**: Evaluates review authenticity and helpfulness\n",
    "- **Batch Processing**: Handles large datasets efficiently\n",
    "- **Ensemble Decision Making**: Leverages multiple approaches for robust predictions\n",
    "- **Explainable AI**: Provides reasoning for each classification decision\n",
    "\n",
    "### 🚀 Production Readiness\n",
    "\n",
    "The system is designed for:\n",
    "- **Scalability**: Batch processing with configurable sizes\n",
    "- **Reliability**: Fallback mechanisms when individual components fail\n",
    "- **Flexibility**: Adjustable weights and thresholds\n",
    "- **Monitoring**: Comprehensive performance analytics\n",
    "\n",
    "### 📈 Next Steps\n",
    "\n",
    "1. **🔧 Fine-Tuning**\n",
    "   - Adjust ensemble weights based on validation data\n",
    "   - Optimize decision thresholds\n",
    "   - Add domain-specific rules\n",
    "\n",
    "2. **📊 Evaluation**\n",
    "   - Test on larger datasets\n",
    "   - Measure precision, recall, F1-score\n",
    "   - A/B test different configurations\n",
    "\n",
    "3. **🚀 Further Improvements**\n",
    "   - Find more \"bad\" examples to train the model better\n",
    "   - Implement monitoring dashboard\n",
    "\n",
    "### 🎉 Hackathon Impact\n",
    "\n",
    "This solution addresses the critical problem of **review trustworthiness** by:\n",
    "- **Filtering noise** from restaurant review platforms\n",
    "- **Protecting consumers** from misleading information\n",
    "- **Supporting businesses** with authentic feedback\n",
    "- **Improving platform quality** through automated moderation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
